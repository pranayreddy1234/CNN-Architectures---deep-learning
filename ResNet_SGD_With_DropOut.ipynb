{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZ2ZpboW14Da"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Hgza-JDZsh7"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JX6jSDWwZtND"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 50 # iterations over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx5bYvq-ZtQV"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "7mstneybZtTy",
    "outputId": "905d1f8d-365a-4b19-8c5c-6e1d7a4e574c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHzHxyG9Ztak"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 3))\n",
    "num_filters = 32\n",
    "t = Conv2D(kernel_size=2,strides=1,filters=num_filters,padding=\"same\")(inputs)\n",
    "t = ReLU()(t)\n",
    "\n",
    "t = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(t)\n",
    "y = ReLU()(t)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,t])\n",
    "z1 = ReLU()(y)\n",
    "\n",
    "z1 = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(z1)\n",
    "y = ReLU()(z1)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "#y = Dropout(0.5)(y)\n",
    "y = Add()([y,z1])\n",
    "z2 = ReLU()(y)\n",
    "\n",
    "z2 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z2)\n",
    "y = ReLU()(z2)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z2])\n",
    "z3 = ReLU()(y)\n",
    "\n",
    "z3 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z3)\n",
    "y = ReLU()(z3)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "#y = Dropout(0.5)(y)\n",
    "y = Add()([y,z3])\n",
    "z4 = ReLU()(y)\n",
    "\n",
    "z4 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z4)\n",
    "y = ReLU()(z4)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z4])\n",
    "z5 = ReLU()(y)\n",
    "\n",
    "z5 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z5)\n",
    "y = ReLU()(z5)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z5])\n",
    "z6 = ReLU()(y)\n",
    "\n",
    "z6 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z6)\n",
    "y = ReLU()(z6)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "#y = Dropout(0.5)(y)\n",
    "y = Add()([y,z6])\n",
    "z7 = ReLU()(y)\n",
    "\n",
    "z7 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z5)\n",
    "y = ReLU()(z7)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z7])\n",
    "z8 = ReLU()(y)\n",
    "\n",
    "t = AveragePooling2D(4)(z8)\n",
    "t = Flatten()(t)\n",
    "\n",
    "outputs = Dense(100, activation='softmax')(t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pUUjEJ9IZtga",
    "outputId": "b69c7a64-e5bb-4219-8760-16d1e43f8c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 32)   416         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_51 (ReLU)                 (None, 32, 32, 32)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 32)   4128        re_lu_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_52 (ReLU)                 (None, 32, 32, 32)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 32)   4128        re_lu_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 32, 32, 32)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 32, 32)   0           max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 32, 32, 32)   0           dropout_18[0][0]                 \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_53 (ReLU)                 (None, 32, 32, 32)   0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 32, 32)   9248        re_lu_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_54 (ReLU)                 (None, 32, 32, 32)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 32, 32)   9248        re_lu_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 32, 32, 32)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 32, 32, 32)   0           max_pooling2d_25[0][0]           \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_55 (ReLU)                 (None, 32, 32, 32)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 32, 32, 64)   8256        re_lu_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_56 (ReLU)                 (None, 32, 32, 64)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 32, 64)   0           max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 32, 32, 64)   0           dropout_19[0][0]                 \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_57 (ReLU)                 (None, 32, 32, 64)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_58 (ReLU)                 (None, 32, 32, 64)   0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 32, 32, 64)   0           max_pooling2d_27[0][0]           \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_59 (ReLU)                 (None, 32, 32, 64)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_60 (ReLU)                 (None, 32, 32, 128)  0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 128)  65664       re_lu_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 32, 128)  0           max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 32, 32, 128)  0           dropout_20[0][0]                 \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_61 (ReLU)                 (None, 32, 32, 128)  0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 128)  65664       re_lu_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 32, 256)  131328      conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_66 (ReLU)                 (None, 32, 32, 256)  0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 256)  262400      re_lu_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 32, 32, 256)  0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 256)  0           max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 32, 32, 256)  0           dropout_22[0][0]                 \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_67 (ReLU)                 (None, 32, 32, 256)  0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 8, 8, 256)    0           re_lu_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 16384)        0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          1638500     flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,281,220\n",
      "Trainable params: 2,281,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2J9Mch6LAyG"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    #zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cQb2S9lLA1o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C85WMW-QZteX"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d20_r5-EZtYX",
    "outputId": "ff1f6449-695a-4e0b-e87f-aed9b953c3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 4.1907 - accuracy: 0.0645\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10610, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 4.1907 - accuracy: 0.0645 - val_loss: 3.9617 - val_accuracy: 0.1061\n",
      "Epoch 2/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.7295 - accuracy: 0.1356\n",
      "Epoch 00002: val_accuracy improved from 0.10610 to 0.15970, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 3.7295 - accuracy: 0.1356 - val_loss: 3.6520 - val_accuracy: 0.1597\n",
      "Epoch 3/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.4244 - accuracy: 0.1873\n",
      "Epoch 00003: val_accuracy improved from 0.15970 to 0.21950, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 3.4244 - accuracy: 0.1873 - val_loss: 3.2712 - val_accuracy: 0.2195\n",
      "Epoch 4/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.1813 - accuracy: 0.2333\n",
      "Epoch 00004: val_accuracy improved from 0.21950 to 0.25760, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 3.1813 - accuracy: 0.2333 - val_loss: 3.0702 - val_accuracy: 0.2576\n",
      "Epoch 5/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.9792 - accuracy: 0.2709\n",
      "Epoch 00005: val_accuracy improved from 0.25760 to 0.29300, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 2.9792 - accuracy: 0.2709 - val_loss: 2.8760 - val_accuracy: 0.2930\n",
      "Epoch 6/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.8132 - accuracy: 0.3029\n",
      "Epoch 00006: val_accuracy improved from 0.29300 to 0.33200, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 2.8132 - accuracy: 0.3029 - val_loss: 2.6975 - val_accuracy: 0.3320\n",
      "Epoch 7/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6643 - accuracy: 0.3340\n",
      "Epoch 00007: val_accuracy improved from 0.33200 to 0.36680, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 2.6643 - accuracy: 0.3340 - val_loss: 2.5114 - val_accuracy: 0.3668\n",
      "Epoch 8/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5349 - accuracy: 0.3628\n",
      "Epoch 00008: val_accuracy improved from 0.36680 to 0.39300, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 2.5349 - accuracy: 0.3628 - val_loss: 2.4041 - val_accuracy: 0.3930\n",
      "Epoch 9/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4186 - accuracy: 0.3856\n",
      "Epoch 00009: val_accuracy improved from 0.39300 to 0.40570, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 2.4186 - accuracy: 0.3856 - val_loss: 2.3158 - val_accuracy: 0.4057\n",
      "Epoch 10/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3163 - accuracy: 0.4092\n",
      "Epoch 00010: val_accuracy improved from 0.40570 to 0.42890, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 2.3163 - accuracy: 0.4092 - val_loss: 2.2274 - val_accuracy: 0.4289\n",
      "Epoch 11/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2219 - accuracy: 0.4260\n",
      "Epoch 00011: val_accuracy improved from 0.42890 to 0.44480, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 2.2219 - accuracy: 0.4260 - val_loss: 2.1642 - val_accuracy: 0.4448\n",
      "Epoch 12/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1431 - accuracy: 0.4425\n",
      "Epoch 00012: val_accuracy improved from 0.44480 to 0.44610, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 2.1431 - accuracy: 0.4425 - val_loss: 2.1677 - val_accuracy: 0.4461\n",
      "Epoch 13/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0609 - accuracy: 0.4618\n",
      "Epoch 00013: val_accuracy improved from 0.44610 to 0.46410, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 2.0609 - accuracy: 0.4618 - val_loss: 2.0761 - val_accuracy: 0.4641\n",
      "Epoch 14/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9870 - accuracy: 0.4804\n",
      "Epoch 00014: val_accuracy improved from 0.46410 to 0.47820, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.9870 - accuracy: 0.4804 - val_loss: 2.0356 - val_accuracy: 0.4782\n",
      "Epoch 15/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9261 - accuracy: 0.4931\n",
      "Epoch 00015: val_accuracy improved from 0.47820 to 0.48820, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.9261 - accuracy: 0.4931 - val_loss: 1.9756 - val_accuracy: 0.4882\n",
      "Epoch 16/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8694 - accuracy: 0.5049\n",
      "Epoch 00016: val_accuracy improved from 0.48820 to 0.49530, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.8694 - accuracy: 0.5049 - val_loss: 1.9857 - val_accuracy: 0.4953\n",
      "Epoch 17/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8092 - accuracy: 0.5188\n",
      "Epoch 00017: val_accuracy improved from 0.49530 to 0.49970, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.8092 - accuracy: 0.5188 - val_loss: 1.9856 - val_accuracy: 0.4997\n",
      "Epoch 18/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7642 - accuracy: 0.5300\n",
      "Epoch 00018: val_accuracy improved from 0.49970 to 0.50890, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.7642 - accuracy: 0.5300 - val_loss: 1.9145 - val_accuracy: 0.5089\n",
      "Epoch 19/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7083 - accuracy: 0.5432\n",
      "Epoch 00019: val_accuracy improved from 0.50890 to 0.51350, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.7083 - accuracy: 0.5432 - val_loss: 1.8822 - val_accuracy: 0.5135\n",
      "Epoch 20/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6628 - accuracy: 0.5497\n",
      "Epoch 00020: val_accuracy improved from 0.51350 to 0.51590, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.6628 - accuracy: 0.5497 - val_loss: 1.8944 - val_accuracy: 0.5159\n",
      "Epoch 21/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6287 - accuracy: 0.5612\n",
      "Epoch 00021: val_accuracy improved from 0.51590 to 0.51880, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.6287 - accuracy: 0.5612 - val_loss: 1.8867 - val_accuracy: 0.5188\n",
      "Epoch 22/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5861 - accuracy: 0.5702\n",
      "Epoch 00022: val_accuracy improved from 0.51880 to 0.52330, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.5861 - accuracy: 0.5702 - val_loss: 1.8689 - val_accuracy: 0.5233\n",
      "Epoch 23/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5390 - accuracy: 0.5789\n",
      "Epoch 00023: val_accuracy improved from 0.52330 to 0.52390, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.5390 - accuracy: 0.5789 - val_loss: 1.8701 - val_accuracy: 0.5239\n",
      "Epoch 24/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5120 - accuracy: 0.5866\n",
      "Epoch 00024: val_accuracy improved from 0.52390 to 0.52940, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.5120 - accuracy: 0.5866 - val_loss: 1.8882 - val_accuracy: 0.5294\n",
      "Epoch 25/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4709 - accuracy: 0.5975\n",
      "Epoch 00025: val_accuracy did not improve from 0.52940\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.4709 - accuracy: 0.5975 - val_loss: 1.9508 - val_accuracy: 0.5228\n",
      "Epoch 26/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4508 - accuracy: 0.6012\n",
      "Epoch 00026: val_accuracy improved from 0.52940 to 0.53850, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.4508 - accuracy: 0.6012 - val_loss: 1.8538 - val_accuracy: 0.5385\n",
      "Epoch 27/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4226 - accuracy: 0.6066\n",
      "Epoch 00027: val_accuracy improved from 0.53850 to 0.54670, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.4226 - accuracy: 0.6066 - val_loss: 1.8086 - val_accuracy: 0.5467\n",
      "Epoch 28/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4004 - accuracy: 0.6137\n",
      "Epoch 00028: val_accuracy did not improve from 0.54670\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.4004 - accuracy: 0.6137 - val_loss: 1.8205 - val_accuracy: 0.5436\n",
      "Epoch 29/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3695 - accuracy: 0.6204\n",
      "Epoch 00029: val_accuracy did not improve from 0.54670\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.3695 - accuracy: 0.6204 - val_loss: 1.8730 - val_accuracy: 0.5369\n",
      "Epoch 30/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3305 - accuracy: 0.6298\n",
      "Epoch 00030: val_accuracy did not improve from 0.54670\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.3305 - accuracy: 0.6298 - val_loss: 1.8365 - val_accuracy: 0.5408\n",
      "Epoch 31/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3033 - accuracy: 0.6362\n",
      "Epoch 00031: val_accuracy did not improve from 0.54670\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.3033 - accuracy: 0.6362 - val_loss: 1.8166 - val_accuracy: 0.5435\n",
      "Epoch 32/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2867 - accuracy: 0.6407\n",
      "Epoch 00032: val_accuracy did not improve from 0.54670\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.2867 - accuracy: 0.6407 - val_loss: 1.8857 - val_accuracy: 0.5467\n",
      "Epoch 33/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2601 - accuracy: 0.6486\n",
      "Epoch 00033: val_accuracy did not improve from 0.54670\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.2601 - accuracy: 0.6486 - val_loss: 1.9451 - val_accuracy: 0.5332\n",
      "Epoch 34/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2435 - accuracy: 0.6502\n",
      "Epoch 00034: val_accuracy improved from 0.54670 to 0.55080, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.2435 - accuracy: 0.6502 - val_loss: 1.8264 - val_accuracy: 0.5508\n",
      "Epoch 35/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2117 - accuracy: 0.6593\n",
      "Epoch 00035: val_accuracy improved from 0.55080 to 0.55330, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.2117 - accuracy: 0.6593 - val_loss: 1.8471 - val_accuracy: 0.5533\n",
      "Epoch 36/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1906 - accuracy: 0.6612\n",
      "Epoch 00036: val_accuracy did not improve from 0.55330\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.1906 - accuracy: 0.6612 - val_loss: 1.8762 - val_accuracy: 0.5463\n",
      "Epoch 37/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1786 - accuracy: 0.6643\n",
      "Epoch 00037: val_accuracy improved from 0.55330 to 0.55580, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.1786 - accuracy: 0.6643 - val_loss: 1.8279 - val_accuracy: 0.5558\n",
      "Epoch 38/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1488 - accuracy: 0.6738\n",
      "Epoch 00038: val_accuracy improved from 0.55580 to 0.55860, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.1488 - accuracy: 0.6738 - val_loss: 1.8312 - val_accuracy: 0.5586\n",
      "Epoch 39/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1440 - accuracy: 0.6727\n",
      "Epoch 00039: val_accuracy did not improve from 0.55860\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.1440 - accuracy: 0.6727 - val_loss: 1.9371 - val_accuracy: 0.5401\n",
      "Epoch 40/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1225 - accuracy: 0.6804\n",
      "Epoch 00040: val_accuracy did not improve from 0.55860\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.1225 - accuracy: 0.6804 - val_loss: 1.9002 - val_accuracy: 0.5474\n",
      "Epoch 41/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1106 - accuracy: 0.6848\n",
      "Epoch 00041: val_accuracy did not improve from 0.55860\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.1106 - accuracy: 0.6848 - val_loss: 1.9082 - val_accuracy: 0.5491\n",
      "Epoch 42/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0756 - accuracy: 0.6932\n",
      "Epoch 00042: val_accuracy did not improve from 0.55860\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.0756 - accuracy: 0.6932 - val_loss: 1.9418 - val_accuracy: 0.5491\n",
      "Epoch 43/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0694 - accuracy: 0.6904\n",
      "Epoch 00043: val_accuracy did not improve from 0.55860\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 1.0694 - accuracy: 0.6904 - val_loss: 1.8676 - val_accuracy: 0.5498\n",
      "Epoch 44/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0665 - accuracy: 0.6913\n",
      "Epoch 00044: val_accuracy improved from 0.55860 to 0.56410, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.0665 - accuracy: 0.6913 - val_loss: 1.8729 - val_accuracy: 0.5641\n",
      "Epoch 45/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0430 - accuracy: 0.6984\n",
      "Epoch 00045: val_accuracy improved from 0.56410 to 0.57000, saving model to ResNet_SGD_dropout.hdf5\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.0430 - accuracy: 0.6984 - val_loss: 1.7987 - val_accuracy: 0.5700\n",
      "Epoch 46/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0196 - accuracy: 0.7083\n",
      "Epoch 00046: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.0196 - accuracy: 0.7083 - val_loss: 1.9091 - val_accuracy: 0.5607\n",
      "Epoch 47/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.7076\n",
      "Epoch 00047: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 1.0095 - accuracy: 0.7076 - val_loss: 1.8481 - val_accuracy: 0.5613\n",
      "Epoch 48/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9946 - accuracy: 0.7119\n",
      "Epoch 00048: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 138ms/step - loss: 0.9946 - accuracy: 0.7119 - val_loss: 1.9826 - val_accuracy: 0.5440\n",
      "Epoch 49/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9810 - accuracy: 0.7132\n",
      "Epoch 00049: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 0.9810 - accuracy: 0.7132 - val_loss: 1.8563 - val_accuracy: 0.5644\n",
      "Epoch 50/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9704 - accuracy: 0.7191\n",
      "Epoch 00050: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 0.9704 - accuracy: 0.7191 - val_loss: 1.9439 - val_accuracy: 0.5599\n",
      "Epoch 51/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9602 - accuracy: 0.7207\n",
      "Epoch 00051: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 0.9602 - accuracy: 0.7207 - val_loss: 1.9558 - val_accuracy: 0.5590\n",
      "Epoch 52/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9493 - accuracy: 0.7236\n",
      "Epoch 00052: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 0.9493 - accuracy: 0.7236 - val_loss: 1.9376 - val_accuracy: 0.5522\n",
      "Epoch 53/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9425 - accuracy: 0.7251\n",
      "Epoch 00053: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 0.9425 - accuracy: 0.7251 - val_loss: 1.8504 - val_accuracy: 0.5618\n",
      "Epoch 54/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9270 - accuracy: 0.7290\n",
      "Epoch 00054: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 0.9270 - accuracy: 0.7290 - val_loss: 1.8735 - val_accuracy: 0.5700\n",
      "Epoch 55/80\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9167 - accuracy: 0.7285Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.57000\n",
      "391/390 [==============================] - 54s 139ms/step - loss: 0.9167 - accuracy: 0.7285 - val_loss: 1.9976 - val_accuracy: 0.5523\n",
      "Epoch 00055: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# save model after each epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"ResNet_SGD_dropout.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "#hist=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early, checkpoint])\n",
    "hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=80, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "mDkWf-ZwCErp",
    "outputId": "543db6af-9319-4f8a-85a3-b5cdd5f281c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.5845594954864525\n",
      "Recall: 0.57\n",
      "Accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "ytuuMD7mrewp",
    "outputId": "8436fb63-b352-47bb-8206-d629f557be5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBM1STYA2-fY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "num_filters = 32\n",
    "t = Conv2D(kernel_size=2,strides=1,filters=num_filters,padding=\"same\")(inputs)\n",
    "t = ReLU()(t)\n",
    "\n",
    "t = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(t)\n",
    "y = ReLU()(t)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,t])\n",
    "z1 = ReLU()(y)\n",
    "\n",
    "z1 = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(z1)\n",
    "y = ReLU()(z1)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "#y = Dropout(0.5)(y)\n",
    "y = Add()([y,z1])\n",
    "z2 = ReLU()(y)\n",
    "\n",
    "z2 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z2)\n",
    "y = ReLU()(z2)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z2])\n",
    "z3 = ReLU()(y)\n",
    "\n",
    "z3 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z3)\n",
    "y = ReLU()(z3)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "#y = Dropout(0.5)(y)\n",
    "y = Add()([y,z3])\n",
    "z4 = ReLU()(y)\n",
    "\n",
    "z4 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z4)\n",
    "y = ReLU()(z4)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z4])\n",
    "z5 = ReLU()(y)\n",
    "\n",
    "z5 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z5)\n",
    "y = ReLU()(z5)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z5])\n",
    "z6 = ReLU()(y)\n",
    "\n",
    "z6 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z6)\n",
    "y = ReLU()(z6)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "#y = Dropout(0.5)(y)\n",
    "y = Add()([y,z6])\n",
    "z7 = ReLU()(y)\n",
    "\n",
    "z7 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z5)\n",
    "y = ReLU()(z7)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z7])\n",
    "z8 = ReLU()(y)\n",
    "\n",
    "t = AveragePooling2D(4)(z8)\n",
    "t = Flatten()(t)\n",
    "\n",
    "outputs = Dense(100, activation='softmax')(t)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.load_weights('../weights/ResNet_SGD_With_DropOut.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet_sgd_dropout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
