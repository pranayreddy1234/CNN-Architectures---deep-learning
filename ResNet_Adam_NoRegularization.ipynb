{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZ2ZpboW14Da"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Hgza-JDZsh7"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JX6jSDWwZtND"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 50 # iterations over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx5bYvq-ZtQV"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "7mstneybZtTy",
    "outputId": "3359bdec-3712-44c9-db06-cde0a4ad491f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHzHxyG9Ztak"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 3))\n",
    "num_filters = 32\n",
    "t = Conv2D(kernel_size=2,strides=1,filters=num_filters,padding=\"same\")(inputs)\n",
    "t = ReLU()(t)\n",
    "\n",
    "t = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(t)\n",
    "y = ReLU()(t)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,t])\n",
    "z1 = ReLU()(y)\n",
    "\n",
    "z1 = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(z1)\n",
    "y = ReLU()(z1)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z1])\n",
    "z2 = ReLU()(y)\n",
    "\n",
    "z2 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z2)\n",
    "y = ReLU()(z2)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z2])\n",
    "z3 = ReLU()(y)\n",
    "\n",
    "z3 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z3)\n",
    "y = ReLU()(z3)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z3])\n",
    "z4 = ReLU()(y)\n",
    "\n",
    "z4 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z4)\n",
    "y = ReLU()(z4)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z4])\n",
    "z5 = ReLU()(y)\n",
    "\n",
    "z5 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z5)\n",
    "y = ReLU()(z5)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z5])\n",
    "z6 = ReLU()(y)\n",
    "\n",
    "z6 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z6)\n",
    "y = ReLU()(z6)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z6])\n",
    "z7 = ReLU()(y)\n",
    "\n",
    "z7 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z5)\n",
    "y = ReLU()(z7)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z7])\n",
    "z8 = ReLU()(y)\n",
    "\n",
    "t = AveragePooling2D(4)(z8)\n",
    "t = Flatten()(t)\n",
    "\n",
    "outputs = Dense(100, activation='softmax')(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pUUjEJ9IZtga",
    "outputId": "bd69c1c3-fee8-4fc5-c12e-766a764a6544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 32)   416         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 32, 32, 32)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 32)   4128        re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 32, 32, 32)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 32)   4128        re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 32)   0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 32, 32, 32)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 32)   9248        re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 32, 32, 32)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 32)   9248        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 32)   0           max_pooling2d_9[0][0]            \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 32, 32, 32)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   8256        re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 32, 32, 64)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 64)   0           max_pooling2d_10[0][0]           \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 32, 32, 64)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 32, 32, 64)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 64)   0           max_pooling2d_11[0][0]           \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 32, 32, 64)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 32, 32, 128)  0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 128)  65664       re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 128)  0           max_pooling2d_12[0][0]           \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 32, 32, 128)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 128)  65664       re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 256)  131328      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 32, 32, 256)  0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 256)  262400      re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 32, 32, 256)  0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 32, 256)  0           max_pooling2d_15[0][0]           \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 32, 32, 256)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 256)    0           re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16384)        0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          1638500     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,281,220\n",
      "Trainable params: 2,281,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISULFttyQE0d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qD3JUArxQE38"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    #zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C85WMW-QZteX"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate = 0.001,clipvalue = 0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d20_r5-EZtYX",
    "outputId": "fc92b30a-9eec-404d-9e8f-903ac2e543bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-19-a6fc6ab2c66f>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 4.0339 - accuracy: 0.0867\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.17940, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 36s 92ms/step - loss: 4.0339 - accuracy: 0.0867 - val_loss: 3.5179 - val_accuracy: 0.1794\n",
      "Epoch 2/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.4069 - accuracy: 0.1929\n",
      "Epoch 00002: val_accuracy improved from 0.17940 to 0.25600, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 3.4069 - accuracy: 0.1929 - val_loss: 3.0963 - val_accuracy: 0.2560\n",
      "Epoch 3/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.0637 - accuracy: 0.2587\n",
      "Epoch 00003: val_accuracy improved from 0.25600 to 0.31560, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 36s 92ms/step - loss: 3.0637 - accuracy: 0.2587 - val_loss: 2.7936 - val_accuracy: 0.3156\n",
      "Epoch 4/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.7928 - accuracy: 0.3078\n",
      "Epoch 00004: val_accuracy improved from 0.31560 to 0.35210, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 2.7928 - accuracy: 0.3078 - val_loss: 2.6243 - val_accuracy: 0.3521\n",
      "Epoch 5/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5900 - accuracy: 0.3519\n",
      "Epoch 00005: val_accuracy improved from 0.35210 to 0.38780, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 2.5900 - accuracy: 0.3519 - val_loss: 2.4685 - val_accuracy: 0.3878\n",
      "Epoch 6/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4253 - accuracy: 0.3868\n",
      "Epoch 00006: val_accuracy improved from 0.38780 to 0.39790, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 89ms/step - loss: 2.4253 - accuracy: 0.3868 - val_loss: 2.4078 - val_accuracy: 0.3979\n",
      "Epoch 7/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2931 - accuracy: 0.4148\n",
      "Epoch 00007: val_accuracy improved from 0.39790 to 0.43050, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 2.2931 - accuracy: 0.4148 - val_loss: 2.2777 - val_accuracy: 0.4305\n",
      "Epoch 8/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1860 - accuracy: 0.4380\n",
      "Epoch 00008: val_accuracy improved from 0.43050 to 0.43440, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 2.1860 - accuracy: 0.4380 - val_loss: 2.2880 - val_accuracy: 0.4344\n",
      "Epoch 9/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0950 - accuracy: 0.4559\n",
      "Epoch 00009: val_accuracy improved from 0.43440 to 0.46070, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 2.0950 - accuracy: 0.4559 - val_loss: 2.1503 - val_accuracy: 0.4607\n",
      "Epoch 10/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0152 - accuracy: 0.4747\n",
      "Epoch 00010: val_accuracy did not improve from 0.46070\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 2.0152 - accuracy: 0.4747 - val_loss: 2.2419 - val_accuracy: 0.4468\n",
      "Epoch 11/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9555 - accuracy: 0.4874\n",
      "Epoch 00011: val_accuracy did not improve from 0.46070\n",
      "391/390 [==============================] - 35s 89ms/step - loss: 1.9555 - accuracy: 0.4874 - val_loss: 2.1631 - val_accuracy: 0.4570\n",
      "Epoch 12/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8940 - accuracy: 0.5013\n",
      "Epoch 00012: val_accuracy improved from 0.46070 to 0.48450, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.8940 - accuracy: 0.5013 - val_loss: 2.0271 - val_accuracy: 0.4845\n",
      "Epoch 13/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8453 - accuracy: 0.5132\n",
      "Epoch 00013: val_accuracy improved from 0.48450 to 0.49230, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.8453 - accuracy: 0.5132 - val_loss: 2.0560 - val_accuracy: 0.4923\n",
      "Epoch 14/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7989 - accuracy: 0.5254\n",
      "Epoch 00014: val_accuracy did not improve from 0.49230\n",
      "391/390 [==============================] - 35s 89ms/step - loss: 1.7989 - accuracy: 0.5254 - val_loss: 2.0696 - val_accuracy: 0.4819\n",
      "Epoch 15/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7549 - accuracy: 0.5330\n",
      "Epoch 00015: val_accuracy did not improve from 0.49230\n",
      "391/390 [==============================] - 35s 89ms/step - loss: 1.7549 - accuracy: 0.5330 - val_loss: 2.0490 - val_accuracy: 0.4921\n",
      "Epoch 16/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7185 - accuracy: 0.5406\n",
      "Epoch 00016: val_accuracy did not improve from 0.49230\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.7185 - accuracy: 0.5406 - val_loss: 2.0711 - val_accuracy: 0.4896\n",
      "Epoch 17/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6566 - accuracy: 0.5559\n",
      "Epoch 00017: val_accuracy improved from 0.49230 to 0.49950, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.6566 - accuracy: 0.5559 - val_loss: 2.0457 - val_accuracy: 0.4995\n",
      "Epoch 18/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6356 - accuracy: 0.5613\n",
      "Epoch 00018: val_accuracy did not improve from 0.49950\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.6356 - accuracy: 0.5613 - val_loss: 2.1633 - val_accuracy: 0.4748\n",
      "Epoch 19/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6089 - accuracy: 0.5704\n",
      "Epoch 00019: val_accuracy did not improve from 0.49950\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.6089 - accuracy: 0.5704 - val_loss: 2.0477 - val_accuracy: 0.4990\n",
      "Epoch 20/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5674 - accuracy: 0.5766\n",
      "Epoch 00020: val_accuracy did not improve from 0.49950\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.5674 - accuracy: 0.5766 - val_loss: 2.0938 - val_accuracy: 0.4885\n",
      "Epoch 21/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5409 - accuracy: 0.5812\n",
      "Epoch 00021: val_accuracy did not improve from 0.49950\n",
      "391/390 [==============================] - 35s 91ms/step - loss: 1.5409 - accuracy: 0.5812 - val_loss: 2.2363 - val_accuracy: 0.4732\n",
      "Epoch 22/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5165 - accuracy: 0.5860\n",
      "Epoch 00022: val_accuracy improved from 0.49950 to 0.50130, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 1.5165 - accuracy: 0.5860 - val_loss: 2.0934 - val_accuracy: 0.5013\n",
      "Epoch 23/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4768 - accuracy: 0.5957\n",
      "Epoch 00023: val_accuracy improved from 0.50130 to 0.50590, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 1.4768 - accuracy: 0.5957 - val_loss: 2.0629 - val_accuracy: 0.5059\n",
      "Epoch 24/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 0.5999\n",
      "Epoch 00024: val_accuracy did not improve from 0.50590\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.4600 - accuracy: 0.5999 - val_loss: 2.0527 - val_accuracy: 0.5021\n",
      "Epoch 25/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4308 - accuracy: 0.6076\n",
      "Epoch 00025: val_accuracy improved from 0.50590 to 0.50950, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 1.4308 - accuracy: 0.6076 - val_loss: 2.0225 - val_accuracy: 0.5095\n",
      "Epoch 26/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4082 - accuracy: 0.6140\n",
      "Epoch 00026: val_accuracy did not improve from 0.50950\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.4082 - accuracy: 0.6140 - val_loss: 2.0909 - val_accuracy: 0.5077\n",
      "Epoch 27/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3893 - accuracy: 0.6181\n",
      "Epoch 00027: val_accuracy improved from 0.50950 to 0.51060, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 1.3893 - accuracy: 0.6181 - val_loss: 2.0552 - val_accuracy: 0.5106\n",
      "Epoch 28/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3653 - accuracy: 0.6228\n",
      "Epoch 00028: val_accuracy improved from 0.51060 to 0.51560, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 1.3653 - accuracy: 0.6228 - val_loss: 2.0157 - val_accuracy: 0.5156\n",
      "Epoch 29/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3406 - accuracy: 0.6290\n",
      "Epoch 00029: val_accuracy did not improve from 0.51560\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 1.3406 - accuracy: 0.6290 - val_loss: 2.1182 - val_accuracy: 0.5033\n",
      "Epoch 30/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3323 - accuracy: 0.6319\n",
      "Epoch 00030: val_accuracy did not improve from 0.51560\n",
      "391/390 [==============================] - 35s 91ms/step - loss: 1.3323 - accuracy: 0.6319 - val_loss: 2.0853 - val_accuracy: 0.5108\n",
      "Epoch 31/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3034 - accuracy: 0.6403\n",
      "Epoch 00031: val_accuracy did not improve from 0.51560\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 1.3034 - accuracy: 0.6403 - val_loss: 2.0946 - val_accuracy: 0.5129\n",
      "Epoch 32/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2864 - accuracy: 0.6401\n",
      "Epoch 00032: val_accuracy did not improve from 0.51560\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.2864 - accuracy: 0.6401 - val_loss: 2.0718 - val_accuracy: 0.5142\n",
      "Epoch 33/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2772 - accuracy: 0.6403\n",
      "Epoch 00033: val_accuracy did not improve from 0.51560\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.2772 - accuracy: 0.6403 - val_loss: 2.1795 - val_accuracy: 0.5069\n",
      "Epoch 34/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2583 - accuracy: 0.6486\n",
      "Epoch 00034: val_accuracy did not improve from 0.51560\n",
      "391/390 [==============================] - 35s 91ms/step - loss: 1.2583 - accuracy: 0.6486 - val_loss: 2.0746 - val_accuracy: 0.5147\n",
      "Epoch 35/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2383 - accuracy: 0.6554\n",
      "Epoch 00035: val_accuracy improved from 0.51560 to 0.52210, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.2383 - accuracy: 0.6554 - val_loss: 2.0683 - val_accuracy: 0.5221\n",
      "Epoch 36/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2263 - accuracy: 0.6570\n",
      "Epoch 00036: val_accuracy did not improve from 0.52210\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.2263 - accuracy: 0.6570 - val_loss: 2.1197 - val_accuracy: 0.5215\n",
      "Epoch 37/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2055 - accuracy: 0.6609\n",
      "Epoch 00037: val_accuracy did not improve from 0.52210\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.2055 - accuracy: 0.6609 - val_loss: 2.1986 - val_accuracy: 0.5056\n",
      "Epoch 38/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2067 - accuracy: 0.6618\n",
      "Epoch 00038: val_accuracy improved from 0.52210 to 0.52480, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 35s 91ms/step - loss: 1.2067 - accuracy: 0.6618 - val_loss: 2.1207 - val_accuracy: 0.5248\n",
      "Epoch 39/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1709 - accuracy: 0.6725\n",
      "Epoch 00039: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 91ms/step - loss: 1.1709 - accuracy: 0.6725 - val_loss: 2.1561 - val_accuracy: 0.5112\n",
      "Epoch 40/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1676 - accuracy: 0.6719\n",
      "Epoch 00040: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.1676 - accuracy: 0.6719 - val_loss: 2.2127 - val_accuracy: 0.5113\n",
      "Epoch 41/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1697 - accuracy: 0.6721\n",
      "Epoch 00041: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.1697 - accuracy: 0.6721 - val_loss: 2.0977 - val_accuracy: 0.5187\n",
      "Epoch 42/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1369 - accuracy: 0.6781\n",
      "Epoch 00042: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.1369 - accuracy: 0.6781 - val_loss: 2.2584 - val_accuracy: 0.5101\n",
      "Epoch 43/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1340 - accuracy: 0.6804\n",
      "Epoch 00043: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.1340 - accuracy: 0.6804 - val_loss: 2.1783 - val_accuracy: 0.5198\n",
      "Epoch 44/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1132 - accuracy: 0.6834\n",
      "Epoch 00044: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.1132 - accuracy: 0.6834 - val_loss: 2.3478 - val_accuracy: 0.5014\n",
      "Epoch 45/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1058 - accuracy: 0.6858\n",
      "Epoch 00045: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 91ms/step - loss: 1.1058 - accuracy: 0.6858 - val_loss: 2.1291 - val_accuracy: 0.5211\n",
      "Epoch 46/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.6870\n",
      "Epoch 00046: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 90ms/step - loss: 1.0983 - accuracy: 0.6870 - val_loss: 2.1261 - val_accuracy: 0.5234\n",
      "Epoch 47/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.6907\n",
      "Epoch 00047: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 36s 91ms/step - loss: 1.0860 - accuracy: 0.6907 - val_loss: 2.1894 - val_accuracy: 0.5121\n",
      "Epoch 48/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.6928Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.52480\n",
      "391/390 [==============================] - 35s 91ms/step - loss: 1.0747 - accuracy: 0.6928 - val_loss: 2.2308 - val_accuracy: 0.5172\n",
      "Epoch 00048: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# save model after each epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"ResNet_Basic_Adam.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "#hist=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=50, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ytuuMD7mrewp",
    "outputId": "5fe0fd87-faeb-479c-d1ed-632842cb11ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72       100\n",
      "           1       0.72      0.71      0.71       100\n",
      "           2       0.50      0.40      0.44       100\n",
      "           3       0.31      0.24      0.27       100\n",
      "           4       0.29      0.37      0.33       100\n",
      "           5       0.46      0.46      0.46       100\n",
      "           6       0.67      0.62      0.64       100\n",
      "           7       0.53      0.53      0.53       100\n",
      "           8       0.50      0.72      0.59       100\n",
      "           9       0.67      0.61      0.64       100\n",
      "          10       0.39      0.32      0.35       100\n",
      "          11       0.38      0.38      0.38       100\n",
      "          12       0.58      0.63      0.61       100\n",
      "          13       0.42      0.63      0.50       100\n",
      "          14       0.45      0.55      0.49       100\n",
      "          15       0.52      0.43      0.47       100\n",
      "          16       0.46      0.61      0.53       100\n",
      "          17       0.55      0.66      0.60       100\n",
      "          18       0.38      0.45      0.41       100\n",
      "          19       0.62      0.45      0.52       100\n",
      "          20       0.68      0.82      0.74       100\n",
      "          21       0.64      0.58      0.61       100\n",
      "          22       0.35      0.58      0.43       100\n",
      "          23       0.71      0.70      0.71       100\n",
      "          24       0.82      0.69      0.75       100\n",
      "          25       0.45      0.37      0.41       100\n",
      "          26       0.43      0.48      0.45       100\n",
      "          27       0.30      0.51      0.37       100\n",
      "          28       0.64      0.73      0.68       100\n",
      "          29       0.58      0.42      0.49       100\n",
      "          30       0.53      0.38      0.44       100\n",
      "          31       0.63      0.42      0.50       100\n",
      "          32       0.55      0.42      0.47       100\n",
      "          33       0.34      0.57      0.43       100\n",
      "          34       0.63      0.46      0.53       100\n",
      "          35       0.35      0.21      0.26       100\n",
      "          36       0.93      0.53      0.68       100\n",
      "          37       0.38      0.55      0.45       100\n",
      "          38       0.37      0.30      0.33       100\n",
      "          39       0.48      0.56      0.52       100\n",
      "          40       0.61      0.43      0.50       100\n",
      "          41       0.84      0.70      0.77       100\n",
      "          42       0.24      0.77      0.37       100\n",
      "          43       0.63      0.52      0.57       100\n",
      "          44       0.34      0.20      0.25       100\n",
      "          45       0.33      0.51      0.40       100\n",
      "          46       0.39      0.29      0.33       100\n",
      "          47       0.48      0.64      0.55       100\n",
      "          48       0.58      0.91      0.71       100\n",
      "          49       0.57      0.81      0.67       100\n",
      "          50       0.47      0.25      0.33       100\n",
      "          51       0.67      0.33      0.44       100\n",
      "          52       0.52      0.61      0.56       100\n",
      "          53       0.81      0.81      0.81       100\n",
      "          54       0.63      0.72      0.67       100\n",
      "          55       0.26      0.12      0.16       100\n",
      "          56       0.82      0.71      0.76       100\n",
      "          57       0.71      0.46      0.56       100\n",
      "          58       0.66      0.69      0.68       100\n",
      "          59       0.61      0.49      0.54       100\n",
      "          60       0.81      0.75      0.78       100\n",
      "          61       0.55      0.57      0.56       100\n",
      "          62       0.79      0.46      0.58       100\n",
      "          63       0.64      0.52      0.57       100\n",
      "          64       0.57      0.16      0.25       100\n",
      "          65       0.56      0.22      0.32       100\n",
      "          66       0.59      0.58      0.58       100\n",
      "          67       0.48      0.39      0.43       100\n",
      "          68       0.85      0.81      0.83       100\n",
      "          69       0.74      0.67      0.71       100\n",
      "          70       0.61      0.50      0.55       100\n",
      "          71       0.73      0.68      0.70       100\n",
      "          72       0.26      0.18      0.21       100\n",
      "          73       0.39      0.45      0.42       100\n",
      "          74       0.34      0.35      0.34       100\n",
      "          75       0.75      0.81      0.78       100\n",
      "          76       0.69      0.70      0.69       100\n",
      "          77       0.58      0.33      0.42       100\n",
      "          78       0.24      0.33      0.28       100\n",
      "          79       0.52      0.58      0.55       100\n",
      "          80       0.48      0.32      0.38       100\n",
      "          81       0.43      0.61      0.50       100\n",
      "          82       0.93      0.77      0.84       100\n",
      "          83       0.54      0.39      0.45       100\n",
      "          84       0.49      0.43      0.46       100\n",
      "          85       0.65      0.64      0.65       100\n",
      "          86       0.57      0.64      0.60       100\n",
      "          87       0.54      0.57      0.56       100\n",
      "          88       0.34      0.84      0.49       100\n",
      "          89       0.60      0.58      0.59       100\n",
      "          90       0.49      0.55      0.52       100\n",
      "          91       0.76      0.68      0.72       100\n",
      "          92       0.53      0.50      0.51       100\n",
      "          93       0.34      0.25      0.29       100\n",
      "          94       0.80      0.73      0.76       100\n",
      "          95       0.48      0.63      0.55       100\n",
      "          96       0.47      0.31      0.37       100\n",
      "          97       0.53      0.51      0.52       100\n",
      "          98       0.33      0.27      0.30       100\n",
      "          99       0.51      0.54      0.52       100\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.55      0.52      0.52     10000\n",
      "weighted avg       0.55      0.52      0.52     10000\n",
      "\n",
      "Prec: 0.5466103215558665\n",
      "Recall: 0.5248\n",
      "Accuracy: 0.5248\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "print(classification_report(y_true,y_pred))\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "2A3d5PLYFrsL",
    "outputId": "ca920b7b-f0d1-4e3b-f8cc-ea9b766653cd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aBllJ-1Pq1Z"
   },
   "source": [
    "# cell to load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "num_filters = 32\n",
    "t = Conv2D(kernel_size=2,strides=1,filters=num_filters,padding=\"same\")(inputs)\n",
    "t = ReLU()(t)\n",
    "\n",
    "t = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(t)\n",
    "y = ReLU()(t)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,t])\n",
    "z1 = ReLU()(y)\n",
    "\n",
    "z1 = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(z1)\n",
    "y = ReLU()(z1)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z1])\n",
    "z2 = ReLU()(y)\n",
    "\n",
    "z2 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z2)\n",
    "y = ReLU()(z2)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z2])\n",
    "z3 = ReLU()(y)\n",
    "\n",
    "z3 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z3)\n",
    "y = ReLU()(z3)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z3])\n",
    "z4 = ReLU()(y)\n",
    "\n",
    "z4 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z4)\n",
    "y = ReLU()(z4)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z4])\n",
    "z5 = ReLU()(y)\n",
    "\n",
    "z5 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z5)\n",
    "y = ReLU()(z5)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z5])\n",
    "z6 = ReLU()(y)\n",
    "\n",
    "z6 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z6)\n",
    "y = ReLU()(z6)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z6])\n",
    "z7 = ReLU()(y)\n",
    "\n",
    "z7 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z5)\n",
    "y = ReLU()(z7)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z7])\n",
    "z8 = ReLU()(y)\n",
    "\n",
    "t = AveragePooling2D(4)(z8)\n",
    "t = Flatten()(t)\n",
    "\n",
    "outputs = Dense(100, activation='softmax')(t)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.load_weights('../weights/ResNet_Adam_NoRegularization.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet_plain_Adam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
