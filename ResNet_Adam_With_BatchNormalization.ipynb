{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZ2ZpboW14Da"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import ELU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "6Hgza-JDZsh7",
    "outputId": "98263eb8-01e2-4611-de1f-23bed63abe5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JX6jSDWwZtND"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 100 # iterations over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx5bYvq-ZtQV"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "7mstneybZtTy",
    "outputId": "855c9e65-e356-4030-e3af-64d63cb3aee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHzHxyG9Ztak"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 3))\n",
    "num_filters = 20\n",
    "t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\")(inputs)\n",
    "t = ELU()(t)\n",
    "\n",
    "t = Conv2D(kernel_size = (3,3),strides=1,filters = 20, padding = \"same\")(t)\n",
    "t = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(t)\n",
    "y = ELU()(t)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 20, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,t])\n",
    "z1 = ELU()(y)\n",
    "z1 = BatchNormalization()(z1)\n",
    "\n",
    "z1 = Conv2D(kernel_size = (3,3),strides=1,filters = 25, padding = \"same\")(z1)\n",
    "z1 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z1)\n",
    "y = ELU()(z1)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 25, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z1])\n",
    "z2 = ELU()(y)\n",
    "z2 = BatchNormalization()(z2)\n",
    "\n",
    "z2 = Conv2D(kernel_size = (3,3),strides=1,filters = 30, padding = \"same\")(z2)\n",
    "z2 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z2)\n",
    "y = ELU()(z2)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 30, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z2])\n",
    "z3 = ELU()(y)\n",
    "z3 = BatchNormalization()(z3)\n",
    "\n",
    "z3 = Conv2D(kernel_size = (3,3),strides=1,filters = 35, padding = \"same\")(z3)\n",
    "z3 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z3)\n",
    "y = ELU()(z3)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 35, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z3])\n",
    "z4 = ELU()(y)\n",
    "z4 = BatchNormalization()(z4)\n",
    "\n",
    "z4 = Conv2D(kernel_size = (3,3),strides=1,filters = 40, padding = \"same\")(z4)\n",
    "z4 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z4)\n",
    "y = ELU()(z4)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 40, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z4])\n",
    "z5 = ELU()(y)\n",
    "z5 = BatchNormalization()(z5)\n",
    "\n",
    "z5 = Conv2D(kernel_size = (3,3),strides=1,filters = 45, padding = \"same\")(z5)\n",
    "z5 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z5)\n",
    "y = ELU()(z5)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 45, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z5])\n",
    "z6 = ELU()(y)\n",
    "z6 = BatchNormalization()(z6)\n",
    "\n",
    "z6 = Conv2D(kernel_size = (3,3),strides=1,filters = 50, padding = \"same\")(z6)\n",
    "z6 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z6)\n",
    "y = ELU()(z6)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 50, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z6])\n",
    "z7 = ELU()(y)\n",
    "z7 = BatchNormalization()(z7)\n",
    "\n",
    "z7 = Conv2D(kernel_size = (3,3),strides=1,filters = 50, padding = \"same\")(z7)\n",
    "z7 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z7)\n",
    "y = ELU()(z7)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 50, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z7])\n",
    "z8 = ELU()(y)\n",
    "z8 = BatchNormalization()(z8)\n",
    "\n",
    "t = AveragePooling2D(4)(z8)\n",
    "t = Flatten()(t)\n",
    "\n",
    "outputs = Dense(100, activation='softmax')(t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pUUjEJ9IZtga",
    "outputId": "a0c1256d-444b-41ca-c5c8-e84d3514574b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 20)   560         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu (ELU)                       (None, 32, 32, 20)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 20)   3620        elu[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 20)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 32, 32, 20)   0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 20)   80          elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 20)   3620        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 20)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 20)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 32, 32, 20)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 20)   80          elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 25)   4525        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 25)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 32, 32, 25)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 25)   100         elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 25)   5650        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 25)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 25)   0           max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 32, 32, 25)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 25)   100         elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 30)   6780        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 30)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 32, 32, 30)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 30)   120         elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 30)   8130        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 30)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 30)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 32, 32, 30)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 30)   120         elu_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 35)   9485        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 35)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 32, 32, 35)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 35)   140         elu_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 35)   11060       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 35)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 35)   0           max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "elu_8 (ELU)                     (None, 32, 32, 35)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 35)   140         elu_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 40)   12640       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 40)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_9 (ELU)                     (None, 32, 32, 40)   0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 40)   160         elu_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 40)   14440       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 40)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 40)   0           max_pooling2d_9[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "elu_10 (ELU)                    (None, 32, 32, 40)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 40)   160         elu_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 45)   16245       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 32, 32, 45)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_11 (ELU)                    (None, 32, 32, 45)   0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 45)   180         elu_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 45)   18270       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 45)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 45)   0           max_pooling2d_11[0][0]           \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "elu_12 (ELU)                    (None, 32, 32, 45)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 45)   180         elu_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 50)   20300       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 50)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_13 (ELU)                    (None, 32, 32, 50)   0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 50)   200         elu_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 50)   22550       batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 32, 32, 50)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 50)   0           max_pooling2d_13[0][0]           \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "elu_14 (ELU)                    (None, 32, 32, 50)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 50)   200         elu_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 50)   22550       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 50)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_15 (ELU)                    (None, 32, 32, 50)   0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 50)   200         elu_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 50)   22550       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 32, 32, 50)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 50)   0           max_pooling2d_15[0][0]           \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "elu_16 (ELU)                    (None, 32, 32, 50)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 50)   200         elu_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 8, 8, 50)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3200)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          320100      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 525,435\n",
      "Trainable params: 524,255\n",
      "Non-trainable params: 1,180\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "560hcgXjQRxf"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    #zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C85WMW-QZteX"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate = 0.001, clipvalue = 0.7),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d20_r5-EZtYX",
    "outputId": "48abc96a-14ac-4f49-cdd9-061266fb37f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-10-169ec1a6352b>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.6474 - accuracy: 0.1620\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.16760, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 42s 108ms/step - loss: 3.6474 - accuracy: 0.1620 - val_loss: 3.8092 - val_accuracy: 0.1676\n",
      "Epoch 2/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.0277 - accuracy: 0.2610\n",
      "Epoch 00002: val_accuracy improved from 0.16760 to 0.25630, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 42s 107ms/step - loss: 3.0277 - accuracy: 0.2610 - val_loss: 3.2694 - val_accuracy: 0.2563\n",
      "Epoch 3/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.7609 - accuracy: 0.3114\n",
      "Epoch 00003: val_accuracy improved from 0.25630 to 0.27460, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 43s 110ms/step - loss: 2.7609 - accuracy: 0.3114 - val_loss: 3.1134 - val_accuracy: 0.2746\n",
      "Epoch 4/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5738 - accuracy: 0.3492\n",
      "Epoch 00004: val_accuracy improved from 0.27460 to 0.34060, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 2.5738 - accuracy: 0.3492 - val_loss: 2.6923 - val_accuracy: 0.3406\n",
      "Epoch 5/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4359 - accuracy: 0.3774\n",
      "Epoch 00005: val_accuracy did not improve from 0.34060\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 2.4359 - accuracy: 0.3774 - val_loss: 2.8680 - val_accuracy: 0.3182\n",
      "Epoch 6/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3196 - accuracy: 0.4018\n",
      "Epoch 00006: val_accuracy improved from 0.34060 to 0.39020, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 2.3196 - accuracy: 0.4018 - val_loss: 2.4181 - val_accuracy: 0.3902\n",
      "Epoch 7/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2165 - accuracy: 0.4214\n",
      "Epoch 00007: val_accuracy did not improve from 0.39020\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 2.2165 - accuracy: 0.4214 - val_loss: 2.6417 - val_accuracy: 0.3690\n",
      "Epoch 8/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1428 - accuracy: 0.4399\n",
      "Epoch 00008: val_accuracy improved from 0.39020 to 0.41390, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 2.1428 - accuracy: 0.4399 - val_loss: 2.3451 - val_accuracy: 0.4139\n",
      "Epoch 9/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0675 - accuracy: 0.4562\n",
      "Epoch 00009: val_accuracy improved from 0.41390 to 0.44240, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 2.0675 - accuracy: 0.4562 - val_loss: 2.2160 - val_accuracy: 0.4424\n",
      "Epoch 10/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0017 - accuracy: 0.4712\n",
      "Epoch 00010: val_accuracy did not improve from 0.44240\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 2.0017 - accuracy: 0.4712 - val_loss: 2.3105 - val_accuracy: 0.4193\n",
      "Epoch 11/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9399 - accuracy: 0.4874\n",
      "Epoch 00011: val_accuracy did not improve from 0.44240\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.9399 - accuracy: 0.4874 - val_loss: 2.4408 - val_accuracy: 0.4144\n",
      "Epoch 12/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8896 - accuracy: 0.4955\n",
      "Epoch 00012: val_accuracy improved from 0.44240 to 0.45120, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 44s 114ms/step - loss: 1.8896 - accuracy: 0.4955 - val_loss: 2.2061 - val_accuracy: 0.4512\n",
      "Epoch 13/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8488 - accuracy: 0.5038\n",
      "Epoch 00013: val_accuracy did not improve from 0.45120\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.8488 - accuracy: 0.5038 - val_loss: 2.2401 - val_accuracy: 0.4434\n",
      "Epoch 14/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7943 - accuracy: 0.5180\n",
      "Epoch 00014: val_accuracy improved from 0.45120 to 0.46420, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.7943 - accuracy: 0.5180 - val_loss: 2.1402 - val_accuracy: 0.4642\n",
      "Epoch 15/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7662 - accuracy: 0.5229\n",
      "Epoch 00015: val_accuracy did not improve from 0.46420\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.7662 - accuracy: 0.5229 - val_loss: 2.2318 - val_accuracy: 0.4471\n",
      "Epoch 16/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7194 - accuracy: 0.5349\n",
      "Epoch 00016: val_accuracy improved from 0.46420 to 0.47330, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.7194 - accuracy: 0.5349 - val_loss: 2.1210 - val_accuracy: 0.4733\n",
      "Epoch 17/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6950 - accuracy: 0.5401\n",
      "Epoch 00017: val_accuracy improved from 0.47330 to 0.51570, saving model to ResNet_BN_Adam.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.6950 - accuracy: 0.5401 - val_loss: 1.8769 - val_accuracy: 0.5157\n",
      "Epoch 18/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6547 - accuracy: 0.5519\n",
      "Epoch 00018: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.6547 - accuracy: 0.5519 - val_loss: 2.0510 - val_accuracy: 0.4867\n",
      "Epoch 19/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6305 - accuracy: 0.5563\n",
      "Epoch 00019: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.6305 - accuracy: 0.5563 - val_loss: 2.1422 - val_accuracy: 0.4756\n",
      "Epoch 20/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6005 - accuracy: 0.5604\n",
      "Epoch 00020: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.6005 - accuracy: 0.5604 - val_loss: 2.0505 - val_accuracy: 0.4834\n",
      "Epoch 21/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5802 - accuracy: 0.5678\n",
      "Epoch 00021: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.5802 - accuracy: 0.5678 - val_loss: 2.1239 - val_accuracy: 0.4724\n",
      "Epoch 22/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5590 - accuracy: 0.5701\n",
      "Epoch 00022: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.5590 - accuracy: 0.5701 - val_loss: 1.9941 - val_accuracy: 0.5105\n",
      "Epoch 23/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5270 - accuracy: 0.5780\n",
      "Epoch 00023: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.5270 - accuracy: 0.5780 - val_loss: 2.0588 - val_accuracy: 0.4905\n",
      "Epoch 24/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5089 - accuracy: 0.5845\n",
      "Epoch 00024: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.5089 - accuracy: 0.5845 - val_loss: 2.0494 - val_accuracy: 0.4915\n",
      "Epoch 25/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4888 - accuracy: 0.5880\n",
      "Epoch 00025: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.4888 - accuracy: 0.5880 - val_loss: 1.9406 - val_accuracy: 0.5086\n",
      "Epoch 26/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4805 - accuracy: 0.5897\n",
      "Epoch 00026: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.4805 - accuracy: 0.5897 - val_loss: 2.0486 - val_accuracy: 0.4921\n",
      "Epoch 27/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4531 - accuracy: 0.5959Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 1.4531 - accuracy: 0.5959 - val_loss: 2.0228 - val_accuracy: 0.5064\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# save model after each epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"ResNet_BN_Adam.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "#hist=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early])\n",
    "hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=50, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytuuMD7mrewp",
    "outputId": "e3cbc8ce-14a3-4cb4-a078-29b64bd9260b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74       100\n",
      "           1       0.62      0.68      0.65       100\n",
      "           2       0.47      0.37      0.42       100\n",
      "           3       0.36      0.16      0.22       100\n",
      "           4       0.37      0.21      0.27       100\n",
      "           5       0.56      0.42      0.48       100\n",
      "           6       0.47      0.65      0.55       100\n",
      "           7       0.51      0.54      0.52       100\n",
      "           8       0.50      0.69      0.58       100\n",
      "           9       0.64      0.69      0.67       100\n",
      "          10       0.43      0.31      0.36       100\n",
      "          11       0.51      0.31      0.39       100\n",
      "          12       0.56      0.61      0.58       100\n",
      "          13       0.42      0.44      0.43       100\n",
      "          14       0.28      0.58      0.38       100\n",
      "          15       0.46      0.39      0.42       100\n",
      "          16       0.55      0.56      0.55       100\n",
      "          17       0.74      0.69      0.72       100\n",
      "          18       0.57      0.30      0.39       100\n",
      "          19       0.35      0.44      0.39       100\n",
      "          20       0.75      0.81      0.78       100\n",
      "          21       0.71      0.70      0.71       100\n",
      "          22       0.47      0.58      0.52       100\n",
      "          23       0.68      0.72      0.70       100\n",
      "          24       0.91      0.42      0.58       100\n",
      "          25       0.57      0.34      0.42       100\n",
      "          26       0.34      0.60      0.43       100\n",
      "          27       0.31      0.38      0.34       100\n",
      "          28       0.69      0.70      0.70       100\n",
      "          29       0.44      0.57      0.50       100\n",
      "          30       0.50      0.40      0.44       100\n",
      "          31       0.55      0.51      0.53       100\n",
      "          32       0.48      0.44      0.46       100\n",
      "          33       0.44      0.64      0.52       100\n",
      "          34       0.44      0.60      0.51       100\n",
      "          35       0.44      0.14      0.21       100\n",
      "          36       0.81      0.51      0.63       100\n",
      "          37       0.53      0.48      0.50       100\n",
      "          38       0.41      0.39      0.40       100\n",
      "          39       0.53      0.54      0.54       100\n",
      "          40       0.67      0.37      0.48       100\n",
      "          41       0.54      0.79      0.64       100\n",
      "          42       0.33      0.49      0.39       100\n",
      "          43       0.61      0.43      0.51       100\n",
      "          44       0.25      0.21      0.23       100\n",
      "          45       0.37      0.32      0.34       100\n",
      "          46       0.38      0.37      0.37       100\n",
      "          47       0.57      0.62      0.59       100\n",
      "          48       0.46      0.96      0.62       100\n",
      "          49       0.66      0.66      0.66       100\n",
      "          50       0.38      0.31      0.34       100\n",
      "          51       0.49      0.52      0.50       100\n",
      "          52       0.57      0.71      0.63       100\n",
      "          53       0.71      0.75      0.73       100\n",
      "          54       0.71      0.60      0.65       100\n",
      "          55       0.24      0.09      0.13       100\n",
      "          56       0.76      0.71      0.73       100\n",
      "          57       0.67      0.51      0.58       100\n",
      "          58       0.57      0.67      0.62       100\n",
      "          59       0.59      0.47      0.52       100\n",
      "          60       0.71      0.77      0.74       100\n",
      "          61       0.58      0.61      0.59       100\n",
      "          62       0.54      0.71      0.61       100\n",
      "          63       0.43      0.40      0.41       100\n",
      "          64       0.38      0.31      0.34       100\n",
      "          65       0.56      0.28      0.37       100\n",
      "          66       0.50      0.55      0.52       100\n",
      "          67       0.61      0.37      0.46       100\n",
      "          68       0.82      0.72      0.77       100\n",
      "          69       0.74      0.67      0.70       100\n",
      "          70       0.56      0.63      0.59       100\n",
      "          71       0.77      0.50      0.61       100\n",
      "          72       0.32      0.11      0.16       100\n",
      "          73       0.51      0.30      0.38       100\n",
      "          74       0.35      0.34      0.34       100\n",
      "          75       0.52      0.83      0.64       100\n",
      "          76       0.88      0.58      0.70       100\n",
      "          77       0.50      0.35      0.41       100\n",
      "          78       0.29      0.45      0.35       100\n",
      "          79       0.52      0.57      0.55       100\n",
      "          80       0.52      0.22      0.31       100\n",
      "          81       0.46      0.62      0.53       100\n",
      "          82       0.86      0.74      0.80       100\n",
      "          83       0.45      0.45      0.45       100\n",
      "          84       0.51      0.42      0.46       100\n",
      "          85       0.69      0.62      0.65       100\n",
      "          86       0.42      0.51      0.46       100\n",
      "          87       0.43      0.75      0.55       100\n",
      "          88       0.39      0.76      0.51       100\n",
      "          89       0.39      0.69      0.50       100\n",
      "          90       0.57      0.59      0.58       100\n",
      "          91       0.69      0.63      0.66       100\n",
      "          92       0.53      0.42      0.47       100\n",
      "          93       0.42      0.22      0.29       100\n",
      "          94       0.89      0.74      0.81       100\n",
      "          95       0.46      0.67      0.54       100\n",
      "          96       0.59      0.38      0.46       100\n",
      "          97       0.61      0.42      0.50       100\n",
      "          98       0.23      0.39      0.29       100\n",
      "          99       0.41      0.48      0.44       100\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.53      0.52      0.51     10000\n",
      "weighted avg       0.53      0.52      0.51     10000\n",
      "\n",
      "Prec: 0.5326537138214419\n",
      "Recall: 0.5157\n",
      "Accuracy: 0.5157\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "print(classification_report(y_true,y_pred))\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2A3d5PLYFrsL",
    "outputId": "2486f0c0-019b-4dfb-cb14-bd603fb2e5fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aBllJ-1Pq1Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import ELU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "num_filters = 20\n",
    "t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\")(inputs)\n",
    "t = ELU()(t)\n",
    "\n",
    "t = Conv2D(kernel_size = (3,3),strides=1,filters = 20, padding = \"same\")(t)\n",
    "t = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(t)\n",
    "y = ELU()(t)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 20, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,t])\n",
    "z1 = ELU()(y)\n",
    "z1 = BatchNormalization()(z1)\n",
    "\n",
    "z1 = Conv2D(kernel_size = (3,3),strides=1,filters = 25, padding = \"same\")(z1)\n",
    "z1 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z1)\n",
    "y = ELU()(z1)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 25, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z1])\n",
    "z2 = ELU()(y)\n",
    "z2 = BatchNormalization()(z2)\n",
    "\n",
    "z2 = Conv2D(kernel_size = (3,3),strides=1,filters = 30, padding = \"same\")(z2)\n",
    "z2 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z2)\n",
    "y = ELU()(z2)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 30, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z2])\n",
    "z3 = ELU()(y)\n",
    "z3 = BatchNormalization()(z3)\n",
    "\n",
    "z3 = Conv2D(kernel_size = (3,3),strides=1,filters = 35, padding = \"same\")(z3)\n",
    "z3 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z3)\n",
    "y = ELU()(z3)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 35, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z3])\n",
    "z4 = ELU()(y)\n",
    "z4 = BatchNormalization()(z4)\n",
    "\n",
    "z4 = Conv2D(kernel_size = (3,3),strides=1,filters = 40, padding = \"same\")(z4)\n",
    "z4 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z4)\n",
    "y = ELU()(z4)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 40, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z4])\n",
    "z5 = ELU()(y)\n",
    "z5 = BatchNormalization()(z5)\n",
    "\n",
    "z5 = Conv2D(kernel_size = (3,3),strides=1,filters = 45, padding = \"same\")(z5)\n",
    "z5 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z5)\n",
    "y = ELU()(z5)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 45, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z5])\n",
    "z6 = ELU()(y)\n",
    "z6 = BatchNormalization()(z6)\n",
    "\n",
    "z6 = Conv2D(kernel_size = (3,3),strides=1,filters = 50, padding = \"same\")(z6)\n",
    "z6 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z6)\n",
    "y = ELU()(z6)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 50, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z6])\n",
    "z7 = ELU()(y)\n",
    "z7 = BatchNormalization()(z7)\n",
    "\n",
    "z7 = Conv2D(kernel_size = (3,3),strides=1,filters = 50, padding = \"same\")(z7)\n",
    "z7 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(z7)\n",
    "y = ELU()(z7)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 50, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Add()([y,z7])\n",
    "z8 = ELU()(y)\n",
    "z8 = BatchNormalization()(z8)\n",
    "\n",
    "t = AveragePooling2D(4)(z8)\n",
    "t = Flatten()(t)\n",
    "\n",
    "outputs = Dense(100, activation='softmax')(t)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.load_weights('../weights/ResNet_Adam_With_BatchNormalization.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet_adam_batchnorm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
