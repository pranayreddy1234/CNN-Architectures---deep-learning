{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knzX58cKksyy"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "j9c7XR7Ykyeu",
    "outputId": "3eec463f-ed43-4e03-a361-fac3c7f470e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdUhR3KrkyhU"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 50 # iterations over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OaTn5mFqkyjx"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "bH7r7OoLkymi",
    "outputId": "e8e76a59-1096-4108-9278-fef722ca883a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVlI-4CTkyrl"
   },
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_1)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_2)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation='relu')(X)\n",
    "X = Conv2D(64, 3, activation='relu')(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FfeZQTy2kyuJ",
    "outputId": "0e8035c4-cf5e-4dcc-8040-9fe302b2d09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 32)   9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9248        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9248        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 32)   9248        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 32)   1056        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 32)   1056        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 32)   9248        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 32)   1056        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 128)  0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 32)   4128        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 32)   4128        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 32)   4128        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 32)   4128        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 128)  0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 32)   4128        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 192)  0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 30, 30, 32)   55328       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 28, 28, 64)   18496       conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 7, 7, 64)     0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1606144     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          51300       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,908,260\n",
      "Trainable params: 1,908,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Dp1gvLHkyw2"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R56a1ovwky2f"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate = 0.001,clipvalue = 0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1CysqgcCky5R",
    "outputId": "b8bdf0cb-5373-4cd6-baa2-645337d9c288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-10-3bfa54baec03>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "  2/390 [..............................] - ETA: 21s - loss: 4.6060 - accuracy: 0.0195WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0406s vs `on_train_batch_end` time: 0.0670s). Check your callbacks.\n",
      "391/390 [==============================] - ETA: 0s - loss: 4.2203 - accuracy: 0.0500\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12170, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 45s 115ms/step - loss: 4.2203 - accuracy: 0.0500 - val_loss: 3.7385 - val_accuracy: 0.1217\n",
      "Epoch 2/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.6561 - accuracy: 0.1347\n",
      "Epoch 00002: val_accuracy improved from 0.12170 to 0.18810, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 45s 116ms/step - loss: 3.6561 - accuracy: 0.1347 - val_loss: 3.4100 - val_accuracy: 0.1881\n",
      "Epoch 3/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.4134 - accuracy: 0.1785\n",
      "Epoch 00003: val_accuracy improved from 0.18810 to 0.21840, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 45s 116ms/step - loss: 3.4134 - accuracy: 0.1785 - val_loss: 3.2145 - val_accuracy: 0.2184\n",
      "Epoch 4/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.2487 - accuracy: 0.2088\n",
      "Epoch 00004: val_accuracy improved from 0.21840 to 0.24460, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 3.2487 - accuracy: 0.2088 - val_loss: 3.0563 - val_accuracy: 0.2446\n",
      "Epoch 5/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.1081 - accuracy: 0.2364\n",
      "Epoch 00005: val_accuracy improved from 0.24460 to 0.26480, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 117ms/step - loss: 3.1081 - accuracy: 0.2364 - val_loss: 2.9691 - val_accuracy: 0.2648\n",
      "Epoch 6/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.0006 - accuracy: 0.2579\n",
      "Epoch 00006: val_accuracy improved from 0.26480 to 0.29970, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 3.0006 - accuracy: 0.2579 - val_loss: 2.8136 - val_accuracy: 0.2997\n",
      "Epoch 7/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.9102 - accuracy: 0.2763\n",
      "Epoch 00007: val_accuracy improved from 0.29970 to 0.31120, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.9102 - accuracy: 0.2763 - val_loss: 2.7528 - val_accuracy: 0.3112\n",
      "Epoch 8/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.8237 - accuracy: 0.2958\n",
      "Epoch 00008: val_accuracy improved from 0.31120 to 0.32110, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.8237 - accuracy: 0.2958 - val_loss: 2.7219 - val_accuracy: 0.3211\n",
      "Epoch 9/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.7597 - accuracy: 0.3048\n",
      "Epoch 00009: val_accuracy improved from 0.32110 to 0.32310, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.7597 - accuracy: 0.3048 - val_loss: 2.7113 - val_accuracy: 0.3231\n",
      "Epoch 10/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6937 - accuracy: 0.3211\n",
      "Epoch 00010: val_accuracy improved from 0.32310 to 0.35130, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.6937 - accuracy: 0.3211 - val_loss: 2.5666 - val_accuracy: 0.3513\n",
      "Epoch 11/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6341 - accuracy: 0.3309\n",
      "Epoch 00011: val_accuracy improved from 0.35130 to 0.36600, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.6341 - accuracy: 0.3309 - val_loss: 2.5000 - val_accuracy: 0.3660\n",
      "Epoch 12/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5885 - accuracy: 0.3400\n",
      "Epoch 00012: val_accuracy improved from 0.36600 to 0.37020, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.5885 - accuracy: 0.3400 - val_loss: 2.4867 - val_accuracy: 0.3702\n",
      "Epoch 13/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5243 - accuracy: 0.3554\n",
      "Epoch 00013: val_accuracy did not improve from 0.37020\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.5243 - accuracy: 0.3554 - val_loss: 2.4829 - val_accuracy: 0.3698\n",
      "Epoch 14/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4883 - accuracy: 0.3615\n",
      "Epoch 00014: val_accuracy did not improve from 0.37020\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.4883 - accuracy: 0.3615 - val_loss: 2.5146 - val_accuracy: 0.3676\n",
      "Epoch 15/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4494 - accuracy: 0.3694\n",
      "Epoch 00015: val_accuracy improved from 0.37020 to 0.39360, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.4494 - accuracy: 0.3694 - val_loss: 2.3647 - val_accuracy: 0.3936\n",
      "Epoch 16/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4010 - accuracy: 0.3802\n",
      "Epoch 00016: val_accuracy did not improve from 0.39360\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.4010 - accuracy: 0.3802 - val_loss: 2.4044 - val_accuracy: 0.3841\n",
      "Epoch 17/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3645 - accuracy: 0.3905\n",
      "Epoch 00017: val_accuracy improved from 0.39360 to 0.39580, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 119ms/step - loss: 2.3645 - accuracy: 0.3905 - val_loss: 2.3860 - val_accuracy: 0.3958\n",
      "Epoch 18/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3376 - accuracy: 0.3944\n",
      "Epoch 00018: val_accuracy improved from 0.39580 to 0.40370, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 119ms/step - loss: 2.3376 - accuracy: 0.3944 - val_loss: 2.3331 - val_accuracy: 0.4037\n",
      "Epoch 19/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2935 - accuracy: 0.4033\n",
      "Epoch 00019: val_accuracy improved from 0.40370 to 0.40690, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 119ms/step - loss: 2.2935 - accuracy: 0.4033 - val_loss: 2.3178 - val_accuracy: 0.4069\n",
      "Epoch 20/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2688 - accuracy: 0.4115\n",
      "Epoch 00020: val_accuracy did not improve from 0.40690\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.2688 - accuracy: 0.4115 - val_loss: 2.3535 - val_accuracy: 0.4061\n",
      "Epoch 21/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2319 - accuracy: 0.4153\n",
      "Epoch 00021: val_accuracy improved from 0.40690 to 0.41920, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.2319 - accuracy: 0.4153 - val_loss: 2.3028 - val_accuracy: 0.4192\n",
      "Epoch 22/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2141 - accuracy: 0.4195\n",
      "Epoch 00022: val_accuracy improved from 0.41920 to 0.42460, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.2141 - accuracy: 0.4195 - val_loss: 2.2201 - val_accuracy: 0.4246\n",
      "Epoch 23/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1792 - accuracy: 0.4283\n",
      "Epoch 00023: val_accuracy improved from 0.42460 to 0.42470, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.1792 - accuracy: 0.4283 - val_loss: 2.2320 - val_accuracy: 0.4247\n",
      "Epoch 24/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1571 - accuracy: 0.4330\n",
      "Epoch 00024: val_accuracy improved from 0.42470 to 0.43100, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.1571 - accuracy: 0.4330 - val_loss: 2.2197 - val_accuracy: 0.4310\n",
      "Epoch 25/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1369 - accuracy: 0.4368\n",
      "Epoch 00025: val_accuracy did not improve from 0.43100\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.1369 - accuracy: 0.4368 - val_loss: 2.2337 - val_accuracy: 0.4288\n",
      "Epoch 26/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1196 - accuracy: 0.4401\n",
      "Epoch 00026: val_accuracy did not improve from 0.43100\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.1196 - accuracy: 0.4401 - val_loss: 2.2270 - val_accuracy: 0.4308\n",
      "Epoch 27/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0891 - accuracy: 0.4462\n",
      "Epoch 00027: val_accuracy did not improve from 0.43100\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.0891 - accuracy: 0.4462 - val_loss: 2.2497 - val_accuracy: 0.4281\n",
      "Epoch 28/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0696 - accuracy: 0.4518\n",
      "Epoch 00028: val_accuracy improved from 0.43100 to 0.43300, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 119ms/step - loss: 2.0696 - accuracy: 0.4518 - val_loss: 2.1841 - val_accuracy: 0.4330\n",
      "Epoch 29/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0519 - accuracy: 0.4523\n",
      "Epoch 00029: val_accuracy improved from 0.43300 to 0.44980, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.0519 - accuracy: 0.4523 - val_loss: 2.1718 - val_accuracy: 0.4498\n",
      "Epoch 30/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0380 - accuracy: 0.4596\n",
      "Epoch 00030: val_accuracy did not improve from 0.44980\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.0380 - accuracy: 0.4596 - val_loss: 2.2612 - val_accuracy: 0.4309\n",
      "Epoch 31/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0015 - accuracy: 0.4662\n",
      "Epoch 00031: val_accuracy did not improve from 0.44980\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 2.0015 - accuracy: 0.4662 - val_loss: 2.3246 - val_accuracy: 0.4201\n",
      "Epoch 32/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9977 - accuracy: 0.4679\n",
      "Epoch 00032: val_accuracy did not improve from 0.44980\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.9977 - accuracy: 0.4679 - val_loss: 2.2997 - val_accuracy: 0.4223\n",
      "Epoch 33/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9790 - accuracy: 0.4702\n",
      "Epoch 00033: val_accuracy did not improve from 0.44980\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.9790 - accuracy: 0.4702 - val_loss: 2.1229 - val_accuracy: 0.4498\n",
      "Epoch 34/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9657 - accuracy: 0.4737\n",
      "Epoch 00034: val_accuracy improved from 0.44980 to 0.45490, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.9657 - accuracy: 0.4737 - val_loss: 2.1693 - val_accuracy: 0.4549\n",
      "Epoch 35/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9513 - accuracy: 0.4788\n",
      "Epoch 00035: val_accuracy improved from 0.45490 to 0.45580, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.9513 - accuracy: 0.4788 - val_loss: 2.1208 - val_accuracy: 0.4558\n",
      "Epoch 36/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9289 - accuracy: 0.4822\n",
      "Epoch 00036: val_accuracy improved from 0.45580 to 0.46010, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.9289 - accuracy: 0.4822 - val_loss: 2.1155 - val_accuracy: 0.4601\n",
      "Epoch 37/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9168 - accuracy: 0.4849\n",
      "Epoch 00037: val_accuracy did not improve from 0.46010\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.9168 - accuracy: 0.4849 - val_loss: 2.1660 - val_accuracy: 0.4486\n",
      "Epoch 38/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9080 - accuracy: 0.4865\n",
      "Epoch 00038: val_accuracy did not improve from 0.46010\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.9080 - accuracy: 0.4865 - val_loss: 2.2076 - val_accuracy: 0.4443\n",
      "Epoch 39/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8866 - accuracy: 0.4898\n",
      "Epoch 00039: val_accuracy did not improve from 0.46010\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8866 - accuracy: 0.4898 - val_loss: 2.1899 - val_accuracy: 0.4434\n",
      "Epoch 40/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8743 - accuracy: 0.4913\n",
      "Epoch 00040: val_accuracy improved from 0.46010 to 0.46810, saving model to Inception_plain_Adam.hdf5\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8743 - accuracy: 0.4913 - val_loss: 2.0690 - val_accuracy: 0.4681\n",
      "Epoch 41/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8667 - accuracy: 0.4966\n",
      "Epoch 00041: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8667 - accuracy: 0.4966 - val_loss: 2.1969 - val_accuracy: 0.4455\n",
      "Epoch 42/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8478 - accuracy: 0.4983\n",
      "Epoch 00042: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8478 - accuracy: 0.4983 - val_loss: 2.1617 - val_accuracy: 0.4634\n",
      "Epoch 43/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8472 - accuracy: 0.5005\n",
      "Epoch 00043: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8472 - accuracy: 0.5005 - val_loss: 2.1145 - val_accuracy: 0.4590\n",
      "Epoch 44/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8257 - accuracy: 0.5055\n",
      "Epoch 00044: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8257 - accuracy: 0.5055 - val_loss: 2.1350 - val_accuracy: 0.4591\n",
      "Epoch 45/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8129 - accuracy: 0.5096\n",
      "Epoch 00045: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8129 - accuracy: 0.5096 - val_loss: 2.1294 - val_accuracy: 0.4609\n",
      "Epoch 46/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8060 - accuracy: 0.5092\n",
      "Epoch 00046: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8060 - accuracy: 0.5092 - val_loss: 2.1588 - val_accuracy: 0.4590\n",
      "Epoch 47/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8012 - accuracy: 0.5102\n",
      "Epoch 00047: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.8012 - accuracy: 0.5102 - val_loss: 2.1632 - val_accuracy: 0.4584\n",
      "Epoch 48/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7827 - accuracy: 0.5147\n",
      "Epoch 00048: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.7827 - accuracy: 0.5147 - val_loss: 2.1702 - val_accuracy: 0.4597\n",
      "Epoch 49/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7758 - accuracy: 0.5156\n",
      "Epoch 00049: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.7758 - accuracy: 0.5156 - val_loss: 2.1982 - val_accuracy: 0.4555\n",
      "Epoch 50/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7637 - accuracy: 0.5168Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.46810\n",
      "391/390 [==============================] - 46s 118ms/step - loss: 1.7637 - accuracy: 0.5168 - val_loss: 2.1205 - val_accuracy: 0.4614\n",
      "Epoch 00050: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"Inception_plain_Adam.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "#hist=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=50, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "BwjuYCP7ky8U",
    "outputId": "be4cfcf1-22ed-42c7-cdff-5853d6032d2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.4759762613477358\n",
      "Recall: 0.4681\n",
      "Accuracy: 0.4681\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "#print(classification_report(y_true,y_pred))\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "3q9IzqVAkzBx",
    "outputId": "4d393687-1d28-4b74-803e-c5bd2916b017"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66IL0202kzEt"
   },
   "source": [
    "# cell to load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFP8O8f2ky_m"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_1)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_2)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation='relu')(X)\n",
    "X = Conv2D(64, 3, activation='relu')(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "#model = create_model()\n",
    "model.load_weights('../weights/InceptionV2_Adam_NoRegularization.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63dRO1Poky0L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHqwsEywkypr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Inception_plain_adam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
