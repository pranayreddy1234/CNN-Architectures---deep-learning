{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF_VfxDhltWA"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VU7E-0epl10K"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pr-sN0xl13b"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 50 # iterations over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JETz4gNRl16A"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "Dz3pe3F4l1_g",
    "outputId": "2ba26ce5-c357-4d4c-ab5f-ac00c2d0239a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDQmJO9Il2Ca"
   },
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = BatchNormalization()(conv_11)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_2)\n",
    "conv_21 = BatchNormalization()(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation='relu')(X)\n",
    "X = Conv2D(64, 3, activation='relu')(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1vpOfnwjl2Kb",
    "outputId": "8efad23b-0389-4718-e823-e596adf59d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 32)   896         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 32)   128         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 32)   9248        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 32)   9248        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 32)   9248        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 32)   128         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 32)   9248        batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 32, 32)   1056        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 32)   1056        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 32)   128         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 32)   128         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 32)   1056        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 32, 32)   9248        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 32, 32, 32)   9248        batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 32)   128         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 32)   1056        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 128)  0           conv2d_48[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 32)   128         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 32, 32)   7200        batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 128)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 32)   128         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 32)   128         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 32)   4128        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 32)   7200        batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 32, 32, 32)   7200        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 32)   128         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 128)  0           conv2d_57[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 128)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 32)   128         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 32)   128         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 32)   4128        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 192)  0           batch_normalization_25[0][0]     \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 30, 30, 32)   55328       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 28, 28, 64)   18496       conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 7, 7, 64)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3136)         0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1606144     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          51300       dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,909,796\n",
      "Trainable params: 1,909,028\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0vc8YPll2TK"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQE8uUR5l2Qe"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_bxv3_eHl2Ok",
    "outputId": "b99ee73a-a592-4680-c777-c9c6fd725948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 4.3625 - accuracy: 0.0439\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.02580, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 104s 266ms/step - loss: 4.3625 - accuracy: 0.0439 - val_loss: 4.5964 - val_accuracy: 0.0258\n",
      "Epoch 2/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.7740 - accuracy: 0.1196\n",
      "Epoch 00002: val_accuracy improved from 0.02580 to 0.14580, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 3.7740 - accuracy: 0.1196 - val_loss: 3.6424 - val_accuracy: 0.1458\n",
      "Epoch 3/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.5035 - accuracy: 0.1654\n",
      "Epoch 00003: val_accuracy improved from 0.14580 to 0.15060, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 3.5035 - accuracy: 0.1654 - val_loss: 3.6453 - val_accuracy: 0.1506\n",
      "Epoch 4/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.3370 - accuracy: 0.1962\n",
      "Epoch 00004: val_accuracy improved from 0.15060 to 0.20750, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 3.3370 - accuracy: 0.1962 - val_loss: 3.2930 - val_accuracy: 0.2075\n",
      "Epoch 5/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.2176 - accuracy: 0.2178\n",
      "Epoch 00005: val_accuracy improved from 0.20750 to 0.22080, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 3.2176 - accuracy: 0.2178 - val_loss: 3.2244 - val_accuracy: 0.2208\n",
      "Epoch 6/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.1077 - accuracy: 0.2378\n",
      "Epoch 00006: val_accuracy improved from 0.22080 to 0.25030, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 3.1077 - accuracy: 0.2378 - val_loss: 3.0685 - val_accuracy: 0.2503\n",
      "Epoch 7/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.0117 - accuracy: 0.2574\n",
      "Epoch 00007: val_accuracy improved from 0.25030 to 0.27330, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 3.0117 - accuracy: 0.2574 - val_loss: 2.9545 - val_accuracy: 0.2733\n",
      "Epoch 8/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.9246 - accuracy: 0.2728\n",
      "Epoch 00008: val_accuracy improved from 0.27330 to 0.28950, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.9246 - accuracy: 0.2728 - val_loss: 2.8511 - val_accuracy: 0.2895\n",
      "Epoch 9/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.8522 - accuracy: 0.2901\n",
      "Epoch 00009: val_accuracy improved from 0.28950 to 0.30860, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 2.8522 - accuracy: 0.2901 - val_loss: 2.7792 - val_accuracy: 0.3086\n",
      "Epoch 10/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.7918 - accuracy: 0.2993\n",
      "Epoch 00010: val_accuracy improved from 0.30860 to 0.31670, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 2.7918 - accuracy: 0.2993 - val_loss: 2.7178 - val_accuracy: 0.3167\n",
      "Epoch 11/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.7237 - accuracy: 0.3132\n",
      "Epoch 00011: val_accuracy did not improve from 0.31670\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.7237 - accuracy: 0.3132 - val_loss: 2.7955 - val_accuracy: 0.3074\n",
      "Epoch 12/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6721 - accuracy: 0.3265\n",
      "Epoch 00012: val_accuracy did not improve from 0.31670\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.6721 - accuracy: 0.3265 - val_loss: 2.7832 - val_accuracy: 0.3114\n",
      "Epoch 13/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6136 - accuracy: 0.3355\n",
      "Epoch 00013: val_accuracy improved from 0.31670 to 0.33660, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 2.6136 - accuracy: 0.3355 - val_loss: 2.6630 - val_accuracy: 0.3366\n",
      "Epoch 14/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5641 - accuracy: 0.3469\n",
      "Epoch 00014: val_accuracy did not improve from 0.33660\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.5641 - accuracy: 0.3469 - val_loss: 2.6644 - val_accuracy: 0.3352\n",
      "Epoch 15/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5166 - accuracy: 0.3555\n",
      "Epoch 00015: val_accuracy improved from 0.33660 to 0.35210, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.5166 - accuracy: 0.3555 - val_loss: 2.5629 - val_accuracy: 0.3521\n",
      "Epoch 16/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4692 - accuracy: 0.3645\n",
      "Epoch 00016: val_accuracy improved from 0.35210 to 0.35720, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 2.4692 - accuracy: 0.3645 - val_loss: 2.5127 - val_accuracy: 0.3572\n",
      "Epoch 17/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4332 - accuracy: 0.3747\n",
      "Epoch 00017: val_accuracy improved from 0.35720 to 0.38930, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 2.4332 - accuracy: 0.3747 - val_loss: 2.3731 - val_accuracy: 0.3893\n",
      "Epoch 18/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3852 - accuracy: 0.3831\n",
      "Epoch 00018: val_accuracy improved from 0.38930 to 0.40290, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 2.3852 - accuracy: 0.3831 - val_loss: 2.3154 - val_accuracy: 0.4029\n",
      "Epoch 19/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3395 - accuracy: 0.3914\n",
      "Epoch 00019: val_accuracy improved from 0.40290 to 0.41130, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 2.3395 - accuracy: 0.3914 - val_loss: 2.2693 - val_accuracy: 0.4113\n",
      "Epoch 20/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3143 - accuracy: 0.3984\n",
      "Epoch 00020: val_accuracy did not improve from 0.41130\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.3143 - accuracy: 0.3984 - val_loss: 2.3068 - val_accuracy: 0.4004\n",
      "Epoch 21/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2834 - accuracy: 0.4040\n",
      "Epoch 00021: val_accuracy did not improve from 0.41130\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.2834 - accuracy: 0.4040 - val_loss: 2.5545 - val_accuracy: 0.3582\n",
      "Epoch 22/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2447 - accuracy: 0.4098\n",
      "Epoch 00022: val_accuracy improved from 0.41130 to 0.42640, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 2.2447 - accuracy: 0.4098 - val_loss: 2.2057 - val_accuracy: 0.4264\n",
      "Epoch 23/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2197 - accuracy: 0.4189\n",
      "Epoch 00023: val_accuracy did not improve from 0.42640\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.2197 - accuracy: 0.4189 - val_loss: 2.2713 - val_accuracy: 0.4108\n",
      "Epoch 24/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1904 - accuracy: 0.4243\n",
      "Epoch 00024: val_accuracy did not improve from 0.42640\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.1904 - accuracy: 0.4243 - val_loss: 2.2403 - val_accuracy: 0.4246\n",
      "Epoch 25/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1644 - accuracy: 0.4292\n",
      "Epoch 00025: val_accuracy did not improve from 0.42640\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.1644 - accuracy: 0.4292 - val_loss: 2.3406 - val_accuracy: 0.4048\n",
      "Epoch 26/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1326 - accuracy: 0.4347\n",
      "Epoch 00026: val_accuracy improved from 0.42640 to 0.42750, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.1326 - accuracy: 0.4347 - val_loss: 2.1906 - val_accuracy: 0.4275\n",
      "Epoch 27/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1083 - accuracy: 0.4429\n",
      "Epoch 00027: val_accuracy improved from 0.42750 to 0.43120, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.1083 - accuracy: 0.4429 - val_loss: 2.2015 - val_accuracy: 0.4312\n",
      "Epoch 28/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0858 - accuracy: 0.4470\n",
      "Epoch 00028: val_accuracy did not improve from 0.43120\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.0858 - accuracy: 0.4470 - val_loss: 2.2292 - val_accuracy: 0.4226\n",
      "Epoch 29/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0558 - accuracy: 0.4525\n",
      "Epoch 00029: val_accuracy improved from 0.43120 to 0.43860, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.0558 - accuracy: 0.4525 - val_loss: 2.1627 - val_accuracy: 0.4386\n",
      "Epoch 30/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0350 - accuracy: 0.4550\n",
      "Epoch 00030: val_accuracy did not improve from 0.43860\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.0350 - accuracy: 0.4550 - val_loss: 2.1902 - val_accuracy: 0.4342\n",
      "Epoch 31/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0251 - accuracy: 0.4571\n",
      "Epoch 00031: val_accuracy improved from 0.43860 to 0.44930, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 2.0251 - accuracy: 0.4571 - val_loss: 2.0940 - val_accuracy: 0.4493\n",
      "Epoch 32/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9927 - accuracy: 0.4689\n",
      "Epoch 00032: val_accuracy did not improve from 0.44930\n",
      "391/390 [==============================] - 103s 262ms/step - loss: 1.9927 - accuracy: 0.4689 - val_loss: 2.1657 - val_accuracy: 0.4454\n",
      "Epoch 33/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9749 - accuracy: 0.4713\n",
      "Epoch 00033: val_accuracy did not improve from 0.44930\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 1.9749 - accuracy: 0.4713 - val_loss: 2.3357 - val_accuracy: 0.4145\n",
      "Epoch 34/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9545 - accuracy: 0.4755\n",
      "Epoch 00034: val_accuracy improved from 0.44930 to 0.45120, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.9545 - accuracy: 0.4755 - val_loss: 2.1314 - val_accuracy: 0.4512\n",
      "Epoch 35/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9354 - accuracy: 0.4798\n",
      "Epoch 00035: val_accuracy did not improve from 0.45120\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.9354 - accuracy: 0.4798 - val_loss: 2.1284 - val_accuracy: 0.4468\n",
      "Epoch 36/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9137 - accuracy: 0.4840\n",
      "Epoch 00036: val_accuracy improved from 0.45120 to 0.46550, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.9137 - accuracy: 0.4840 - val_loss: 2.0484 - val_accuracy: 0.4655\n",
      "Epoch 37/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9010 - accuracy: 0.4875\n",
      "Epoch 00037: val_accuracy did not improve from 0.46550\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.9010 - accuracy: 0.4875 - val_loss: 2.0486 - val_accuracy: 0.4622\n",
      "Epoch 38/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8809 - accuracy: 0.4930\n",
      "Epoch 00038: val_accuracy improved from 0.46550 to 0.46620, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.8809 - accuracy: 0.4930 - val_loss: 2.0465 - val_accuracy: 0.4662\n",
      "Epoch 39/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8590 - accuracy: 0.4975\n",
      "Epoch 00039: val_accuracy improved from 0.46620 to 0.48200, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.8590 - accuracy: 0.4975 - val_loss: 1.9492 - val_accuracy: 0.4820\n",
      "Epoch 40/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8423 - accuracy: 0.4990\n",
      "Epoch 00040: val_accuracy did not improve from 0.48200\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 1.8423 - accuracy: 0.4990 - val_loss: 2.1202 - val_accuracy: 0.4563\n",
      "Epoch 41/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8298 - accuracy: 0.5034\n",
      "Epoch 00041: val_accuracy did not improve from 0.48200\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.8298 - accuracy: 0.5034 - val_loss: 2.0442 - val_accuracy: 0.4697\n",
      "Epoch 42/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8148 - accuracy: 0.5062\n",
      "Epoch 00042: val_accuracy did not improve from 0.48200\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 1.8148 - accuracy: 0.5062 - val_loss: 2.1212 - val_accuracy: 0.4563\n",
      "Epoch 43/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7944 - accuracy: 0.5122\n",
      "Epoch 00043: val_accuracy did not improve from 0.48200\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.7944 - accuracy: 0.5122 - val_loss: 2.0624 - val_accuracy: 0.4709\n",
      "Epoch 44/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7816 - accuracy: 0.5142\n",
      "Epoch 00044: val_accuracy did not improve from 0.48200\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.7816 - accuracy: 0.5142 - val_loss: 1.9988 - val_accuracy: 0.4775\n",
      "Epoch 45/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7623 - accuracy: 0.5184\n",
      "Epoch 00045: val_accuracy improved from 0.48200 to 0.48810, saving model to inception_SGD_BN.hdf5\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.7623 - accuracy: 0.5184 - val_loss: 1.9774 - val_accuracy: 0.4881\n",
      "Epoch 46/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7479 - accuracy: 0.5217\n",
      "Epoch 00046: val_accuracy did not improve from 0.48810\n",
      "391/390 [==============================] - 103s 264ms/step - loss: 1.7479 - accuracy: 0.5217 - val_loss: 1.9849 - val_accuracy: 0.4792\n",
      "Epoch 47/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7261 - accuracy: 0.5279\n",
      "Epoch 00047: val_accuracy did not improve from 0.48810\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 1.7261 - accuracy: 0.5279 - val_loss: 2.0519 - val_accuracy: 0.4691\n",
      "Epoch 48/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7203 - accuracy: 0.5292\n",
      "Epoch 00048: val_accuracy did not improve from 0.48810\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 1.7203 - accuracy: 0.5292 - val_loss: 2.0542 - val_accuracy: 0.4720\n",
      "Epoch 49/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7018 - accuracy: 0.5345\n",
      "Epoch 00049: val_accuracy did not improve from 0.48810\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 1.7018 - accuracy: 0.5345 - val_loss: 1.9436 - val_accuracy: 0.4863\n",
      "Epoch 50/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6936 - accuracy: 0.5345\n",
      "Epoch 00050: val_accuracy did not improve from 0.48810\n",
      "391/390 [==============================] - 103s 263ms/step - loss: 1.6936 - accuracy: 0.5345 - val_loss: 2.0637 - val_accuracy: 0.4733\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# save model after each epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"inception_SGD_BN.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "#hist=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early, checkpoint])\n",
    "hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=50, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "-NDVZWgCl2Hx",
    "outputId": "f66f8b7d-e557-45b6-eb86-2e6bc63830a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.5259592575257784\n",
      "Recall: 0.4733\n",
      "Accuracy: 0.4733\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "hTbLY-l6l2Fe",
    "outputId": "9f14a74e-a30a-401d-89ab-64d3c94110aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeTiAdRjl19s"
   },
   "source": [
    "# cell to load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = BatchNormalization()(conv_11)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_2)\n",
    "conv_21 = BatchNormalization()(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation='relu')(X)\n",
    "X = Conv2D(64, 3, activation='relu')(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.load_weights('../weights/InceptionV2_SGD_With_BatchNormalization.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Inception_SGD_BN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
