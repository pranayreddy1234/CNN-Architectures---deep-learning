{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZ2ZpboW14Da"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Hgza-JDZsh7"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JX6jSDWwZtND"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 50 # iterations over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx5bYvq-ZtQV"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "7mstneybZtTy",
    "outputId": "2c975d82-9cf0-4b3a-c24a-cd74da6276b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHzHxyG9Ztak"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 3))\n",
    "num_filters = 32\n",
    "t = Conv2D(kernel_size=2,strides=1,filters=num_filters,padding=\"same\")(inputs)\n",
    "t = ReLU()(t)\n",
    "\n",
    "t = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(t)\n",
    "y = ReLU()(t)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,t])\n",
    "z1 = ReLU()(y)\n",
    "\n",
    "z1 = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(z1)\n",
    "y = ReLU()(z1)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z1])\n",
    "z2 = ReLU()(y)\n",
    "\n",
    "z2 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z2)\n",
    "y = ReLU()(z2)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z2])\n",
    "z3 = ReLU()(y)\n",
    "\n",
    "z3 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z3)\n",
    "y = ReLU()(z3)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z3])\n",
    "z4 = ReLU()(y)\n",
    "\n",
    "z4 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z4)\n",
    "y = ReLU()(z4)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z4])\n",
    "z5 = ReLU()(y)\n",
    "\n",
    "z5 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z5)\n",
    "y = ReLU()(z5)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z5])\n",
    "z6 = ReLU()(y)\n",
    "\n",
    "z6 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z6)\n",
    "y = ReLU()(z6)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z6])\n",
    "z7 = ReLU()(y)\n",
    "\n",
    "z7 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z5)\n",
    "y = ReLU()(z7)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z7])\n",
    "z8 = ReLU()(y)\n",
    "\n",
    "t = AveragePooling2D(4)(z8)\n",
    "t = Flatten()(t)\n",
    "\n",
    "outputs = Dense(100, activation='softmax')(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pUUjEJ9IZtga",
    "outputId": "b69ce6fb-695d-48eb-e75c-6192544b76a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 32)   416         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 32, 32, 32)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 32)   4128        re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 32, 32, 32)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 32)   4128        re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 32)   0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 32)   0           dropout_8[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 32, 32, 32)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 32)   9248        re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 32, 32, 32)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 32)   9248        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 32)   0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 32)   0           dropout_9[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 32, 32, 32)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   8256        re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 32, 32, 64)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 64)   0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 32, 32, 64)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 32, 32, 64)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   16448       re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 64)   0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 64)   0           dropout_11[0][0]                 \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 32, 32, 64)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 32, 32, 128)  0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 128)  65664       re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 128)  0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 128)  0           dropout_12[0][0]                 \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 32, 32, 128)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 128)  65664       re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 256)  131328      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 32, 32, 256)  0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 256)  262400      re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 32, 32, 256)  0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 256)  0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 32, 256)  0           dropout_15[0][0]                 \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 32, 32, 256)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 256)    0           re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16384)        0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          1638500     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,281,220\n",
      "Trainable params: 2,281,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EvFHLqZKNIG"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    #zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C85WMW-QZteX"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate = 0.001,clipvalue = 0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d20_r5-EZtYX",
    "outputId": "9044b885-8ef1-4095-dcf7-16e296b4c260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-19-a6fc6ab2c66f>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 4.1928 - accuracy: 0.0652\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.09480, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 83s 213ms/step - loss: 4.1928 - accuracy: 0.0652 - val_loss: 4.0025 - val_accuracy: 0.0948\n",
      "Epoch 2/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.7738 - accuracy: 0.1240\n",
      "Epoch 00002: val_accuracy improved from 0.09480 to 0.14360, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 86s 220ms/step - loss: 3.7738 - accuracy: 0.1240 - val_loss: 3.6974 - val_accuracy: 0.1436\n",
      "Epoch 3/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.6010 - accuracy: 0.1537\n",
      "Epoch 00003: val_accuracy improved from 0.14360 to 0.15090, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 3.6010 - accuracy: 0.1537 - val_loss: 3.6414 - val_accuracy: 0.1509\n",
      "Epoch 4/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.4106 - accuracy: 0.1881\n",
      "Epoch 00004: val_accuracy improved from 0.15090 to 0.20660, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 3.4106 - accuracy: 0.1881 - val_loss: 3.3181 - val_accuracy: 0.2066\n",
      "Epoch 5/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.1821 - accuracy: 0.2310\n",
      "Epoch 00005: val_accuracy improved from 0.20660 to 0.24920, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 3.1821 - accuracy: 0.2310 - val_loss: 3.0947 - val_accuracy: 0.2492\n",
      "Epoch 6/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.0001 - accuracy: 0.2685\n",
      "Epoch 00006: val_accuracy improved from 0.24920 to 0.28170, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 3.0001 - accuracy: 0.2685 - val_loss: 2.9301 - val_accuracy: 0.2817\n",
      "Epoch 7/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.8586 - accuracy: 0.2986\n",
      "Epoch 00007: val_accuracy improved from 0.28170 to 0.31480, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 2.8586 - accuracy: 0.2986 - val_loss: 2.7918 - val_accuracy: 0.3148\n",
      "Epoch 8/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.7459 - accuracy: 0.3175\n",
      "Epoch 00008: val_accuracy improved from 0.31480 to 0.33000, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.7459 - accuracy: 0.3175 - val_loss: 2.6914 - val_accuracy: 0.3300\n",
      "Epoch 9/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6448 - accuracy: 0.3395\n",
      "Epoch 00009: val_accuracy did not improve from 0.33000\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.6448 - accuracy: 0.3395 - val_loss: 2.7821 - val_accuracy: 0.3204\n",
      "Epoch 10/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5522 - accuracy: 0.3611\n",
      "Epoch 00010: val_accuracy improved from 0.33000 to 0.36120, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 2.5522 - accuracy: 0.3611 - val_loss: 2.5577 - val_accuracy: 0.3612\n",
      "Epoch 11/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4718 - accuracy: 0.3749\n",
      "Epoch 00011: val_accuracy improved from 0.36120 to 0.36990, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.4718 - accuracy: 0.3749 - val_loss: 2.5124 - val_accuracy: 0.3699\n",
      "Epoch 12/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3972 - accuracy: 0.3890\n",
      "Epoch 00012: val_accuracy improved from 0.36990 to 0.37430, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.3972 - accuracy: 0.3890 - val_loss: 2.5198 - val_accuracy: 0.3743\n",
      "Epoch 13/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3392 - accuracy: 0.4039\n",
      "Epoch 00013: val_accuracy improved from 0.37430 to 0.38590, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.3392 - accuracy: 0.4039 - val_loss: 2.4466 - val_accuracy: 0.3859\n",
      "Epoch 14/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2610 - accuracy: 0.4225\n",
      "Epoch 00014: val_accuracy improved from 0.38590 to 0.39700, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 2.2610 - accuracy: 0.4225 - val_loss: 2.4212 - val_accuracy: 0.3970\n",
      "Epoch 15/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2221 - accuracy: 0.4277\n",
      "Epoch 00015: val_accuracy improved from 0.39700 to 0.41040, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.2221 - accuracy: 0.4277 - val_loss: 2.3279 - val_accuracy: 0.4104\n",
      "Epoch 16/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1683 - accuracy: 0.4389\n",
      "Epoch 00016: val_accuracy improved from 0.41040 to 0.43170, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.1683 - accuracy: 0.4389 - val_loss: 2.2669 - val_accuracy: 0.4317\n",
      "Epoch 17/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1231 - accuracy: 0.4500\n",
      "Epoch 00017: val_accuracy did not improve from 0.43170\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.1231 - accuracy: 0.4500 - val_loss: 2.2784 - val_accuracy: 0.4280\n",
      "Epoch 18/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0690 - accuracy: 0.4588\n",
      "Epoch 00018: val_accuracy improved from 0.43170 to 0.43260, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.0690 - accuracy: 0.4588 - val_loss: 2.2484 - val_accuracy: 0.4326\n",
      "Epoch 19/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0356 - accuracy: 0.4679\n",
      "Epoch 00019: val_accuracy did not improve from 0.43260\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.0356 - accuracy: 0.4679 - val_loss: 2.3202 - val_accuracy: 0.4269\n",
      "Epoch 20/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0042 - accuracy: 0.4765\n",
      "Epoch 00020: val_accuracy improved from 0.43260 to 0.43980, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 2.0042 - accuracy: 0.4765 - val_loss: 2.2080 - val_accuracy: 0.4398\n",
      "Epoch 21/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9607 - accuracy: 0.4856\n",
      "Epoch 00021: val_accuracy improved from 0.43980 to 0.45000, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.9607 - accuracy: 0.4856 - val_loss: 2.1992 - val_accuracy: 0.4500\n",
      "Epoch 22/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9322 - accuracy: 0.4917\n",
      "Epoch 00022: val_accuracy improved from 0.45000 to 0.46960, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.9322 - accuracy: 0.4917 - val_loss: 2.0930 - val_accuracy: 0.4696\n",
      "Epoch 23/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9017 - accuracy: 0.4968\n",
      "Epoch 00023: val_accuracy did not improve from 0.46960\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.9017 - accuracy: 0.4968 - val_loss: 2.2000 - val_accuracy: 0.4477\n",
      "Epoch 24/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8705 - accuracy: 0.5034\n",
      "Epoch 00024: val_accuracy did not improve from 0.46960\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.8705 - accuracy: 0.5034 - val_loss: 2.0931 - val_accuracy: 0.4656\n",
      "Epoch 25/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8460 - accuracy: 0.5084\n",
      "Epoch 00025: val_accuracy did not improve from 0.46960\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.8460 - accuracy: 0.5084 - val_loss: 2.1230 - val_accuracy: 0.4540\n",
      "Epoch 26/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8221 - accuracy: 0.5164\n",
      "Epoch 00026: val_accuracy did not improve from 0.46960\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.8221 - accuracy: 0.5164 - val_loss: 2.0930 - val_accuracy: 0.4637\n",
      "Epoch 27/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7882 - accuracy: 0.5247\n",
      "Epoch 00027: val_accuracy did not improve from 0.46960\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.7882 - accuracy: 0.5247 - val_loss: 2.1469 - val_accuracy: 0.4605\n",
      "Epoch 28/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7617 - accuracy: 0.5311\n",
      "Epoch 00028: val_accuracy did not improve from 0.46960\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.7617 - accuracy: 0.5311 - val_loss: 2.1015 - val_accuracy: 0.4684\n",
      "Epoch 29/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7382 - accuracy: 0.5328\n",
      "Epoch 00029: val_accuracy improved from 0.46960 to 0.48530, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.7382 - accuracy: 0.5328 - val_loss: 2.0077 - val_accuracy: 0.4853\n",
      "Epoch 30/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7160 - accuracy: 0.5389\n",
      "Epoch 00030: val_accuracy did not improve from 0.48530\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.7160 - accuracy: 0.5389 - val_loss: 2.1140 - val_accuracy: 0.4624\n",
      "Epoch 31/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7037 - accuracy: 0.5385\n",
      "Epoch 00031: val_accuracy did not improve from 0.48530\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.7037 - accuracy: 0.5385 - val_loss: 2.0542 - val_accuracy: 0.4787\n",
      "Epoch 32/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6774 - accuracy: 0.5485\n",
      "Epoch 00032: val_accuracy did not improve from 0.48530\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.6774 - accuracy: 0.5485 - val_loss: 2.0481 - val_accuracy: 0.4804\n",
      "Epoch 33/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6549 - accuracy: 0.5540\n",
      "Epoch 00033: val_accuracy did not improve from 0.48530\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.6549 - accuracy: 0.5540 - val_loss: 2.1159 - val_accuracy: 0.4658\n",
      "Epoch 34/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6420 - accuracy: 0.5585\n",
      "Epoch 00034: val_accuracy improved from 0.48530 to 0.49140, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.6420 - accuracy: 0.5585 - val_loss: 2.0061 - val_accuracy: 0.4914\n",
      "Epoch 35/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6219 - accuracy: 0.5619\n",
      "Epoch 00035: val_accuracy did not improve from 0.49140\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.6219 - accuracy: 0.5619 - val_loss: 2.0536 - val_accuracy: 0.4859\n",
      "Epoch 36/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5980 - accuracy: 0.5668\n",
      "Epoch 00036: val_accuracy did not improve from 0.49140\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.5980 - accuracy: 0.5668 - val_loss: 2.0861 - val_accuracy: 0.4773\n",
      "Epoch 37/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5924 - accuracy: 0.5692\n",
      "Epoch 00037: val_accuracy did not improve from 0.49140\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.5924 - accuracy: 0.5692 - val_loss: 2.0259 - val_accuracy: 0.4849\n",
      "Epoch 38/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5696 - accuracy: 0.5712\n",
      "Epoch 00038: val_accuracy improved from 0.49140 to 0.49850, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.5696 - accuracy: 0.5712 - val_loss: 1.9937 - val_accuracy: 0.4985\n",
      "Epoch 39/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5532 - accuracy: 0.5779\n",
      "Epoch 00039: val_accuracy did not improve from 0.49850\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.5532 - accuracy: 0.5779 - val_loss: 2.0328 - val_accuracy: 0.4925\n",
      "Epoch 40/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5409 - accuracy: 0.5771\n",
      "Epoch 00040: val_accuracy improved from 0.49850 to 0.49920, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.5409 - accuracy: 0.5771 - val_loss: 1.9946 - val_accuracy: 0.4992\n",
      "Epoch 41/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5282 - accuracy: 0.5798\n",
      "Epoch 00041: val_accuracy did not improve from 0.49920\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.5282 - accuracy: 0.5798 - val_loss: 2.0560 - val_accuracy: 0.4894\n",
      "Epoch 42/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5095 - accuracy: 0.5885\n",
      "Epoch 00042: val_accuracy did not improve from 0.49920\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.5095 - accuracy: 0.5885 - val_loss: 2.0727 - val_accuracy: 0.4911\n",
      "Epoch 43/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4979 - accuracy: 0.5869\n",
      "Epoch 00043: val_accuracy did not improve from 0.49920\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.4979 - accuracy: 0.5869 - val_loss: 2.0225 - val_accuracy: 0.4948\n",
      "Epoch 44/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4853 - accuracy: 0.5910\n",
      "Epoch 00044: val_accuracy did not improve from 0.49920\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.4853 - accuracy: 0.5910 - val_loss: 2.3441 - val_accuracy: 0.4622\n",
      "Epoch 45/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4588 - accuracy: 0.5960\n",
      "Epoch 00045: val_accuracy did not improve from 0.49920\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.4588 - accuracy: 0.5960 - val_loss: 2.1214 - val_accuracy: 0.4791\n",
      "Epoch 46/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4650 - accuracy: 0.5970\n",
      "Epoch 00046: val_accuracy did not improve from 0.49920\n",
      "391/390 [==============================] - 87s 223ms/step - loss: 1.4650 - accuracy: 0.5970 - val_loss: 2.0845 - val_accuracy: 0.4810\n",
      "Epoch 47/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4404 - accuracy: 0.6029\n",
      "Epoch 00047: val_accuracy did not improve from 0.49920\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.4404 - accuracy: 0.6029 - val_loss: 1.9836 - val_accuracy: 0.4990\n",
      "Epoch 48/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4402 - accuracy: 0.6025\n",
      "Epoch 00048: val_accuracy improved from 0.49920 to 0.49950, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.4402 - accuracy: 0.6025 - val_loss: 2.0063 - val_accuracy: 0.4995\n",
      "Epoch 49/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4167 - accuracy: 0.6092\n",
      "Epoch 00049: val_accuracy improved from 0.49950 to 0.51570, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.4167 - accuracy: 0.6092 - val_loss: 1.9229 - val_accuracy: 0.5157\n",
      "Epoch 50/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4181 - accuracy: 0.6084\n",
      "Epoch 00050: val_accuracy did not improve from 0.51570\n",
      "391/390 [==============================] - 87s 222ms/step - loss: 1.4181 - accuracy: 0.6084 - val_loss: 1.9720 - val_accuracy: 0.5045\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# save model after each epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"ResNet_Adam_dropout.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "#hist=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=50, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ytuuMD7mrewp",
    "outputId": "65ce183b-993e-45d7-c0aa-84e2a7f11785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       100\n",
      "           1       0.56      0.65      0.60       100\n",
      "           2       0.43      0.40      0.41       100\n",
      "           3       0.36      0.20      0.26       100\n",
      "           4       0.30      0.24      0.27       100\n",
      "           5       0.47      0.41      0.44       100\n",
      "           6       0.54      0.52      0.53       100\n",
      "           7       0.56      0.50      0.53       100\n",
      "           8       0.49      0.76      0.59       100\n",
      "           9       0.58      0.57      0.57       100\n",
      "          10       0.34      0.36      0.35       100\n",
      "          11       0.58      0.26      0.36       100\n",
      "          12       0.51      0.56      0.53       100\n",
      "          13       0.49      0.45      0.47       100\n",
      "          14       0.44      0.39      0.41       100\n",
      "          15       0.57      0.29      0.38       100\n",
      "          16       0.40      0.64      0.49       100\n",
      "          17       0.76      0.52      0.62       100\n",
      "          18       0.49      0.38      0.43       100\n",
      "          19       0.61      0.36      0.45       100\n",
      "          20       0.66      0.82      0.73       100\n",
      "          21       0.64      0.70      0.67       100\n",
      "          22       0.46      0.54      0.50       100\n",
      "          23       0.76      0.63      0.69       100\n",
      "          24       0.84      0.57      0.68       100\n",
      "          25       0.35      0.30      0.32       100\n",
      "          26       0.59      0.47      0.52       100\n",
      "          27       0.39      0.32      0.35       100\n",
      "          28       0.67      0.70      0.68       100\n",
      "          29       0.51      0.46      0.48       100\n",
      "          30       0.49      0.50      0.50       100\n",
      "          31       0.44      0.50      0.47       100\n",
      "          32       0.50      0.41      0.45       100\n",
      "          33       0.35      0.56      0.43       100\n",
      "          34       0.61      0.43      0.50       100\n",
      "          35       0.36      0.21      0.26       100\n",
      "          36       0.79      0.50      0.61       100\n",
      "          37       0.47      0.60      0.53       100\n",
      "          38       0.36      0.27      0.31       100\n",
      "          39       0.65      0.46      0.54       100\n",
      "          40       0.44      0.45      0.44       100\n",
      "          41       0.77      0.79      0.78       100\n",
      "          42       0.38      0.63      0.47       100\n",
      "          43       0.73      0.40      0.52       100\n",
      "          44       0.30      0.27      0.28       100\n",
      "          45       0.30      0.42      0.35       100\n",
      "          46       0.26      0.29      0.27       100\n",
      "          47       0.58      0.45      0.51       100\n",
      "          48       0.62      0.84      0.71       100\n",
      "          49       0.70      0.60      0.65       100\n",
      "          50       0.30      0.21      0.25       100\n",
      "          51       0.39      0.50      0.44       100\n",
      "          52       0.42      0.77      0.54       100\n",
      "          53       0.74      0.69      0.72       100\n",
      "          54       0.65      0.55      0.60       100\n",
      "          55       0.22      0.14      0.17       100\n",
      "          56       0.76      0.71      0.74       100\n",
      "          57       0.62      0.60      0.61       100\n",
      "          58       0.72      0.70      0.71       100\n",
      "          59       0.53      0.41      0.46       100\n",
      "          60       0.80      0.67      0.73       100\n",
      "          61       0.48      0.68      0.56       100\n",
      "          62       0.58      0.56      0.57       100\n",
      "          63       0.34      0.55      0.42       100\n",
      "          64       0.43      0.22      0.29       100\n",
      "          65       0.36      0.24      0.29       100\n",
      "          66       0.66      0.46      0.54       100\n",
      "          67       0.41      0.48      0.44       100\n",
      "          68       0.74      0.85      0.79       100\n",
      "          69       0.70      0.64      0.67       100\n",
      "          70       0.61      0.52      0.56       100\n",
      "          71       0.70      0.52      0.60       100\n",
      "          72       0.28      0.13      0.18       100\n",
      "          73       0.47      0.40      0.43       100\n",
      "          74       0.27      0.36      0.31       100\n",
      "          75       0.66      0.74      0.70       100\n",
      "          76       0.67      0.78      0.72       100\n",
      "          77       0.31      0.36      0.33       100\n",
      "          78       0.18      0.51      0.27       100\n",
      "          79       0.54      0.59      0.56       100\n",
      "          80       0.33      0.34      0.34       100\n",
      "          81       0.48      0.57      0.52       100\n",
      "          82       0.81      0.81      0.81       100\n",
      "          83       0.52      0.36      0.43       100\n",
      "          84       0.63      0.38      0.48       100\n",
      "          85       0.66      0.70      0.68       100\n",
      "          86       0.66      0.48      0.55       100\n",
      "          87       0.53      0.61      0.56       100\n",
      "          88       0.59      0.69      0.64       100\n",
      "          89       0.52      0.65      0.58       100\n",
      "          90       0.42      0.64      0.50       100\n",
      "          91       0.57      0.60      0.59       100\n",
      "          92       0.51      0.37      0.43       100\n",
      "          93       0.31      0.33      0.32       100\n",
      "          94       0.68      0.88      0.77       100\n",
      "          95       0.66      0.46      0.54       100\n",
      "          96       0.46      0.42      0.44       100\n",
      "          97       0.55      0.54      0.54       100\n",
      "          98       0.38      0.19      0.25       100\n",
      "          99       0.26      0.49      0.34       100\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.52      0.50      0.50     10000\n",
      "weighted avg       0.52      0.50      0.50     10000\n",
      "\n",
      "Prec: 0.52100732250736\n",
      "Recall: 0.5045\n",
      "Accuracy: 0.5045\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "print(classification_report(y_true,y_pred))\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "2A3d5PLYFrsL",
    "outputId": "f2be6a8d-8511-4575-d7c6-369482aa0fb6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aBllJ-1Pq1Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "num_filters = 32\n",
    "t = Conv2D(kernel_size=2,strides=1,filters=num_filters,padding=\"same\")(inputs)\n",
    "t = ReLU()(t)\n",
    "\n",
    "t = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(t)\n",
    "y = ReLU()(t)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,t])\n",
    "z1 = ReLU()(y)\n",
    "\n",
    "z1 = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(z1)\n",
    "y = ReLU()(z1)\n",
    "y = Conv2D(kernel_size = (3,3),strides=1,filters = 32, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z1])\n",
    "z2 = ReLU()(y)\n",
    "\n",
    "z2 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z2)\n",
    "y = ReLU()(z2)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z2])\n",
    "z3 = ReLU()(y)\n",
    "\n",
    "z3 = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(z3)\n",
    "y = ReLU()(z3)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 64, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z3])\n",
    "z4 = ReLU()(y)\n",
    "\n",
    "z4 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z4)\n",
    "y = ReLU()(z4)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z4])\n",
    "z5 = ReLU()(y)\n",
    "\n",
    "z5 = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(z5)\n",
    "y = ReLU()(z5)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 128, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z5])\n",
    "z6 = ReLU()(y)\n",
    "\n",
    "z6 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z6)\n",
    "y = ReLU()(z6)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z6])\n",
    "z7 = ReLU()(y)\n",
    "\n",
    "z7 = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(z5)\n",
    "y = ReLU()(z7)\n",
    "y = Conv2D(kernel_size = (2,2),strides=1,filters = 256, padding = \"same\")(y)\n",
    "y = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Add()([y,z7])\n",
    "z8 = ReLU()(y)\n",
    "\n",
    "t = AveragePooling2D(4)(z8)\n",
    "t = Flatten()(t)\n",
    "\n",
    "outputs = Dense(100, activation='softmax')(t)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.load_weights('../weights/ResNet_Adam_With_DropOut.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": " resnet_Adam_Dropout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
