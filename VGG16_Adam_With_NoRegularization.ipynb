{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3ehSwCoJHA6"
   },
   "outputs": [],
   "source": [
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.layers import ELU\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cx3J75qjJL17"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTf_xlkRJL4u"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 50 # iterations over dataset\n",
    "elu_alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Enf6v70UJL7_"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "Xdnhsa2UJMD9",
    "outputId": "5d8266c4-6596-4a9c-91fa-598e8bd757b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBkrkxe1JMJ8"
   },
   "outputs": [],
   "source": [
    "initializer = keras.initializers.HeNormal()\n",
    "#layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n-hj2gyzW3js",
    "outputId": "7f11e770-4032-4337-9773-508a58ac7456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "elu_79 (ELU)                 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "elu_80 (ELU)                 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "elu_81 (ELU)                 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "elu_82 (ELU)                 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "elu_83 (ELU)                 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "elu_84 (ELU)                 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "elu_85 (ELU)                 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "elu_86 (ELU)                 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_87 (ELU)                 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_88 (ELU)                 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_89 (ELU)                 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_90 (ELU)                 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_91 (ELU)                 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "elu_92 (ELU)                 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "elu_93 (ELU)                 (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "elu_94 (ELU)                 (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               204900    \n",
      "=================================================================\n",
      "Total params: 20,166,564\n",
      "Trainable params: 20,166,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building the sequential model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = input_shape,filters=64,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=2048))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dense(units=2048))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dense(units=100, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3JOyIFlJMBG"
   },
   "outputs": [],
   "source": [
    "#initial_learning_rate = 0.1\n",
    "#lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "     #initial_learning_rate,\n",
    "    #  decay_steps=1000,\n",
    "    #  decay_rate=0.96,\n",
    "    #  staircase=True)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate = 0.001, clipnorm = 0.6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "zJnkIr_e-CIu",
    "outputId": "d5446b55-d5f2-438b-c82d-4e14ff0fd0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "checkpoint = ModelCheckpoint('VGG_Adam_Plain.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XUQ5ghfGJL-9",
    "outputId": "5f01c3d9-32fa-4048-843f-1d270e31cc45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 4.6088 - accuracy: 0.0135\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.02960, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 4.6086 - accuracy: 0.0135 - val_loss: 4.4143 - val_accuracy: 0.0296\n",
      "Epoch 2/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 4.2953 - accuracy: 0.0320\n",
      "Epoch 00002: val_accuracy improved from 0.02960 to 0.03790, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 4.2952 - accuracy: 0.0321 - val_loss: 4.2204 - val_accuracy: 0.0379\n",
      "Epoch 3/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 4.1496 - accuracy: 0.0429\n",
      "Epoch 00003: val_accuracy improved from 0.03790 to 0.05440, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 4.1494 - accuracy: 0.0430 - val_loss: 4.0385 - val_accuracy: 0.0544\n",
      "Epoch 4/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 3.9923 - accuracy: 0.0600\n",
      "Epoch 00004: val_accuracy improved from 0.05440 to 0.06830, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 3.9923 - accuracy: 0.0600 - val_loss: 3.9180 - val_accuracy: 0.0683\n",
      "Epoch 5/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 3.8381 - accuracy: 0.0837\n",
      "Epoch 00005: val_accuracy improved from 0.06830 to 0.09380, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 3.8379 - accuracy: 0.0837 - val_loss: 3.8081 - val_accuracy: 0.0938\n",
      "Epoch 6/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 3.6676 - accuracy: 0.1068\n",
      "Epoch 00006: val_accuracy improved from 0.09380 to 0.11130, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 3.6676 - accuracy: 0.1069 - val_loss: 3.7156 - val_accuracy: 0.1113\n",
      "Epoch 7/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 3.5090 - accuracy: 0.1300\n",
      "Epoch 00007: val_accuracy improved from 0.11130 to 0.14060, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 3.5095 - accuracy: 0.1299 - val_loss: 3.4757 - val_accuracy: 0.1406\n",
      "Epoch 8/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 3.3505 - accuracy: 0.1568\n",
      "Epoch 00008: val_accuracy improved from 0.14060 to 0.16500, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 3.3501 - accuracy: 0.1569 - val_loss: 3.2932 - val_accuracy: 0.1650\n",
      "Epoch 9/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 3.5482 - accuracy: 0.1876\n",
      "Epoch 00009: val_accuracy improved from 0.16500 to 0.17450, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 3.5477 - accuracy: 0.1876 - val_loss: 3.2948 - val_accuracy: 0.1745\n",
      "Epoch 10/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 3.0059 - accuracy: 0.2191\n",
      "Epoch 00010: val_accuracy improved from 0.17450 to 0.22450, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 3.0055 - accuracy: 0.2191 - val_loss: 3.0071 - val_accuracy: 0.2245\n",
      "Epoch 11/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.8413 - accuracy: 0.2519\n",
      "Epoch 00011: val_accuracy improved from 0.22450 to 0.24730, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 2.8411 - accuracy: 0.2520 - val_loss: 2.8811 - val_accuracy: 0.2473\n",
      "Epoch 12/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.6596 - accuracy: 0.2869\n",
      "Epoch 00012: val_accuracy improved from 0.24730 to 0.26990, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 2.6599 - accuracy: 0.2867 - val_loss: 2.8028 - val_accuracy: 0.2699\n",
      "Epoch 13/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.4805 - accuracy: 0.3274\n",
      "Epoch 00013: val_accuracy improved from 0.26990 to 0.29440, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 2.4800 - accuracy: 0.3276 - val_loss: 2.6991 - val_accuracy: 0.2944\n",
      "Epoch 14/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.2809 - accuracy: 0.3696\n",
      "Epoch 00014: val_accuracy improved from 0.29440 to 0.32100, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 2.2810 - accuracy: 0.3697 - val_loss: 2.6012 - val_accuracy: 0.3210\n",
      "Epoch 15/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.0979 - accuracy: 0.4100\n",
      "Epoch 00015: val_accuracy improved from 0.32100 to 0.34630, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.0977 - accuracy: 0.4100 - val_loss: 2.5323 - val_accuracy: 0.3463\n",
      "Epoch 16/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.9162 - accuracy: 0.4511\n",
      "Epoch 00016: val_accuracy improved from 0.34630 to 0.36010, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.9164 - accuracy: 0.4511 - val_loss: 2.5336 - val_accuracy: 0.3601\n",
      "Epoch 17/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.7292 - accuracy: 0.4970\n",
      "Epoch 00017: val_accuracy improved from 0.36010 to 0.37500, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 1.7292 - accuracy: 0.4971 - val_loss: 2.5950 - val_accuracy: 0.3750\n",
      "Epoch 18/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.5776 - accuracy: 0.5364\n",
      "Epoch 00018: val_accuracy improved from 0.37500 to 0.38450, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.5772 - accuracy: 0.5365 - val_loss: 2.5715 - val_accuracy: 0.3845\n",
      "Epoch 19/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.4230 - accuracy: 0.5774\n",
      "Epoch 00019: val_accuracy improved from 0.38450 to 0.38510, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.4228 - accuracy: 0.5773 - val_loss: 2.7040 - val_accuracy: 0.3851\n",
      "Epoch 20/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.6856 - accuracy: 0.6181\n",
      "Epoch 00020: val_accuracy improved from 0.38510 to 0.39440, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 1.6850 - accuracy: 0.6180 - val_loss: 2.7356 - val_accuracy: 0.3944\n",
      "Epoch 21/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 16.9630 - accuracy: 0.6474\n",
      "Epoch 00021: val_accuracy improved from 0.39440 to 0.40550, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 16.9375 - accuracy: 0.6474 - val_loss: 2.7655 - val_accuracy: 0.4055\n",
      "Epoch 22/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 16.7793 - accuracy: 0.6821\n",
      "Epoch 00022: val_accuracy did not improve from 0.40550\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 16.7544 - accuracy: 0.6821 - val_loss: 2.8715 - val_accuracy: 0.4018\n",
      "Epoch 23/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.9711 - accuracy: 0.7101\n",
      "Epoch 00023: val_accuracy did not improve from 0.40550\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.9715 - accuracy: 0.7100 - val_loss: 2.8298 - val_accuracy: 0.4055\n",
      "Epoch 24/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.8759 - accuracy: 0.7328\n",
      "Epoch 00024: val_accuracy improved from 0.40550 to 0.40830, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.8760 - accuracy: 0.7329 - val_loss: 3.0583 - val_accuracy: 0.4083\n",
      "Epoch 25/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.7896 - accuracy: 0.7588\n",
      "Epoch 00025: val_accuracy improved from 0.40830 to 0.40850, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.7897 - accuracy: 0.7588 - val_loss: 3.1230 - val_accuracy: 0.4085\n",
      "Epoch 26/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.7355 - accuracy: 0.7739\n",
      "Epoch 00026: val_accuracy improved from 0.40850 to 0.41440, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.7360 - accuracy: 0.7737 - val_loss: 3.2580 - val_accuracy: 0.4144\n",
      "Epoch 27/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.6824 - accuracy: 0.7926\n",
      "Epoch 00027: val_accuracy improved from 0.41440 to 0.41720, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.6826 - accuracy: 0.7926 - val_loss: 3.2770 - val_accuracy: 0.4172\n",
      "Epoch 28/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.6453 - accuracy: 0.8053\n",
      "Epoch 00028: val_accuracy did not improve from 0.41720\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.6453 - accuracy: 0.8053 - val_loss: 3.1615 - val_accuracy: 0.4160\n",
      "Epoch 29/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.5961 - accuracy: 0.8202\n",
      "Epoch 00029: val_accuracy did not improve from 0.41720\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.5963 - accuracy: 0.8202 - val_loss: 3.4768 - val_accuracy: 0.4107\n",
      "Epoch 30/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.8300\n",
      "Epoch 00030: val_accuracy did not improve from 0.41720\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.5613 - accuracy: 0.8300 - val_loss: 3.5144 - val_accuracy: 0.4166\n",
      "Epoch 31/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.8369\n",
      "Epoch 00031: val_accuracy did not improve from 0.41720\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.5410 - accuracy: 0.8369 - val_loss: 3.5320 - val_accuracy: 0.4149\n",
      "Epoch 32/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.5690 - accuracy: 0.8465\n",
      "Epoch 00032: val_accuracy did not improve from 0.41720\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 0.5686 - accuracy: 0.8466 - val_loss: 3.6750 - val_accuracy: 0.4163\n",
      "Epoch 33/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.5046 - accuracy: 0.8507\n",
      "Epoch 00033: val_accuracy improved from 0.41720 to 0.41820, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.5044 - accuracy: 0.8508 - val_loss: 3.6556 - val_accuracy: 0.4182\n",
      "Epoch 34/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 6.4843 - accuracy: 0.8609\n",
      "Epoch 00034: val_accuracy did not improve from 0.41820\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 6.4751 - accuracy: 0.8608 - val_loss: 3.7022 - val_accuracy: 0.4135\n",
      "Epoch 35/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.5018 - accuracy: 0.8648\n",
      "Epoch 00035: val_accuracy improved from 0.41820 to 0.41970, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.5016 - accuracy: 0.8648 - val_loss: 3.6869 - val_accuracy: 0.4197\n",
      "Epoch 36/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.4634 - accuracy: 0.8692\n",
      "Epoch 00036: val_accuracy improved from 0.41970 to 0.42020, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.4634 - accuracy: 0.8692 - val_loss: 3.9621 - val_accuracy: 0.4202\n",
      "Epoch 37/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.8743\n",
      "Epoch 00037: val_accuracy did not improve from 0.42020\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.4615 - accuracy: 0.8743 - val_loss: 3.6536 - val_accuracy: 0.4167\n",
      "Epoch 38/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8802\n",
      "Epoch 00038: val_accuracy did not improve from 0.42020\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.4082 - accuracy: 0.8802 - val_loss: 3.9622 - val_accuracy: 0.4170\n",
      "Epoch 39/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.6677 - accuracy: 0.8787\n",
      "Epoch 00039: val_accuracy did not improve from 0.42020\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.6673 - accuracy: 0.8787 - val_loss: 3.9106 - val_accuracy: 0.4064\n",
      "Epoch 40/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.4016 - accuracy: 0.8861\n",
      "Epoch 00040: val_accuracy did not improve from 0.42020\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.4017 - accuracy: 0.8860 - val_loss: 3.8462 - val_accuracy: 0.4190\n",
      "Epoch 41/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3766 - accuracy: 0.8899\n",
      "Epoch 00041: val_accuracy did not improve from 0.42020\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.3764 - accuracy: 0.8900 - val_loss: 4.1601 - val_accuracy: 0.4074\n",
      "Epoch 42/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3941 - accuracy: 0.8953\n",
      "Epoch 00042: val_accuracy improved from 0.42020 to 0.42170, saving model to VGG_Adam_Plain.hdf5\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.3943 - accuracy: 0.8953 - val_loss: 4.0772 - val_accuracy: 0.4217\n",
      "Epoch 43/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3965 - accuracy: 0.8923\n",
      "Epoch 00043: val_accuracy did not improve from 0.42170\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.3962 - accuracy: 0.8923 - val_loss: 3.8791 - val_accuracy: 0.4158\n",
      "Epoch 44/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3565 - accuracy: 0.8979\n",
      "Epoch 00044: val_accuracy did not improve from 0.42170\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.3563 - accuracy: 0.8978 - val_loss: 4.0770 - val_accuracy: 0.4068\n",
      "Epoch 45/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3447 - accuracy: 0.9004\n",
      "Epoch 00045: val_accuracy did not improve from 0.42170\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.3444 - accuracy: 0.9005 - val_loss: 4.0413 - val_accuracy: 0.4195\n",
      "Epoch 46/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.9035\n",
      "Epoch 00046: val_accuracy did not improve from 0.42170\n",
      "391/391 [==============================] - 22s 55ms/step - loss: 0.3323 - accuracy: 0.9036 - val_loss: 4.1596 - val_accuracy: 0.4168\n",
      "Epoch 47/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.9071\n",
      "Epoch 00047: val_accuracy did not improve from 0.42170\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.3194 - accuracy: 0.9070 - val_loss: 4.2583 - val_accuracy: 0.4185\n",
      "Epoch 48/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3296 - accuracy: 0.9073\n",
      "Epoch 00048: val_accuracy did not improve from 0.42170\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.3300 - accuracy: 0.9072 - val_loss: 4.2263 - val_accuracy: 0.4208\n",
      "Epoch 49/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3363 - accuracy: 0.9074\n",
      "Epoch 00049: val_accuracy did not improve from 0.42170\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.3363 - accuracy: 0.9074 - val_loss: 4.1112 - val_accuracy: 0.4210\n",
      "Epoch 50/50\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.3160 - accuracy: 0.9117\n",
      "Epoch 00050: val_accuracy did not improve from 0.42170\n",
      "391/391 [==============================] - 21s 55ms/step - loss: 0.3165 - accuracy: 0.9116 - val_loss: 4.4581 - val_accuracy: 0.4108\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "# history=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "#                     steps_per_epoch = len(x_train) / 128, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "hKbldP9lJfI4",
    "outputId": "47d325b1-9e63-4eef-b7e7-7b9dfb42b9af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.4557957523455909\n",
      "Recall: 0.4108\n",
      "Accuracy: 0.4108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "pqfbpy9AJfMZ",
    "outputId": "991fd400-7aef-44fe-db6f-e6e1eb83f5d8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEt6YxfvJfQY"
   },
   "source": [
    "# cell to load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.layers import ELU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#building the sequential model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = input_shape,filters=64,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=2048))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dense(units=2048))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dense(units=100, activation=\"softmax\"))\n",
    "\n",
    "model.load_weights('../weights/VGG16_Adam_With_NoRegularization.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG_Adam_plain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
