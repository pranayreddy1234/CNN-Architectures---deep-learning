{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSR_RhEsrkZK"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLFDpYqrtI_I"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyUUgSUmtJFS"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 100 # iterations over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPpMfUbDtyag"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "0SDNtSWTtJLE",
    "outputId": "01fc5cfc-e581-4e10-ccc7-252ebe05acb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0U8-z7OtJOI"
   },
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_2 = Dropout(0.3)(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Dropout(0.3)(conv_3)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "conv_2 = Dropout(0.3)(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "conv_3 = Dropout(0.3)(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_4 = Dropout(0.3)(conv_4)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "#conv_1 = Dropout(0.5)(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "conv_21 = Dropout(0.3)(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_4 = Dropout(0.3)(conv_4)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(64, 3, activation=LeakyReLU(0.3))(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(256, activation=LeakyReLU(0.3))(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CkpOxoRBtJRM",
    "outputId": "ec187479-2e00-458e-f0d0-c1d844e79337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 32, 32, 32)   896         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 32, 32, 32)   9248        conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 32, 32, 32)   9248        conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 32, 32, 32)   0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 32, 32, 32)   0           max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 32, 32, 32)   9248        dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 32, 32, 32)   9248        conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 32, 32, 32)   9248        conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 32, 32, 32)   1056        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 32, 32, 32)   9248        conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 32, 32, 32)   1056        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 32, 32, 32)   0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 32, 32, 32)   0           conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 32, 32, 32)   0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 32, 32, 32)   0           max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 32, 32, 32)   9248        dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 32, 32, 32)   9248        dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 32, 32, 32)   1056        dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 32)   1056        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 32, 32, 128)  0           conv2d_212[0][0]                 \n",
      "                                                                 conv2d_214[0][0]                 \n",
      "                                                                 conv2d_215[0][0]                 \n",
      "                                                                 conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 32, 32, 32)   4128        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 32, 32, 32)   7200        conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 32, 32, 32)   0           conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 32, 32, 32)   7200        dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 32, 32, 32)   4128        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 32, 32, 32)   7200        conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 32, 32, 32)   7200        conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 32, 32, 128)  0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 32, 32, 32)   0           conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 32, 32, 32)   0           conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 32, 32, 32)   4128        max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 32, 32, 32)   4128        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 32, 32, 32)   7200        dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 32, 32, 32)   7200        dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 32, 32, 32)   0           conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 32, 32, 32)   0           conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 32, 32, 128)  0           conv2d_221[0][0]                 \n",
      "                                                                 conv2d_224[0][0]                 \n",
      "                                                                 dropout_76[0][0]                 \n",
      "                                                                 dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 32, 32, 32)   4128        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 32, 32, 32)   4128        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 32, 32, 32)   9248        conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 32, 32, 32)   3104        conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 32, 32, 128)  0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 32, 32, 32)   4128        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 32, 32, 32)   3104        conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 32, 32, 32)   3104        conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 32, 32, 32)   0           conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 32, 32, 32)   3104        conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 32, 32, 32)   4128        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 32, 32, 32)   0           conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 32, 32, 192)  0           conv2d_229[0][0]                 \n",
      "                                                                 conv2d_230[0][0]                 \n",
      "                                                                 dropout_78[0][0]                 \n",
      "                                                                 conv2d_233[0][0]                 \n",
      "                                                                 conv2d_234[0][0]                 \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 30, 30, 32)   55328       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 28, 28, 64)   18496       conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 64)     0           conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 3136)         0           average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          803072      flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 100)          25700       dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,079,588\n",
      "Trainable params: 1,079,588\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xM-8AL3WtJUJ"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3_Y76v4tJWy"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate = 0.001,clipvalue = 0.5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HExRxSUFtJcf",
    "outputId": "ec929bca-ffce-4cd4-afa9-fcf737738bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.9352 - accuracy: 0.0989\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.15260, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 68s 174ms/step - loss: 3.9352 - accuracy: 0.0989 - val_loss: 3.6308 - val_accuracy: 0.1526\n",
      "Epoch 2/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.3008 - accuracy: 0.2014\n",
      "Epoch 00002: val_accuracy improved from 0.15260 to 0.24050, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 3.3008 - accuracy: 0.2014 - val_loss: 3.1405 - val_accuracy: 0.2405\n",
      "Epoch 3/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.0207 - accuracy: 0.2545\n",
      "Epoch 00003: val_accuracy improved from 0.24050 to 0.24130, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 3.0207 - accuracy: 0.2545 - val_loss: 3.2918 - val_accuracy: 0.2413\n",
      "Epoch 4/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.8150 - accuracy: 0.2971\n",
      "Epoch 00004: val_accuracy improved from 0.24130 to 0.25550, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 2.8150 - accuracy: 0.2971 - val_loss: 3.2179 - val_accuracy: 0.2555\n",
      "Epoch 5/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6652 - accuracy: 0.3253\n",
      "Epoch 00005: val_accuracy improved from 0.25550 to 0.34820, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 2.6652 - accuracy: 0.3253 - val_loss: 2.6187 - val_accuracy: 0.3482\n",
      "Epoch 6/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5390 - accuracy: 0.3542\n",
      "Epoch 00006: val_accuracy did not improve from 0.34820\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 2.5390 - accuracy: 0.3542 - val_loss: 3.1738 - val_accuracy: 0.2837\n",
      "Epoch 7/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4279 - accuracy: 0.3756\n",
      "Epoch 00007: val_accuracy improved from 0.34820 to 0.36230, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 2.4279 - accuracy: 0.3756 - val_loss: 2.5647 - val_accuracy: 0.3623\n",
      "Epoch 8/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3399 - accuracy: 0.3911\n",
      "Epoch 00008: val_accuracy did not improve from 0.36230\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 2.3399 - accuracy: 0.3911 - val_loss: 2.7286 - val_accuracy: 0.3540\n",
      "Epoch 9/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2426 - accuracy: 0.4101\n",
      "Epoch 00009: val_accuracy improved from 0.36230 to 0.37070, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 2.2426 - accuracy: 0.4101 - val_loss: 2.6285 - val_accuracy: 0.3707\n",
      "Epoch 10/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1788 - accuracy: 0.4274\n",
      "Epoch 00010: val_accuracy improved from 0.37070 to 0.41460, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 2.1788 - accuracy: 0.4274 - val_loss: 2.3674 - val_accuracy: 0.4146\n",
      "Epoch 11/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1090 - accuracy: 0.4424\n",
      "Epoch 00011: val_accuracy did not improve from 0.41460\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 2.1090 - accuracy: 0.4424 - val_loss: 2.3426 - val_accuracy: 0.4137\n",
      "Epoch 12/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0388 - accuracy: 0.4542\n",
      "Epoch 00012: val_accuracy did not improve from 0.41460\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 2.0388 - accuracy: 0.4542 - val_loss: 2.7579 - val_accuracy: 0.3699\n",
      "Epoch 13/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9990 - accuracy: 0.4668\n",
      "Epoch 00013: val_accuracy improved from 0.41460 to 0.43640, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.9990 - accuracy: 0.4668 - val_loss: 2.3019 - val_accuracy: 0.4364\n",
      "Epoch 14/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9580 - accuracy: 0.4758\n",
      "Epoch 00014: val_accuracy did not improve from 0.43640\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 1.9580 - accuracy: 0.4758 - val_loss: 2.6128 - val_accuracy: 0.3964\n",
      "Epoch 15/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9106 - accuracy: 0.4853\n",
      "Epoch 00015: val_accuracy did not improve from 0.43640\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 1.9106 - accuracy: 0.4853 - val_loss: 2.3979 - val_accuracy: 0.4163\n",
      "Epoch 16/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8850 - accuracy: 0.4928\n",
      "Epoch 00016: val_accuracy did not improve from 0.43640\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 1.8850 - accuracy: 0.4928 - val_loss: 2.6877 - val_accuracy: 0.3934\n",
      "Epoch 17/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8582 - accuracy: 0.4962\n",
      "Epoch 00017: val_accuracy improved from 0.43640 to 0.43960, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.8582 - accuracy: 0.4962 - val_loss: 2.2987 - val_accuracy: 0.4396\n",
      "Epoch 18/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8105 - accuracy: 0.5087\n",
      "Epoch 00018: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.8105 - accuracy: 0.5087 - val_loss: 2.8426 - val_accuracy: 0.3824\n",
      "Epoch 19/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7963 - accuracy: 0.5096\n",
      "Epoch 00019: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 1.7963 - accuracy: 0.5096 - val_loss: 2.5482 - val_accuracy: 0.4175\n",
      "Epoch 20/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7809 - accuracy: 0.5154\n",
      "Epoch 00020: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.7809 - accuracy: 0.5154 - val_loss: 2.6541 - val_accuracy: 0.4047\n",
      "Epoch 21/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7397 - accuracy: 0.5222\n",
      "Epoch 00021: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 1.7397 - accuracy: 0.5222 - val_loss: 2.5977 - val_accuracy: 0.4084\n",
      "Epoch 22/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7174 - accuracy: 0.5277\n",
      "Epoch 00022: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.7174 - accuracy: 0.5277 - val_loss: 2.5853 - val_accuracy: 0.4286\n",
      "Epoch 23/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6918 - accuracy: 0.5359\n",
      "Epoch 00023: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.6918 - accuracy: 0.5359 - val_loss: 2.7226 - val_accuracy: 0.4116\n",
      "Epoch 24/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6779 - accuracy: 0.5353\n",
      "Epoch 00024: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.6779 - accuracy: 0.5353 - val_loss: 2.4835 - val_accuracy: 0.4332\n",
      "Epoch 25/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6597 - accuracy: 0.5433\n",
      "Epoch 00025: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.6597 - accuracy: 0.5433 - val_loss: 2.4661 - val_accuracy: 0.4334\n",
      "Epoch 26/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6374 - accuracy: 0.5483\n",
      "Epoch 00026: val_accuracy did not improve from 0.43960\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.6374 - accuracy: 0.5483 - val_loss: 2.6520 - val_accuracy: 0.4280\n",
      "Epoch 27/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6279 - accuracy: 0.5499\n",
      "Epoch 00027: val_accuracy improved from 0.43960 to 0.44990, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 1.6279 - accuracy: 0.5499 - val_loss: 2.4023 - val_accuracy: 0.4499\n",
      "Epoch 28/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6064 - accuracy: 0.5542\n",
      "Epoch 00028: val_accuracy did not improve from 0.44990\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 1.6064 - accuracy: 0.5542 - val_loss: 2.8240 - val_accuracy: 0.4126\n",
      "Epoch 29/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5980 - accuracy: 0.5569\n",
      "Epoch 00029: val_accuracy improved from 0.44990 to 0.48990, saving model to Inception_Adam_dropout.hdf5\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.5980 - accuracy: 0.5569 - val_loss: 2.1643 - val_accuracy: 0.4899\n",
      "Epoch 30/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5844 - accuracy: 0.5593\n",
      "Epoch 00030: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 67s 173ms/step - loss: 1.5844 - accuracy: 0.5593 - val_loss: 2.2542 - val_accuracy: 0.4794\n",
      "Epoch 31/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5770 - accuracy: 0.5595\n",
      "Epoch 00031: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.5770 - accuracy: 0.5595 - val_loss: 2.6507 - val_accuracy: 0.4327\n",
      "Epoch 32/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5548 - accuracy: 0.5667\n",
      "Epoch 00032: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.5548 - accuracy: 0.5667 - val_loss: 2.6111 - val_accuracy: 0.4371\n",
      "Epoch 33/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5418 - accuracy: 0.5693\n",
      "Epoch 00033: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.5418 - accuracy: 0.5693 - val_loss: 2.8222 - val_accuracy: 0.4166\n",
      "Epoch 34/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5359 - accuracy: 0.5712\n",
      "Epoch 00034: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 1.5359 - accuracy: 0.5712 - val_loss: 2.5004 - val_accuracy: 0.4539\n",
      "Epoch 35/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5203 - accuracy: 0.5757\n",
      "Epoch 00035: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 67s 172ms/step - loss: 1.5203 - accuracy: 0.5757 - val_loss: 2.3278 - val_accuracy: 0.4814\n",
      "Epoch 36/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4999 - accuracy: 0.5811\n",
      "Epoch 00036: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.4999 - accuracy: 0.5811 - val_loss: 3.0748 - val_accuracy: 0.4036\n",
      "Epoch 37/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5025 - accuracy: 0.5803\n",
      "Epoch 00037: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.5025 - accuracy: 0.5803 - val_loss: 2.6964 - val_accuracy: 0.4350\n",
      "Epoch 38/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4940 - accuracy: 0.5821\n",
      "Epoch 00038: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.4940 - accuracy: 0.5821 - val_loss: 2.5331 - val_accuracy: 0.4588\n",
      "Epoch 39/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4811 - accuracy: 0.5847Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.48990\n",
      "391/390 [==============================] - 68s 173ms/step - loss: 1.4811 - accuracy: 0.5847 - val_loss: 2.7508 - val_accuracy: 0.4389\n",
      "Epoch 00039: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# save model after each epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"Inception_Adam_dropout.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "#hist=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=100, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "cZyDDol-tJaZ",
    "outputId": "71eea807-93d8-43dc-f9fe-b934b1a55572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.5755537106710966\n",
      "Recall: 0.4899\n",
      "Accuracy: 0.4899\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "#print(classification_report(y_true,y_pred))\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "dYSYhItwtJIZ",
    "outputId": "d5ec8161-8421-4eaf-c41b-e7156cbf8f95"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeVhVVdfAf5tBZhCEcE7NFAdEAYGcTSw15yE1y9CytF57rbfBhq/MsrRsHi2nLAPNcsrUnIccwVkUFUUREUTmGe5d3x/3SqgMFwRBOb/nuY/nnr332utcD2edvfbeaykRQUNDQ0Oj5mJW1QpoaGhoaFQtmiHQ0NDQqOFohkBDQ0OjhqMZAg0NDY0ajmYINDQ0NGo4miHQ0NDQqOFohkCjRqGUWqiUet/EulFKqcDK1klDo6rRDIGGhoZGDUczBBoadyBKKYuq1kHj7kEzBBrVDqNL5hWl1BGlVIZSap5Syl0ptVYplaaU2qiUci5Uf6BS6rhSKlkptVUp1apQWQel1AFjuyWA9Q199VdKHTK23aWUameijo8opQ4qpVKVUtFKqWk3lHcxyks2lgcZz9sopT5RSp1XSqUopXYaz/VQSl0s4ncINB5PU0otU0r9opRKBYKUUn5Kqd3GPmKVUl8rpWoVat9GKbVBKZWolIpTSr2hlKqrlMpUStUpVM9bKXVFKWVpyrVr3H1ohkCjujIM6A20AAYAa4E3ADcM9+0LAEqpFkAwMMVY9hewWilVy/hQXAH8DLgAvxnlYmzbAZgPPAvUAeYAq5RSVibolwGMBWoDjwCTlFKDjXLvNer7lVGn9sAhY7vZgA/QyajTq4DexN9kELDM2OdiQAe8CLgCDwC9gOeMOjgAG4F1QH2gObBJRC4DW4FHC8l9AggRkTwT9dC4y9AMgUZ15SsRiRORGGAHsFdEDopINrAc6GCsNxJYIyIbjA+y2YANhgdtAGAJfC4ieSKyDNhfqI9ngDkisldEdCLyE5BjbFciIrJVRI6KiF5EjmAwRt2NxY8BG0Uk2NjvVRE5pJQyA8YD/xWRGGOfu0Qkx8TfZLeIrDD2mSUiYSKyR0TyRSQKgyG7pkN/4LKIfCIi2SKSJiJ7jWU/AY8DKKXMgdEYjKVGDUUzBBrVlbhCx1lFfLc3HtcHzl8rEBE9EA00MJbFyPWRFc8XOr4X+J/RtZKslEoGGhnblYhSyl8ptcXoUkkBJmJ4M8coI7KIZq4YXFNFlZlC9A06tFBK/amUumx0F31ggg4AK4HWSqmmGEZdKSKyr5w6adwFaIZA407nEoYHOgBKKYXhIRgDxAINjOeu0bjQcTQwQ0RqF/rYikiwCf3+CqwCGomIE/A9cK2faOC+ItokANnFlGUAtoWuwxyDW6kwN4YK/g44CdwvIo4YXGeFdWhWlOLGUdVSDKOCJ9BGAzUezRBo3OksBR5RSvUyTnb+D4N7ZxewG8gHXlBKWSqlhgJ+hdr+CEw0vt0rpZSdcRLYwYR+HYBEEclWSvlhcAddYzEQqJR6VClloZSqo5RqbxytzAc+VUrVV0qZK6UeMM5JnAKsjf1bAm8Bpc1VOACpQLpSygOYVKjsT6CeUmqKUspKKeWglPIvVL4ICAIGohmCGo9mCDTuaEQkAsOb7VcY3rgHAANEJFdEcoGhGB54iRjmE/4o1DYUmAB8DSQBZ4x1TeE5YLpSKg14G4NBuib3AtAPg1FKxDBR7GUsfhk4imGuIhGYBZiJSIpR5lwMo5kM4LpVREXwMgYDlIbBqC0ppEMaBrfPAOAycBroWaj8HwyT1AdEpLC7TKMGorTENBoaNROl1GbgVxGZW9W6aFQtmiHQ0KiBKKU6AhswzHGkVbU+GlWL5hrS0KhhKKV+wrDHYIpmBDRAGxFoaGho1Hi0EYGGhoZGDeeOC1zl6uoqTZo0qWo1NDQ0NO4owsLCEkTkxr0pwB1oCJo0aUJoaGhVq6GhoaFxR6GUKnaZsOYa0tDQ0KjhaIZAQ0NDo4ZT6YbAuI3+oFLqzyLKrJRSS5RSZ5RSe5VSTSpbHw0NDQ2N67kdcwT/BU4AjkWUPQUkiUhzpdQoDNvtR94GnTQqiLy8PC5evEh2dnZVq6JRjbC2tqZhw4ZYWmq5bu4EKtUQKKUaYkjaMQN4qYgqg4BpxuNlwNdKKSXa5oY7hosXL+Lg4ECTJk24PsinRk1FRLh69SoXL16kadOmVa2OhglUtmvoc0rOwNQAY4x1EckHUjBkiroOpdQzSqlQpVTolStXKktXjXKQnZ1NnTp1NCOgUYBSijp16mijxDuISjMESqn+QLyIhN2qLBH5QUR8RcTXza3IZbAaVYhmBDRuRLsn7iwqc0TQGRiolIoCQoAHlVK/3FAnBkMSEZRSFoATcLUylDmTdIbZ+2eTna+9pWhoaGgUptIMgYi8LiINRaQJMArYLCKP31BtFfCk8Xi4sU6lzA9cyrjET+E/ceTKkcoQr1HFrFixAqUUJ0+erGpVNDTuOG77PgKl1HSl1EDj13lAHaXUGQyTyVMrq9/297RHoQiN03Yl340EBwfTpUsXgoNNyTJZPnQ6XaXJ1tCoSm6LIRCRrSLS33j8toisMh5ni8gIEWkuIn4icraydHCs5YiHiwdhcbc8ZaFRzUhPT2fnzp3MmzePkJAQwPDQfvnll2nbti3t2rXjq6++AmD//v106tQJLy8v/Pz8SEtLY+HChfznP/8pkNe/f3+2bt0KgL29Pf/73//w8vJi9+7dTJ8+nY4dO9K2bVueeeYZrg1gz5w5Q2BgIF5eXnh7exMZGcnYsWNZsWJFgdwxY8awcuXK2/SraGiYzh0Xa+hW8HH34bdTv5Gry6WWea2qVueu493Vxwm/lFqhMlvXd+SdAW1KrLNy5Ur69OlDixYtqFOnDmFhYezbt4+oqCgOHTqEhYUFiYmJ5ObmMnLkSJYsWULHjh1JTU3FxsamRNkZGRn4+/vzySefGPRp3Zq3334bgCeeeII///yTAQMGMGbMGKZOncqQIUPIzs5Gr9fz1FNP8dlnnzF48GBSUlLYtWsXP/30U8X8MBoaFUiNCjHhW9eXHF0OxxKOVbUqGhVIcHAwo0aNAmDUqFEEBwezceNGnn32WSwsDO86Li4uREREUK9ePTp27AiAo6NjQXlxmJubM2zYsILvW7Zswd/fH09PTzZv3szx48dJS0sjJiaGIUOGAIbNVLa2tnTv3p3Tp09z5coVgoODGTZsWKn9aWhUBTXqrvS+xxuA0LhQvN29q1ibu4/S3twrg8TERDZv3szRo0dRSqHT6VBKFTzsTcHCwgK9/t+tLoXXv1tbW2Nubl5w/rnnniM0NJRGjRoxbdq0UtfKjx07ll9++YWQkBAWLFhQxqvT0Lg91KgRgbO1M81rN9fmCe4ili1bxhNPPMH58+eJiooiOjqapk2b4uXlxZw5c8jPzwcMBqNly5bExsayf/9+ANLS0sjPz6dJkyYcOnQIvV5PdHQ0+/btK7Kvaw99V1dX0tPTWbZsGQAODg40bNiwYD4gJyeHzMxMAIKCgvj8888Bg1tJQ6M6UqMMAYCvuy8H4w+Sp8+ralU0KoDg4OACl8w1hg0bRmxsLI0bN6Zdu3Z4eXnx66+/UqtWLZYsWcLkyZPx8vKid+/eZGdn07lzZ5o2bUrr1q154YUX8PYuerRYu3ZtJkyYQNu2bXn44YevG3X8/PPPfPnll7Rr145OnTpx+fJlANzd3WnVqhXjxo2rvB9BQ+MWueNyFvv6+sqtJKZZF7WOV7a9wuJ+i2nn1q4CNauZnDhxglatWlW1GtWWzMxMPD09OXDgAE5OTlWtzm1FuzeqF0qpMBHxLaqsRo4IAM09pFHpbNy4kVatWjF58uQaZwQ07ixq1GQxgKuNK00cmxAaF8q4ttpwXaPyCAwM5Pz5YrMDamhUG2rciAAMy0gPxB1Ap9d2impoaGjUSEPg4+5Del46EUkRVa2KhoaGRpVTIw2BNk+goaGh8S81yhBcWyFV164uDe0bEnpZC0CnoaGhUWMMQfq2bUQG9iY/MREwzBOExYehl+KSp2ncCfTs2ZP169dfd+7zzz9n0qRJxbbp0aMH15Yg9+vXj+Tk5JvqTJs2jdmzZ5fY94oVKwgPDy/4/vbbb7Nx48ayqF8iU6ZMoUGDBtftetbQqAxqjCGwcHMjLyaG9M2bAcM8QUpOCmeSz1SxZhq3wujRowsijl4jJCSE0aNHm9T+r7/+onbt2uXq+0ZDMH36dAIDA8sl60b0ej3Lly+nUaNGbNu2rUJkFsW1ndcaNZsaYwisWrXCsn590jYY3ti0eYK7g+HDh7NmzRpyc3MBiIqK4tKlS3Tt2pVJkybh6+tLmzZteOedd4ps36RJExISEgCYMWMGLVq0oEuXLkRE/LuQ4Mcff6Rjx454eXkxbNgwMjMz2bVrF6tWreKVV16hffv2REZGEhQUVBB2YtOmTXTo0AFPT0/Gjx9PTk5OQX/vvPMO3t7eeHp6FptIZ+vWrbRp04ZJkyZdl2MhLi6OIUOG4OXlhZeXF7t27QJg0aJFBbuon3jiCYDr9AFDSO1rsrt27crAgQMLwl4MHjwYHx8f2rRpww8//FDQZt26dXh7e+Pl5UWvXr3Q6/Xcf//9XMsdrtfrad68OVou8TubGrOPQCmFQ+9Akn4NRpeeQQP7BtS1q0vo5VBGe5j29qhRCmunwuWjFSuzrif0nVlssYuLC35+fqxdu5ZBgwYREhLCo48+ilKKGTNm4OLigk6no1evXhw5coR27YreTR4WFkZISAiHDh0iPz8fb29vfHx8ABg6dCgTJkwA4K233mLevHlMnjyZgQMH0r9/f4YPH36drOzsbIKCgti0aRMtWrRg7NixfPfdd0yZMgUwxCo6cOAA3377LbNnz2bu3Lk36RMcHMzo0aMZNGgQb7zxBnl5eVhaWvLCCy/QvXt3li9fjk6nIz09nePHj/P++++za9cuXF1dSTS6P0viwIEDHDt2jKZNmwIwf/58XFxcyMrKomPHjgwbNgy9Xs+ECRPYvn07TZs2JTExETMzMx5//HEWL17MlClT2LhxI15eXmi5xO9sasyIAMAhMBDJyyNjx3aUUvi4+xAaF8qdFmZD43oKu4cKu4WWLl2Kt7c3HTp04Pjx49e5cW5kx44dDBkyBFtbWxwdHRk4cGBB2bFjx+jatSuenp4sXryY48ePl6hPREQETZs2pUWLFgA8+eSTbN++vaB86NChAPj4+BAVFXVT+9zcXP766y8GDx6Mo6Mj/v7+BfMgmzdvLpj/MDc3x8nJic2bNzNixAhcXV0Bg3EsDT8/vwIjAPDll1/i5eVFQEAA0dHRnD59mj179tCtW7eCetfkjh8/nkWLFgEGA6LFUbrzqbQRgVLKGtgOWBn7WSYi79xQJwj4GEMSe4CvReTm16MKwsbbG3MXF9I2bMSxb1983X1Zc3YN51LP0cypWWV1W3Mo4c29Mhk0aBAvvvgiBw4cIDMzEx8fH86dO8fs2bPZv38/zs7OBAUFlRoyujiCgoJYsWIFXl5eLFy4sCB7WXmxsrICDA/yonz069evJzk5GU9PT8AQr8jGxob+/fuXqZ/C4bX1en2B+wzAzs6u4Hjr1q1s3LiR3bt3Y2trS48ePUr8rRo1aoS7uzubN29m3759LF68uEx6aVQ/KnNEkAM8KCJeQHugj1IqoIh6S0SkvfFTaUYAQJmb49DrQdK3bUOfm6vNE9wl2Nvb07NnT8aPH18wGkhNTcXOzg4nJyfi4uJYu3ZtiTK6devGihUryMrKIi0tjdWrVxeUpaWlUa9ePfLy8q576Dk4OJCWlnaTrJYtWxIVFcWZM4aFCD///DPdu3c3+XqCg4OZO3cuUVFRREVFce7cOTZs2EBmZia9evXiu+++AwzpOFNSUnjwwQf57bffuHr1KkCBa6hJkyaEhRnu7VWrVpGXV3TE3ZSUFJydnbG1teXkyZPs2bMHgICAALZv3865c+eukwvw9NNP8/jjjzNixIiCfA0ady6VZgjEQLrxq6XxU+U+GIfAQPQZGWTu3s29jvfiauOq7Se4Cxg9ejSHDx8uMAReXl506NABDw8PHnvsMTp37lxie29vb0aOHImXlxd9+/a9LsT0e++9h7+/P507d8bDw6Pg/KhRo/j444/p0KEDkZGRBeetra1ZsGABI0aMwNPTEzMzMyZOnGjSdWRmZrJu3ToeeeSRgnN2dnZ06dKF1atX88UXX7BlyxY8PT3x8fEhPDycNm3a8Oabb9K9e3e8vLx46aWXAJgwYQLbtm0ryLdceBRQmD59+pCfn0+rVq2YOnUqAQGG9zU3Nzd++OEHhg4dipeXFyNHjixoM3DgQNLT0zW30F1CpYahVkqZA2FAc+AbEXnthvIg4EPgCnAKeFFEoouQ8wzwDEDjxo19biWQlz43l9MPdMKxX1/qvfceL297mYPxB9k4fCNKqXLLralooYZrJqGhobz44ovs2LGj2DravVG9qLIw1CKiE5H2QEPATynV9oYqq4EmItIO2AAUmdlbRH4QEV8R8b3V1QlmtWph370baZs2Izodvu6+xGfGczH94i3J1dCoKcycOZNhw4bx4YcfVrUqGhXEbVk1JCLJwBagzw3nr4pIjvHrXMDndujjEBiILjGRrIMHC+YJNPeQhoZpTJ06lfPnz9OlS5eqVkWjgqg0Q6CUclNK1TYe2wC9gZM31KlX6OtA4ERl6VMYu27dUJaWpG3YwH2178PZypnQOM0QaGho1Ewqc0RQD9iilDoC7Ac2iMifSqnpSqlri7RfUEodV0odBl4AgipRnwLM7e2x69SpYJext7u3tnJIQ0OjxlJp+whE5AjQoYjzbxc6fh14vbJ0KAmH3oGkb9tGzokT+Lr7sunCJmLTY6lnX6/0xhoaGhp3ETVqZ3Fh7B98EMzMSNu4Ed+6xnkCzT2koaFRA6mxhsDCxQVbb2/SNmzk/tr342DpoLmH7lCuBVPT0NAoHzXWEIDBPZRz+jS6C9F4u3trIwINDY0aSY02BPa9DLHj0zZuxNfdl/Op54lNjy2yrj43l/QdO9Hn5BRZrlH1iAivvPIKbdu2xdPTkyVLlgAQGxtLt27daN++PW3btmXHjh3odDqCgoIK6n722WdVrL2GRtVRY8JQF0Wthg2wbt2atA0bCRw5my8OfsGcI3OY1mnadfX02dlcnPwCGTt2YO7mSp2gIGqPHIW5fdFb9msqs/bN4mRi0fH1y4uHiwev+b1WekXgjz/+4NChQxw+fJiEhAQ6duxIt27d+PXXX3n44Yd588030el0ZGZmcujQIWJiYjh27BhAkVnKNDRqCjV6RAAG91DW4cO4Z9ZiVMtRLD+znNNJpwvK9ZmZRE+cRMbOnbg+9xzW999P/MezOdOrF1e+/Ir8pKQq1F6jMDt37mT06NGYm5vj7u5O9+7d2b9/Px07dmTBggVMmzaNo0eP4uDgQLNmzTh79iyTJ09m3bp1ODo6VrX6GhpVRo0eEYBhl/GVL74kffMmnh3yLCsjV/Jp2Kd8F/gduvQMoic+S9aBg9SfNRMnY4z6rKNHufrDDyR8+y1XFyzA+dFHcRk/Dkt39yq+mqrF1Df32023bt3Yvn07a9asISgoiJdeeomxY8dy+PBh1q9fz/fff8/SpUuZP39+VauqoVEl1PgRQa3mzal1772kbdhAbevaPNvuWXbG7GTXqY1EP/00WQcP0WD2xwVGAMDG05OGX31Fsz9X4/jQQyT+8gtnAnsT++67SDGhfjUqn65du7JkyRJ0Oh1Xrlxh+/bt+Pn5cf78edzd3ZkwYQJPP/00Bw4cICEhAb1ez7Bhw3j//fc5cOBAVauvoVFl1PgRwbUUllcX/oQuJYXRHqNZeeAXMp57hazL+TT4/DMce/cusq1V8+bUnzUT18mTSfjuW5KDQ7Dv2g2HB3ve5qvQABgyZAi7d+/Gy8sLpRQfffQRdevW5aeffuLjjz/G0tISe3t7Fi1aRExMDOPGjStI3KIFUNOoyVRqGOrKwNfXV0JDK3aZZ9ahQ0SNGk39WTOx69aN42NGoM7HEPfmWHo/ZtrGZ31ODqf8/HEeNRL318u+WVpEyI2MxKp58zK3rUq0UMMaxaHdG9WLKgtDfadg3a4dFm5uJP+xnAtjn8QqJoHfnmrOTIuNZOVnmSTDzMoKG+8OZOzZWy4d0rds4Wz/AWQePFiu9hoaGhrlRTMEgDIzw6F3IJl795J78SKN5nzPkDHvEp8Vz6Lji0yWY+cfQE5EBPmFUvqZSvqWLQBk7PynzG01NDQ0bgXNEBipPXw4Vh4eNP7xB+wCAvB29yawcSDzjs0jISvBJBl2DxhS/GXuLduoQERINxqAsrbV0NDQuFU0Q2DEunVrmq1Yjq3vvy60KT5TyNPl8e2hb02T0aYNZvb2ZXYP5UZGkh8bi4WbG5mHD6PPMs0dpaGhoVERaIagBO51vJeRHiP5/fTvRCZHllpfWVhg27EjGXt2l6mf9B07AXB9/nnIyyNLmyfQ0Ljj0CUnIzpdVatRLjRDUArPtnsWOws7Pg371KT6dgH+5J2/QN6lSyb3kbFzJ7Xuuw+nAf3BwoKMvfvKq66GhkYVoM/N5czDfUj4xjTvQXWjMlNVWiul9imlDhuzkL1bRB0rpdQSpdQZpdRepVSTytKnvDhbOzOh3QS2X9zOntg9pda3DXgAwOSHuT4ri8z9+7Hv0hkzOzts2rYlc0/p/WgY6NmzJ+vXr7/u3Oeff86kSZOKbdOjRw+uLUHu169fkXGGpk2bxuzZs0vse8WKFYSHhxd8f/vtt9m4cWNZ1C+SrVu30r9//1uWo3H7yImIQJ+SQlJwMPrc3KpWp8xU5oggB3hQRLyA9kAfpVTADXWeApJEpDnwGTCrEvUpN4+1eoz6dvX5JPQT9KIvsa7V/c0xd3Eh00T3UOb+/UhuLnZdugJgG+BP1rFj6NIzblnvmsDo0aMJCQm57lxISAijR482qf1ff/1F7dq1y9X3jYZg+vTpBAYGlkuWxp1N1pEjAOiSkkhb/3cVa1N2Ks0QiIF041dL4+fG3WuDgJ+Mx8uAXkopVVk6lRcrcyum+EzhZOJJ5h2dV2JdZWaGrb8fGXv2YspmvfSdO1FWVth2NExS2/n7g05H1gEtSY4pDB8+nDVr1pBrfAuLiori0qVLdO3alUmTJuHr60ubNm145513imzfpEkTEhIMq8JmzJhBixYt6NKlCxEREQV1fvzxRzp27IiXlxfDhg0jMzOTXbt2sWrVKl555RXat29PZGQkQUFBLFu2DIBNmzbRoUMHPD09GT9+PDnG8OVNmjThnXfewdvbG09PT06eND1aa3BwMJ6enrRt25bXXjPEdSounPaXX35J69atadeuHaNGjSrjr6pRVrKPHsO8Th0s721MUnBwVatTZio1xIRSyhwIA5oD34jIjctpGgDRACKSr5RKAeoACTfIeQZ4BqBx48aVqXKx9GnShy3RW/j60Ne0v6c9Het2LLauXcADpK1dR+65KKyaNS1RbsaOndh27IiZtTUANh06oCwtydizF/tu3Sr0Giqbyx98QM6Jig1DbdXKg7pvvFFsuYuLC35+fqxdu5ZBgwYREhLCo48+ilKKGTNm4OLigk6no1evXhw5coR27doVKScsLIyQkBAOHTpEfn4+3t7e+Pj4ADB06FAmTJgAwFtvvcW8efOYPHkyAwcOpH///gwfPvw6WdnZ2QQFBbFp0yZatGjB2LFj+e6775gyZQoArq6uHDhwgG+//ZbZs2czd+7cUn+HS5cu8dprrxEWFoazszMPPfQQK1asoFGjRkWG0545cybnzp3DyspKC7F9G8g6dhSbtm2x9fcn/qOPyI44hXXLFlWtlslU6mSxiOhEpD3QEPBTSrUtp5wfRMRXRHzd3NwqVkkTUUrxzgPv0NihMa9uf7XEvQV2Af4AZO4t2defezGG3HPnsO/apeCcmbU1Nu3ba/sJykBh91Bht9DSpUvx9vamQ4cOHD9+/Do3zo3s2LGDIUOGYGtri6OjIwMLBRk8duwYXbt2xdPTk8WLF3P8+PES9YmIiKBp06a0aGF4EDz55JNs3769oHzo0KEA+Pj4EBUVZdI17t+/nx49euDm5oaFhQVjxoxh+/btxYbTbteuHWPGjOGXX37BwqLGhxSrVHTpGeRGnsW6nSdOQwajatUiKeTOGhXcljtERJKVUluAPsCxQkUxQCPgolLKAnACrt4OncqDnaUdn/T4hDFrxjB1x1TmBM7B3Mz8pnqWjRtjUb8eGXv24lyCrzpjp2HZqF3Xrtedt/X3J+Hbb9GlpGDu5FSxF1GJlPTmXpkMGjSIF198kQMHDpCZmYmPjw/nzp1j9uzZ7N+/H2dnZ4KCgsjOzi6X/KCgIFasWIGXlxcLFy5k69att6SvlZUVAObm5uTn59+SLGdn5yLDaa9Zs4bt27ezevVqZsyYwdGjRzWDUElkHz8OIth4emLh7Ixj376krlzFPf97+Y5JXlWZq4bclFK1jcc2QG/gRr/BKuBJ4/FwYLNU8yh4LZxb8Ib/G+yN3cucI3OKrKOUws4/gMy9exF98ZPL6Tt3YFG/HrWaXu8+svP3A72ezAoOrne3Ym9vT8+ePRk/fnzBaCA1NRU7OzucnJyIi4tj7dq1Jcro1q0bK1asICsri7S0NFavXl1QlpaWRr169cjLy2Px4sUF5x0cHEhLS7tJVsuWLYmKiuLMmTMA/Pzzz3Tv3v2WrtHPz49t27aRkJCATqcjODiY7t27FxlOW6/XEx0dTc+ePZk1axYpKSmkp6eX3olGucg+dhQAa09PAJxHj0KfmUnqn6tLalatqEzXUD1gi1LqCLAf2CAifyqlpiulro275wF1lFJngJeAqZWoT4UxuPlgBt43kO8Pf8/uS0WvDrIL8EeXnExOoUnHwkheHpm792DfpSs3zo9be3mhrK3J0NxDJjN69GgOHz5cYAi8vLzo0KEDHh4ePPbYY3Tu3LnE9t7e3owcORIvLy/69u1Lx47/zgG99957+Pv707lzZzw8PArOjxo1io8//pgOHToQGfnvhkNra2sWLFjAiBEj8IOrutYAACAASURBVPT0xMzMjIkTJ5bpejZt2kTDhg0LPlFRUcycOZOePXvi5eWFj48PgwYNIiYmhh49etC+fXsef/xxPvzwQ3Q6HY8//jienp506NCBF154odwrozRKJ+voMSwbNsTC2Rkw/P1atW5FUnCISQtGqgUickd9fHx8pDqQkZshg5YPkm4h3SQuI+6m8tzLlyW8pYckzJtfdPt9+yS8pYek/P13keXnx42TyIGDKlTnyiA8PLyqVdCoptSUe+P0g70kesqU684lLlki4S09JCMsrIq0uhkgVIp5rmo7i8uJraUtn/b4lKz8LF7d/ir5+ut9vZbu7tRq2pSMYiaM03fsBHNz7AJu3FphlO/nX+5IphoaGreH/MRE8mJisGnred15p/79MbO3Jyk4pJiW1QvNENwCzWo34/8C/o+wuDC+OfTNTeV2DwSQtT+0yPSV6Tt3YNOhPeYODkXKLlh5tG9/xSqtUSz63Nw7ZyivUS3IPnptfuD6BZFmtrY4DRpE2rp1d8TLnGYIbpEB9w1g2P3DmHt0Ljsu7riuzNY/AH1mJllHj113Pj8hgZzwE9h3uX61UGGs27TBzNa22BFFdeJueHjqs7PJOXUKXVJSVatyx1LYkFbHe0KfkVHhemUdPQZmZti0aXNTmfOokUheHil//FGhfVYGmiGoAKb6TaWFcwte3/k6Z1POFpy39esISt20nyDjH0PuAbtC+wduRFlaYuPrQ2Y1D0BnbW3N1atXq+UfflnQpRpW/+THx5e40kujaPS5ueScPo0uMRER4erVq1gbN0lWB7IjIjjVtRtX5xS90q/cco8exeq+ZpjZ3bxM1Or++7Ht2JGkJUur/T2lLSyuAKwtrPm0x6eMXTuWcevG8eNDP9LCuQUWzs5YtfIgY/ceXAsFQUvfsRNzFxesS8nnaucfQPz2j8mLj8fynnsq+zLKRcOGDbl48SJXrlypalVuifyEBCQ/H/R6zFJTi3XZaRSNLi0NfVoaKjkZCxcXrK2tadiwYVWrBYA+M5OYF19CMjO5Om8+zmPGVMj/r4iQdfQo9iUsDXYePYqYl/5Hxj//YN+1eA9AVaMZggriXsd7WdhnIU///TTj149nTu85tKnTBjv/AJJ++QV9djZm1taIXk/GP/9g17ULyqzkAZmt/7UdyvsMIaqrIZaWljRtWnIYjeqOLiWFU8OGU+eZCWSfOEHWocM03/A35sZduholIyJEPvQwedHRmDs7c/+uf25aEl2VXH5/BrnnznHPa68RP2sWSYt/xXXis7csN//SJXSJiTfNDxTGITAQc1dXkoJDqrUh0FxDFUhTp6Ys7LMQe0t7JqyfwKH4Q9g9EIDk5ZF14AAA2cfD0SUlmXRTWLfywMzRkcx91X8/Qd7ly5x/MojcixerWpUyk7FrF+j12Hfrzj1TpqBPSeHqvPlVrdYdQ9bBg+RFR2Pr64suKYncc1FVrVIBKatXk/LHH9SZ+Cx1xgVh170biQsXos/MvGXZ1+b+bDyLjl8FoGrVovawYaRv3VqmHCVFkfDjj2SfOnVLMopDMwQVTCOHRizssxBna2ee2fAMJxpiSDZjTF+ZsdMwoWzXqVOpspS5uSHjmQnzBKLTkbFvX5ErlG4HyUt/I3PvXpJ/W1Yl/d8K6dt3YObkhI1XO6xbtcKxXz8SFy0iv5q5u6rrPEzK8hUoGxvumWrYD1pdIufmnj/P5XemYePjg9vzzwPgOnEiuuRkkpYsvWX52ceOoiwtSw0u5/zoCBAhaWn5+0zbtIkrn3xK6urK2a2sGYJKoK5dXRb2WUh9u/pM2vUSeS3vLVj9k77zH6zbtMGiTh2TZNn5+5F3oeSMZ6LXE/vmW1wY+yTnHh1JVilB0Soa0etJWbECgNS1a6vtA6soRK8nfecO7Dt3Qpkb4ka5vTAZyc0l4fuKnVi8FdK2bOF0l66krP6zqlW5Dn12Nqnr1uH4UG+s27Q25OIIrXpDoM/NJebFl8DSkgazP0YZ4yzZduiAbUAAifPnozeGBi8vWUeOYuXhgapVq8R6lg0aYN+9O8nLfkfKkbQmLy6e2Dffwqp1K9wmTy6vuiWiGYJKws3Wjfl95tPUqSmrnc+TdfQoeZcukXXoUImrhW7k2jxBcaMCESHu/RmkrFiB0+DB5CdcIerRkcR9/DH6rKwKuZbSyNwfSt6lS9g+EEDehQtkHy8+ymdlknvxYpmNUM7Jk+iuJGDX9d+Q37WaNKH2sGEkLV1aLVxdSSFLuPj8f9AlJ3P5vffIi4+vapUKSN+8GX1aGk6DBqGUwtbHm0yjG7QqufLJJ2SHh1P/ww+wrFfvujLXic+Sf+XKLS3rFL2e7OPHsfH0LL0y4PzYaHQJCaT89VeZ+4l9fSr67GwazJ5dqtEpL5ohqERcrF2Y+9Bc0j2boPTCoQ+mgk6HfRfTDYHV/fdjXrt2sWGpr3z6GUm//orL+PHU+/AD7luzhtpDh5A4bz5nBw0ucElVJinLl2NmZ0f9mTPBwoLUMt7sFUH6zn+IDOxN6pqy9Z2+3eCqs7/BOLs+/xzKzIyEr76qMB3LiogQ//nnXJ42DbuuXWiydAmSnU3ce+9XmU43krxyJRZ16xa8sNh4+xhGsFVorNI2byHxp0U4P/EEDg8+eFO5rb8/Nu3bc/XHueV2peaeO4c+I6Mg0Fxp2HXpgnXbtlye9i6Z+03fJJq48Ccydu3G/fXXsWrWrFy6moJmCCoZJysn3njqJ/IsFbYb95Nva4V1MclRisKQ8cyfjL03ZzxL+H4OV3/8kdqjRnLPKy+jlMLc0ZF6771H44ULAbgQFETs//0futTUirysAvQZGaT+/TeO/fpi6e6OfefOpK67ve4h0euJN+YXLmsc+PTt27Fu3RoLV9frzlu6u+P8+BhSVq02aYJOn5FB0pKlZB48WCHXLrm5xE59navfz6H2iBE0+uYbbNq0wXXyf0jbsIHUdetLF1KW/kTI2LO3TKPI/CtXyNj5D04DBhS41Wx9vAEKFkdUJFlHj5Fz7lyJv2/e5cvEvv46Vq1bcc8rLxdZRymF66SJ5F26VG5XW9YRw45imxJWDF3Xp5kZjX6Yg2X9+kRPnFSQ2rIksk+cIP6zz3DoHUjtR0eUS09T0QzBbcDB3gUHHz/MgLBGufzfvnfJ0Znun7T19yM/Npa86OiCc4mLfubK55/jOHAAdd9++6blenYB/jRbtZI6Tz9F8h/LiXzkEVL/rvhcqqnr/0YyM3EaMgQAx359yb8US9ahQxXeV7E6rPmLnJMnsfH2Jis0jBxj+OfS0KWkGFx13YpewVXn6acxs7PjyhdflignMzSUs4OHcPmddzg/+jEi+/ThytffkHvhQpmvBUCXnk70xEmkrFyJ239foO70dwt83HXGjcO6dWsuv/ceugrMPJa0aBEXgoK4/O50k9uk/LkGdDqcBg8qOGfdqhXKxobMsIo1BLkXLhD16KOc7duPMz16EvPqqyT//ge5F2MK6kh+PjEvv4zk5dHw008xK8GNYtetG1atW3F1zhxEpyuzPtlHj2Jma3tTCPmSsHBxofGC+Zg7O3NhwjNkFxOZGECflUXM/17GwtmZutOnV/pyXM0Q3CYcHjCsEqrdrSerIlcxbt044jLiTGprVzBPYHDzJP/+B3EffIBD70Dqf/BBsfsRzKytuefll2mydAkWrm7EvPDfCjcGKcuXY3lvY2w6dADAvlcvVK1apJYS//9GRITMAwcNm7rK0i43lytffIFV61Y0/PILsLQk+bffTGpbeNloUVg4O1PnqfGkb9pUpGHT5+QQN+sjzj8xFoBGc+dSb8YMLOvWI+Gbb4h86GGiRj9GUnCwyQ/tvLh4zj/+BBn79lHvgw9wnTTpuoeAsrCg3gcz0KWkEPfhTJNklkb6tm3EzfoIc1dXUlasMGmVGkDKypVYe3pidd99/+pnaYmNlxdZYRU7YZy87HdQCvfXp2Lr403Gzn+IffNNIgMDOdMrkEtvvknsW/9HVmgYdae9Q60mTUqUp5TC9dmJ5J4/T+q6dWXWJ+vYMazbti0YCZmKpbs7jRcuwMzamgvjnyLn3Lki68XNmkXu2bPUn/lhQXjrSqW4sKTV9VNdwlCXlZzoaDn/1NOSd/WqbDy/Ufx+8ZMeS3rIwbiDpbbV6/US0aWLXHzpf5Kydq2Et2ot5596WnQ5OSb3r8/NlchBg+VUj56iy8i4lUspICc6WsJbesiV77677vyF55+XU126ij4/32RZyatWSXhLD7n84cwy6XB10c8S3tJD0rbvEBGR6ClT5KSfv+iys0ttGzP1dTnp51+inrr0dIno1Fminhgrer2+4HzmkaNypt8jEt7SQy5Nmya69PTr2uVeuiRXfvhBIvv3l/CWHhLe1lMuTHpO4mZ/IgnzF0jS8uWStm2bZB45IjnRF0WXkSHZp07JqR495WQHb0nbsbNE3eM++8x43dtLvc6SyD51Sk56+0jkkCGSl5gopwN7y5mH+5R6b2WdOCHhLT3k6s+/3FQW/8WXEt6qteSnpd2SbtfQ5+VJRJcucmHipH/P6fWSfeqUXF30s0T/5z9y0s9fwlt6SMxrU02Xq9PJmX6PSGT/AaLX6Uxvl5MjJ9p6yuWPPirTdRQmO/KsRHTqLKe695Cc6IvXlaVu2mT4W5hVfvlFQQlhqKv8wV7Wz51qCG7kVOIp6bOsj3RY1EH+OPVHqfUvvvQ/OentI+Ft2sq5MWNEl5lZ5j4zQkMlvKWHxH32WXlUvon4r76WcI9WkhsTc935lDVrJLylh6Tv3WuSHH1+vpx5uI+Et25Tpodbflq6RDzQSaLGPlnwkE7ftUvCW3pI8qpVJfep0xmM64svltrP1Z8WGfTasVP0ubmGB13rNnKqW/dSH9h6vV6yjh+Xyx98KKd7PijhbdoaDEMxn4guXSTr+PFSddJlZ8uZvv3kVM+ekp+WXmr9osi7elVO9wqUiC5dJDc2VkRE0rbvkPCWHhL/9dcltr384UwJb+speYmJN5Wl7dxZ8HtVBKkbN0p4Sw9J3bSp2Dp6nU6yz5wRfV5emWQnr1xpkL1xo8ltMo8cNeQSWbu2TH3dSNaJE3Kyo5+cDuwtuZcNOU1y4+IkIuABiRwyRPRleNEzBc0QVFOSs5Pl6fVPS9uFbeWDPR9Iri632LrXEl2cHTb8lt60Lr7yipxo6yk5UVHlliFi+MM73StQzo8bd1OZLiNDTrTvIJemTTNJ1rXRQPKqVRLZf4BEdOoseVeulNou/quvJbylh2QePny9Xg89JOfGjCmxbdbx4xLe0kOS/lheaj+6nBw53fNBiew/QM4OGWp483z1VclPSSn94m5Ar9dLfkqK5ERFScaBA5K6abMkLVsmCT/+KPFffCm5Fy+WLsRIRtgBCfdoJbHvTi+zHrqcHDn32Bg50c7rut9PROTiiy/JCc92kn32bNHXkJcnEZ27yIXnny+yPD8tXcJbt5H4L74os15FceHZiYYRZhkf8qagz8uT04G95eyw4deN+Eoi8ddfJbylR5n+r4oj89AhOdnBW870e0TyEhLk/LjxcsKrvWRHRt6y7BupEkOAISn9FiAcOA78t4g6PYAU4JDx83Zpcu8mQyAikqfLk1n7ZknbhW1l/LrxciWz6AegLj1drnw/p8g3sLKQGxcnJ7195Pwzz5h84xdF+t69hof3ypVFlkdPmSIRD3Qq9Y/32mggcuAgw1vdqVNyop2XnH/q6RKH63kJCXKyg7dEv/Dfm8oSfvxRwlt6SPaZM8W2v/LddxLe0sMkgyMikvTHcsMb+wOdis0qVxXEvj/DkAlr/36T2+j1eol5/Q3DW+2aNTeV58XHy0nfjhL1ZFCR90ja1q0lZtcTETk7dJhEPTHWZJ2KI/fyZQlv1VriPq2YUWxRJC5dWqYRTMzrbxju7Vv4+ylM+t69cqKdl0QEPCDhLT0kMTikQuTeSFUZgnqAt/HYATgFtL6hTg/gz7LIvdsMwTVWnlkpPj/7SLeQbrItelul9pUwf4FxqL253DJipr4uJ719ip1vSFm/3uAe+uefEuVcGw2krF9fcC4xONiQ5nP+gmLbxb73voS3blPkW2teQoKEt/WUyx98WGz7c6Mfk7NDhpaoW2H0Op2krFkjeQkJJre5HejS0+X0g73kzEMPiy4ry6Q2CXPnGdw/X35VbJ1rb71FGfqLL74oEX7+JbouYmfMkBNe7W/ZvXHl228lvKWH5Jw/f0tySkKfkyOnuvcodRR5jcj+A+T8M89UqA5p27cb5pGef77CDMyNlGQIKm3VkIjEisgB43EacAJoUFn93ekMvG8gIY+EUMemDs9vep4P9n5Adn52pfTl8vgYajW/j7gPPijXNnt9Rgap69fj0LcPZra2Rdax79YNMzu7EndSik5HwjffYtWyJQ6BgQXna48ciX1gL+I//bTIcBm50dEkLVlC7WHDsCpi+Z5FnTo4BPYiZcWKIq+vYNlo9243lRWHMjPDsV8/k0OD3C7M7OyoO/1dcs+fJ+Gbm7Pk3Uja5i3Ez56NQ98+uD7/XLH1ao8cibVXO+JmzrpuxZMuNZW0jZtwfOSREne52vr4ItnZZJ84UbYLKoTo9SQv+x3bBwKo1bhxueWUhqpVizpPPUVWaBgZe0pOBKXPyCAnMvKm1JS3in3XrjTf8DcNP/usSiK33pblo0qpJkAHoKhtrg8opQ4rpdYqpW5O82No/4xSKlQpFXqnx70viebOzQl+JJjHWz1O8MlgRq8Zzemk0xXej7K0pO5bb5F38SJX584tc/vUDRuQzExqG/cOFIWZtTX2vR4kbcPGYuOrpP71F7lRUQW7eAv0U4p6772HhYsLl/73MvqMjOvaXfniS5S5Oa7GQGJF4fzoo+hSUkgrYrlswbLRrqYbguqMfefOOA0bytX5C7g09XWufPklSUuXkr5jhyFZTJoh6U52RASXXn4Z6zZtSlx2DAbDV2/6dHQpKcR/8knB+dR165DcXJyGDC5RJ1tvw3LiW9lPkLlnD3kxMdQePrzcMkyl9ojhWDZoQMzLr5BbaL/OjWSHh4Nej027ijUEAJZ166IsLStcrilUuiFQStkDvwNTROTG7a0HgHtFxAv4ClhRlAwR+UFEfEXE183NrXIVrmKszK14ze81vgv8jqTsJEb9OYrFJxZfc6VVGHYBATj07cPVH368blOOKaQsX4Fl48bYeHuXWM+xb1/0KSlk7N59U1lxo4FrWDg7U/+jjwwRJD/4oOB89okTpP75Jy5PPIGle/HJemz9/bFs3JjkIqJMFo42erfg/uqr2HXpTMauXSR89z2X336H6AnPcHbAQE519CPCx5fzox/DzN6eht98g5mNTakyrVu2xCXoSZJ/W0amcV9AyspV1GrWDOu2Je+otXBzw/LexgXtykPSb79h7uRU5P1R0ZhZW9Poxx8gL48LTz9N/tWrRda7Fnra1NASdwqVagiUUpYYjMBiEbkpwpOIpIpIuvH4L8BSKeV6Y72aSJcGXfh94O/41/Nn5r6ZPL/pea5mFX1zlhf3V18FMzPiZ5m+MSn3YgyZe/dSe8jgUoew9p07Y+boSOpfN28uK240UBg7fz/qPPsMKb//URC/KP7TzzBzcqLOhKdL7FuZmeH86AgyQ0PJOftv+tCioo3eDZg7OdF4zhzu374NjyOHab55E/f+upj6n8zmnldexmnoUBx6BxrCHJRgQG/E7fnnsaxfn9h33iHn7FmywsIKAsyVhq2PL1lhYeV6iclPSiJt4yacBg/CzMqqzO3Lg1WzZjT8/jvy4+KJfnbiTSNRMISetqxfHwsXl9ui022juMmDW/0AClgEfF5CnbqAMh77AReufS/uc7dOFheHXq+XxeGLxXuRt3QL6SbLTy8Xnd70zS+lcWXOD9dtyCqN+G++KdPSuZg33jBMKhfa4HXjSqGS0OfmyrmRo+Skj68kLfvdMIk8d55JfRc1aVyWZaMaBlI3b5bwlh5yOrC3Yd/IpUsmtUtatsyweqscSyETFhgWNGRFRJS57a2SunmzhLduI+fHP3XTZPfpXoFFrlS7E6AqJouBzsATwINKqUPGTz+l1ESl1ERjneHAMaXUYeBLYJRRYQ0jSikea/UYIf1DaGDfgP/75/8Y9ecoQi+HVoh8l6AnqXXvvcTNmIG+lFjpIkLK8hXYBgRg2cC0eX/Hvv3QZ2SQsWNHwTlTRgPXUJaW1DcGlIt9800s6tbF+fExJvVtUacODr2unzRO374duDnaqEbxOPTsicNDDxmykAX43xTWuTiuuQ4zQ8t2r4oIyb8tw8bLC+sWJSd9qQwcevak3vTpZPzzD5fefKsg8Xx+UhJ5Fy9WyvxAVVOqIVBKDVBKldlgiMhOEVEi0k5E2hs/f4nI9yLyvbHO1yLSRkS8RCRARHaV5yJqAvc7388v/X5hZteZJOUkMW79OF7c8iLRqcVPbJmCWa1auL/1JrlRUST+9FOJdbPCwsiLjqZ2KROFhbEL8Mfc2bnAPVTa3EBR1GrYgHrT3wWlcJvy3zK5CpxHXps03gAY5ges27S5KdqoRsm4v/kGlvc2xuWJJ0xuU6tJE8zr1CGrjBPGWQcPkRsZWekRN0ui9rChuE2ZQurq1cTPNkyWZx8zzg9U8Iqh6oApyetHAp8rpX4H5ovIyUrWSaMYzJQZjzR7hAcbP8ii44uYd2we2y5uY0yrMUxoNwHHWuVLtm7ftSv2gb1I+PY78i/HUeu+Zlg1a0atZs2wcHMr8AcnL1+Oma0tDr17myxbWVjg8NBDpKxahT4zk7RNm8iNiqLBl1+UOhoojGO/ftgGBJTZN/vvpPES7Lt1JevQIeo8+0yZZGgYgqU1X1+20NdKKWy9y56oJnnZMsxsbXHs06dM7SqaOs8+Q358PInz52Ph5oY+KxOUwrpNkYsb72hKNQQi8rhSyhEYDSxUSgmwAAgWw/4AjduMjYUNz3o9y9D7h/LVwa/46fhPrDyzkufaP8eIFiMwNyv7JGjdN97g0mtTDW6UQpNkZg4OBqNw332krVtX4t6B4nDs14/kJUtI27ylzKOBwpRngk6ZmVF7xHCufPIpib/8clctG70TsPHxJm3DBvLi4k2apNalp5O6di1O/ftjZmd3GzQsHqUU7m++Qf7Vq8TPmoWFuzu17muGuX3V6lUZmPRKJoZln8uAEAw7hocAB5RSlZNAU8Mk3GzdmN55Okv6L6G5c3Nm7J3BY389RvjVsqeKtKxfn3t/XkSL0P0037aVxvPn4f7mmzj2fwRlZUX69u3oc3JwHjmyzLJtfX0wd3Ml7sMPTZ4bqEhqDx0KlpYkfPf9XbdstLpj6+MDmJ7QPvXPNUhWVpW6hQqjzM2p/9EsbDt2JD8ursI3klUXSh0RKKUGAuOA5hhWAfmJSLxSyhZDHKGqy+WnAUCrOq2Y99A81p9fz6x9sxi9ZjRjWo3hP+3/g61l2d7elVJYurtj6e6OXadO15VJfn5BgpQyyTQ3x/HhPiT98ku5RwO3wrVJ47R16+66ZaPVHetWrVC2tmSGHcCxb99S6ycvW4ZVy5al7lO4nZhZWdHw22+IfeNNnAYOqGp1KgVTXsuGAZ+JiKeIfCwi8QAikgk8VanaaZiMUoo+TfqwcvBKRrQYwS/hvzBo5SC2XNhScX2Uwwhcw2nQIDAzw+2/L9zW0cA1nEcZRjL2PXve9r5rMsrCAhuvdmSaMCLIPnGC7GPHqD18eJWEWSgJcwcHGn715U0vR3cLpvxFTgMKUhYppWyMISMQkU2VopVGuXGs5chbAW+xqO8i7C3teWHLC7y45UWTs6FVFjaebWmx658ik4nfDuwCAmjy21IcH3mkSvqvydh6+5BzMgJdenqJ9ZJ/W4aqVeuufeuuzphiCH4D9IW+64znNKox7e9pz9IBS/mv93/ZEbODQSsHsfjEYnJ1Je8VqEzMa9eusr4BbDw9q2Q0UtOx9fUBvZ6sg0XnsRYRUjdsIGXlShwefhhzJ6fbrKGGKX8VFiJS8PQwHhcfdlCj2mBpZsnTnk+zfNByvNy8mLlvJr2X9eazsM+4mHaxqtXTqCHYtGsH5uZFuoeyI05xYdx4Yia/gGX9erg+N6kKNNQwxel7RSk1UERWASilBgEJlauWRkXSyKER3wd+z+7Y3Sw5uYSFxxey4NgCOjfozMiWI+naoGu5lpxqaJiCmZ0d1q1akRX6ryHIT0oi4auvSApZgpmDA+7/9xbOI0fe0jyURvkx5VefCCxWSn2NIX5QNDC2UrXSqHCUUnSq34lO9TtxOeMyv5/+nd9P/c7kzZOpZ1eP4S2GM/T+objaaDtuNSoeWx8fkkJC0Gdlkbzsd658/TX69HScR4/G9T/PY+HsXNUq1miUqaF9jOGkEWO00KrC19dXQssYu0SjaPL0eWyN3sqSiCXsjd2LhbKgb9O+PNnmSVq6tKxq9TTuIlL//puYF/6LRd265F++jO0DAbi//nqVxBKqqSilwkTEt6gyk8ZhSqlHgDaA9bVlXSIyvcI01KgSLM0s6X1vb3rf25uolChCIkL44/QfrD67Gv96/jzZ+km6NOhS7Zbyadx52Pr4oGrVQlla0vCbr7F/8EHtvqpGlDoiUEp9D9gCPYG5GCKG7hORKtlDoI0IKpeUnBSWnVrGryd+JT4rnvuc7mNsm7E80uwRrMxvT1x4jbuTvEuXMHd1xayEFJcalUdJIwJTDMEREWlX6F97YK2IdK0MZUtDMwS3hzxdHuui1rEofBEnE0/iYu3CKI9RjGo5CmdrzZ+roXGnUZIhMGX56LUM6plKqfpAHoZ4Qxp3MZbmlgy4bwBL+y9l7kNzaVOnDd8e+paHlj3E+3ve53zq+apWUUNDo4IwZY5gtVKqNvAxhhzDAvxYqVppVBuUUvjX88e/nj+RyZH8HP4zf5z+g6URS+nZqCdBbYNo79Zet8LH9AAAIABJREFU8/dqaNzBlOgaMiakKUgYo5SyAqxFJOU26XcTmmuo6knISiD4ZDBLIpaQkpNCO7d2PNn6SXo17qXtR9DQqKbc6hzBQRHpUI5OG2GIVuqOYRTxg4h8cUMdBXwB9AMygSARKTGLhWYIqg+ZeZmsilzFovBFRKdF08C+AT0a9cCvrh8+7j44WWmhAjQ0qgu3aghmA7uBP8qST1gpVQ+oJyIHlFIOQBgwWETCC9XpB0zGYAj8gS9ExL8kuZohqH7o9Dq2Rm/lt1O/ERYXRrYuG4WiVZ1W+NX1w6+uH97u3thZ3n0JPTQ07hRu1RCkAXZAPoaJYwWIiJQpL6JSaiXwtYhsKHRuDrBVRIKN3yOAHiISW5wczRBUb3J1uRxNOMq+2H3su7yPw1cOk6fPw1yZ09a1Lf71/AmoF4CXmxe1zLVlhBoat4tbMgQVpEATYDvQ1pjt7Nr5P4GZIrLT+H0T8JqIhN7Q/hngGYDGjRv7nD+vrVi5U8jKz+JQ/CH2X97P3ti9HLt6DL3osTa3xsfdp8AwtHRpiZnSIoNqaFQWt7SzWClVZIJXEdluYuf2wO/AlMJGoCyIyA/AD2AYEZRHhkbVYGNhwwP1H+CB+g8AkJabRujlUPbE7mFv7F4+DfsUgNpWtfGr60e3ht3o1rCbtldBQ+M2Ysry0VcKHVsDfhj8/aVmGPn/9u48Sq67OvD499bWtfS+auvWYgkL29iykeUVI5vFhpiQDAzBMzkQyBkDExIgGTAJOQNhhjMJySQM4EAc4mBywDYJaxLCEpAxxLYsgeXdllqypJa6pV6q19qXO3/8Xq/qbnVLXaqS6n7Oeect9erVrdddv/ve7/fe+4lIEJcEvqqq35xnleNA54z5dd4yc4GqC9Vxc9fN3NzlegrrT/azu283u/t282jvo/zwyA/xiY9tbdu4ufNmdnbuZEPDhvIGbcwFbtlVQ97VQJ9R1becZj0B7gPiqvrBBdb5FeD9TDcWf1ZVdyy2XWsjuHCpKs/Fn+Ohnod4qOchXoi/AMCG+g3c3HkzN627iUtaLll2P8zGmBVuI/AK+GdV9ZLTrHcj8DPgaaZ7OPsjoAtAVb/obevzwG24y0ffNbd9YC5LBNWjb6KPh449xK6ju9hzcg/5Yh6ANbE1bGrcxEUNF3FRoxs2NWyiNlRb5oiNqVxne9XQ53D3AYB7JMU24LCq/uaKRrlElgiq03h2nD0n9tA90s3BkYMcGj3ES6MvkSlkptbpiHawuXGzG5o2s6VpC5saNhEJRMoYuTGV4WwTwTtnzOZxSeA/VjC+ZbFEYCYVigV6J3o5OHqQgyNumEwU2aLrXVUQOus62dzoEsN1a65jW9s2uwPaVJ2zTQQxIK2qBW/eD9SoanLFI10CSwTmdArFAj3jPXSPdHNg5AAHhg/QPdLNkbEjFLVIY00jN627iZs7b+b6Nddbm4OpCmebCB4DXjvZM5l3OegPVfX6FY90CSwRmDM1kZ3gP3r/g109u3j42MOMZ8cJ+UJcu+Zadnbu5NXrXk17tL3cYRpTEmfbQ1l4ZveUqjohInYIZc47taFabt1wK7duuJVcMccTJ59gV8+uqcQAEA1EaYm00BpppSXcQkukZWq+NdxKa6SVtmgbLZEWgr5gmb+RMStjKYkgISJXTT4MTkReCaRKG5YxpRX0Bdmxegc7Vu/gI1d/hO6Rbh7pfYQTiRMMpYcYSg3x0uhL7Dm5h9HMqQ/bFYSmcJNLDJE22qJttEfbuaLtCrZ3bLfqJnNeWUoi+CDwjyLSi3vO0CrgN0oalTHnkIiwpWkLW5q2zPt6rpCbSg4DqQEGUgMMJgfpT/UzmBxkIDXAgZEDDKWGKGiBgAS4vO1yrl19LdeuuZbLWi+zswdT0ZZ0H4F3h/DF3uyLqporaVSLsDYCU6nS+TT7BvbxWO9jPNb3GM8NPYeiRANRrl51NdesvoYtTVtYX7eejliHPVvJnFNn+6yh38E9IuIZb75JRO5Q1b9e4TiNOa+FA2F3FrD6WgBGM6M8fuJxdvft5rG+x/jpsZ9OrRvyheis66Srvouuui666rtYX7+eTQ2baI20Wo9v5pxaylVD+1R125xlZ9RZzUqwMwJzvupP9nN49DBHxo9wdOyoG8aP0jPeM+vGuLpQHZsbN7OpYZO7c9q7g7o92m4Jwpyxs71qyC8iMtkpjXcfgT1I3phlao+20x5tZ8fq2Y/TKmrRJYmxwxwaOcSh0UN0j3Tz46M/5hsHvjG1Xm2wlvZoOy2RFprDzdNXNYXdfGuklY5YB62RVqt2MsuylETwfeBBrxMZgPcA/1a6kIypLj7xsSq2ilWxVVPVSpPi6fjUXdOHRg8xmBpkKDXEC/EXiKfijOfGT9lewBegI9rB6thqVsdWsyq2itW1brqzrpM1tWus8drMspREcBeuU5j3evNP4a4cMsaUWHO4meZVzVy96up5X88UMsRTcYbSQwymBjmZOElfoo++RB8nEifYe3Iv/cl+Cu7BAAD4xc+a2jWuXaJu/ax2iqZwE7XBWjujqDKnTQSqWhSR3cBFwNuAVlwfA8aYMqvx17ij/drVC66TL+YZTA3SO9HL0fHptomjY0fZ17+PRC4xa31BqA3WUheqozbkxnWhOupD9ayKraKzrnNqaIu0WbvFBWDBRCAiLwPu8IZB4EEAVb353IRmjFkJAV9gqurpqo6rZr2mqgylh+gZ76FnvIeR9AjjuXHGs7OHE4kTvBh/kZPJkxS1OPX+SCDC2tq1U4mhKdxELBijNlhLLBibNV0bqqWhpsGqpSrQYmcEL+D6E7hdVbsBRORD5yQqY8w5ISLu8RmRVq5sP/2FgLlijr6JvqmrnXrGe+gZ6+Ho2FEe6X1k1tVPC2moaZhq7G4ON083fkdaqAvWEQ1GiQQiRINRYoEY0WCUaMAts6fGlsZiieA/AW8HdonI94EHcHcWG2OqVNAXdG0K9V2nvKaqZItZJrITJHIJErkEE7mJqfFEdoLhzDBDqSHi6ThDqSH2D+9nqG+I8eypjd7zaY+0T91z0VnXOTXuqu+yfifOwoKJQFW/DXzbewz1m3GPmmgXkS8A31LVH56jGI0x5wERocZfQ02khpZIy7LemyvkiKfjJHIJkvmkG+eSJPPekEsykZtw7RxjR9nVs4t4Oj5rG+2RdtqibTSHm2kKN9ESbqEp3DQ13xxudmcb/gjhQJhwIEyNv8YaxllaY3EC+BrwNRFpAv4z7kqiRROBiNwL3A70q+pl87y+E/gO8JK36Juq+sllRW+MuSAE/UE6Yh3Les94dtxVUY31cGTsCEfHj05dPXVg5ADxVHyqg6LF1PhrXGLwh2kON9MWbZt6kGBbxA3tUZdkLtR7NJbdZ/GSNyxyEzABfGWRRPA/VPX25WzX7iw2xiyFqpLMJ4mn4sQzceKpOMl8kkwhQyqfIlPIkM6n3VBIk8qniKfjDCTdgwWHUkMos8vHoC/Imto1rKtdx9ratayrmz0O+UMUigUKWiBfzJMv5ilogUKxQF7zhP1hYqEYsUDsnLd3nO2dxWdEVR8WkQ2l2r4xxixGRKauXOqkc9nvzxfzDKXcGUZ/sp/+ZD+9iV6OjR/j+MRxnhl6Zt5HlC9VJBCZvqIqWEssFKMh5BrSJ6uzJqu0JucbQg0lSSAlSwRLdJ2IPAn04s4Onp1vJRG5E3dTG11dpzZSGWPMSgv4AnTEOuiIdXApl867znh2nOMTx6eSQ76YJ+ALEPAF8Isfv89PQAL4fX584iNbmG5Mn9WQnpsgkU2wP7GfeDrOWHZs3s97xyXv4MNXf3jlv+uKb3Hpfgms93o8eyPwbWDeB8Kr6j3APeCqhs5diMYYs7C6UB1bm7eytXnrim43V8wxmhklno4TT8cZTg8TT8e5uOni07/5DJQtEajq2Izp74nIX4tIq6oOlismY4ypBEFfcOr+jnOhbM3fIrJKvHvTRWSHF8tQueIxxphqVbIzAhG5H9gJtIrIMeDjQBBAVb8IvBV4n4jkcX0gv11LdQmTMcaYBZXyqqE7TvP654HPl+rzjTHGLM2Fd2eEMcaYZbFEYIwxVc4SgTHGVDlLBMYYU+UsERhjTJWzRGCMMVXOEoExxlQ5SwTGGFPlLBEYY0yVs0RgjDFVzhKBMcZUOUsExhhT5SwRGGNMlbNEYIwxVc4SgTHGVDlLBMYYU+VKlghE5F4R6ReRZxZ4XUTksyLSLSJPichVpYrFGGPMwkp5RvBl4LZFXn8DsMUb7gS+UMJYjDHGLKBkiUBVHwbii6zyZuAr6jwGNIrI6lLFY4wxZn7lbCNYC/TMmD/mLTuFiNwpIntFZO/AwMA5Cc4YY6rFedFYrKr3qOp2Vd3e1tZW7nCMMeaCUs5EcBzonDG/zltmjDHmHCpnIvgu8A7v6qFrgVFV7StjPMYYU5UCpdqwiNwP7ARaReQY8HEgCKCqXwS+B7wR6AaSwLtKFYsxxpiFlSwRqOodp3ldgd8p1ecbY4xZmvOisdgYY0zpWCIwxpgqZ4nAGGOqnCUCY4ypcpYIjDGmylkiMMaYKmeJwBhjqpwlAmOMqXKWCIwxpspZIjDGmCpnicAYY6qcJQJjjKlylgiMMabKWSIwxpgqZ4nAGGOqXMn6IzDGmHJSVfJFpVB043yhSMGbL6gbF4tMT6uSzRfJ5Itk8oWp6ZnjdK5AOl8gnXPrZHLeslyBTL5IURWfCCIgeGMRBPAJFNV9XrE4/ZkuHigWlXyxOBVvoajkCkqhWJyav2NHF+999UUrvq8sERhjZinOLCjnFJi5wuyCMevNu+kC+YJX6BZdAeYKMlcIzyyU3bLZhVy+qKi6GBSdikenJ0nnCiSyBZKZPIlsnmS2QCKTJ5V1y3Pe5+QLRYpKSYUCPsIBH+Ggn3DQT03Ah08ERSmqS0Tqxa/qlvkEfD7BL4LfJ/gmxz7BLxDw+Qj6fYSDQsAn+H0+gn63TsAnrG2MlOS7lDQRiMhtwP8D/MCXVPVP57z+W8CfM91p/edV9UuljMmYSqaqZPJFEpk8E5ND2o0T2QLqlYqTR5kzjzwBUtnC1PsS3jCRcYVlIpufOnLNTB7RTh4Be8vzpS495zFZ0PnFFYxT5pmMhPxEQwGiIT+xUIDmWIjOpijRkJ9oyE8o4MPv83mFqHjbnp6fNYhXAPuYKpBDfh+hgI+agN8bTw5uPhx00zUBHz6fcKEoZZ/FfuBu4HXAMWCPiHxXVZ+bs+qDqvr+UsVhzEqZLKQzuSIprzog5Q2T1QPJrDdk8iRzBVLZ6WWpbJ50rkg675anvQLYvdctT2Ty5AorUxj7fUIs5KcuHCRW4wrQSNBPLBYgHPBTE5wu5MJB31Qh6o5W3ZGrT2YUmALBgG9GYenGIb8rJIN+Iej3EfALgVmFsW/qiHbytcn5C6kwPZ+V8oxgB9CtqocAROQB4M3A3ERgzBmbLJwnqwhyBVcd4cZuOl+YrsIYSeYYSmQZTmYZmsgST2SIJ3PEExlGEjlXPeGd2qNQnDq91zOqahCBSNAdrUZCfiJeNUI44Kc+HCBcV0M46CcSdFUMsZoAtTOGWE2AuvDktB8R8apKXDXKVNWDV5USmbGNmoAPEStozemVMhGsBXpmzB8DrplnvbeIyE3AfuBDqtozdwURuRO4E6Crq6sEoZpyyOaLjKdzTGTyjKfzjKVzbpzKMZbOM57OMZbyxt5rCa+KZLLaI5ktnFF1Rk3AR0ssRHNtiKZoiI0tURqjIUIBn1fl4qpbfF7Vi8+rhwkHfYQDrlAPB31Egn5qgtMFfNQr7KNeFUY4aIUx6THY/Tfw+D1QyEKkESJNEG5002FvPtIE666Gzh3g85c7aqeQh/hBOPksDB6A9dfDxleVO6oVV+7G4n8G7lfVjIi8B7gPuGXuSqp6D3APwPbt2899JaZZVLGojKfzxJNZ4onJIcNQIkt8wptPZhlOZKcK+PF0nky+eNpt19YEqA8HqAsHqQsHaIyGWNfk1RF7R8nRUICYV/C6KorpaorJqoqg31VpNEaDNMdCREN+K6BLLT3qEsCjd0N6BLa8Hpo2QGoYUiNu2WjP9HQx794XaXbrXnwbXPQaCNefm3gn+uHE067Q738OTj4DA/uhkJm93vobYedHVy4hZCZgqBvihyAUg8b10NgFoejKbH8JSpkIjgOdM+bXMd0oDICqDs2Y/RLw6RLGY5ZIVZnI5OkfzzAwnpkaD4xnGPYK9RGv0B9J5hhOZhesNokE/TTHQrREA1xSc5JsUyc1kRavcHcFfG3N9HR9JEB9OEh9OEhtOIB/peqQx3qh53Gouxpq1q7MNitNNumOuKfM80fxhyAQAd8itxClRmD4JVcwxQ9B3Jse6YHmje6oeP317ug9FJv//bv/Bh672yWDl70Bdt4Fa65c+DNVXYI49BDs/z4c+AE89QD4grDhBreNl70eoi2Qz7rCOe8NhYy3LAu17a4QDZ7m6hpVGD4MRx6Bo4/AkUfdkf+k2lXQcSls2gntl0LHJa6AfupB+Nlfwn23Ly8hqMLYcRh4AQa7YeiAO8MY6nbL5xNrc5/ZtH46Oay7GlZddvrPWyZRLc0BtogEcNU9r8ElgD3Af1HVZ2ess1pV+7zpXwfuUtVrF9vu9u3bde/evSWJuRoUisrgRIa+0TR9Iyk3HnXjxPBJhidSDExkSOVcMVLE5+qh8SH+IJFYLU1RV53SFAvSGA3RHA3RGA3SFHVVLS2xkCv8YzVENAn77nfVAkMHwF/jTv03vho23gRrrwJ/8PSBp0Zg4iTUrYJww+nXLxah9wlXqOz/Ppx4yntB3I/7ijvg5bfPX5DNJ5uA/uchEIZYqyuQlhL3vNtKwshRGDkCw0dcgTRyxBUI4QaoXwv1a7xh7fQ40uQKy5mFc/zQdKGdGFh6DJMJIRiGQI2b9odgvBeSQ7PXrVsDzZugYa0ryE48DVoEXwBWb4P118H6G6D9Enjyfnj0ryEzChf/Crz6I7Bm2/L3USEPxx6HF//N/f0G9y/v/bWr3NlH03o3blzv4h88AEcfdQlgvM+tG2mCruvcsOZKlwCizQtvO5eGX97nEsLEiVMTgqrbdu8T3rDPjZOD09uoaYDWzdCyBVq9ofkiyHn/G5P/E8NH3Hj0mDtjuvH34bUfX96+8IjIL1R1+7yvlSoReB/8RuAzuMtH71XVT4nIJ4G9qvpdEfk/wK8CeSAOvE9VX1hsm5YIFpfJF+gdSXN8OMXxkSTHhlMcH05xbMSNT46lp+rUa8hyre95bgk8xc3+J+nS3tN/wKrLYfNr3dC5Y+HCcOigK/yf+Cpkx2HtK13hO3wYXnrYFSYoBGNevetNbnvp0el//pk/hPTo9LZjbe5H07IZWmaMazvcD3z/D9wRZWIAxAed18LLboXOa+DQLldYjRyFUC1c8ma44u3uxzx5lKzqqix6HveG3V7hV5j9HcMNEG31EkOrV3goFHLu6HRq7E3nUq6wnzg5ezuBiCus6tdAZsydvYz3ucJ2Jl9guvpkUv06d5TevNEVdsE51Qkzq79Up4+kcynIp2ePC1mXaJs3TQ9NG0+tokiPuv1y5BFXqB7/xewzka23uwSw+or5/zfOxNBBOPgTF3ugxktkYQiE3MFFoMb9L070u8Q4fHg6yY4eY9bZUd0aL3ldD13XQ9vWxc+QFjI3IXRdDzV1rtBP9Lt1xAdtL3fJcPU2d2bRssWduSynarKQd/8T/hDUdSw/VsqYCEqhWhNB0TuSPzmW4eRYmv7xDP3jaU6OZRjwxpPLZ/IJrKoPs7YpwtqGMJeGB9iW2cvGkUdpHngcXyGDBsLIhhtdYRyqBXTyLhivMPLGmXFXiPfsdgVSqA42vXo6MdSvhYM/dtUC3T9yp/WX/jpc8x5YN+f/LxmHwz9323vpYRh8cfbrgYg7FW7smj41rlvlCsn4QVcwDHWfWqiCK6A3vw5edhtsfs2pR3fFIvQ85hLCs992hW/9Onj5m9wRcc/j00eLwZg7a+m8xh0tFvPuyC4x5I0HIDHojqKTcdfI6Q+6H6w/NGc65Ar7pvXQuGH6iDXWdmqhUMi7wmSs1yWPsV73XWPtXsG/ySv4w8v7RyqFXAqO/xL69sGGV8Hqy8sd0Wz5rEvsoz1eVcuG5RXCpzOZEB6921VJrbnSDau3wapXnNO6/sVYIjhP5ApFjg+nOBJPcnQoweGhJEeGkhyNJxge6udVxb3k8ZMgzIRGmSBMMFpPuLaJuvpGWurruCiWYlPNKOv8I7QTpz7Xj3/ihFeAHnI/BnBHJVte5wrK9Tecvk51pvSoK7y7/x0O/DuMHXPLw42u0a+2A7a/G175rqUfvYyfcEdS0Rb3Y13qEVN6zH2voW73Hdde5c4A/Ets/sql4IV/hScfcEmsYZ0r9DuvcWco7ZcufVvGVDBLBJXgyKPw9D+6gnfLrcTTRZ7rHeP5vjGe63Pj7v6JWZdChoM+Xt5U5F2+7/P68W8QLiSW/7m+gKsvrV/jCrkNN7ij96YNK/O9VF39bfe/u7rQLa931S2B0Mps/1wq5M683t+YCrdYIrBDnRLLj/SS/N7HqN//TYr48e39O07Qyj/kbuHBws0M0sCq+jCXrKnnlq3tbGiNsaElxobaAm3P3otMXnmx9XbXUBRucFUZmXE3ZCe86TF3ilrbDnWrpxsbY22lvSZbBNoudsP5zpKAqVKWCFbQSDLL833jPN83xv6+OJtf+hpvT3yVGnJ8rvBrfKn4Jt7SeJC38wM+nPw6f1DzLXIXv4maa++Eru2uUM2Mw+4vwiOfd9UsF7/RXZGwkg1vxhgzgyWCs5DOFdhzOM7PDgzy8P4BXjgxDsB1vmf5X6GvsJkeDjReT/cr/5hbNl/Gne211AT8wF0wsB/f3nup2fc1eP6bri56007XgJmKw5ZbXQJYe1U5v6IxpgpYG8EyqCr7T07wswMD/HT/AI+/FCeTLxL0C9vXN3NrV4E39t5N+9F/RRvXI2/4M3flymKNntkEPP1PsOdv3SWKm18HO/8Q1r3y3H0xY8wFzxqLl2qs111TPXnpJEqxWOSZ46P89MUT7O4+iSQHaWWUrXVpXtGYZlM4SZuM4E8OTt+ZeOOH4IYPLO9KHFVXFRRpKslXM8ZUN2ssPp3+5+EHH3OXD87hAy73ht8FmLwYJgMMhV3jbKzdXQ++4Ua47r+f2RU5IpYEjDFlUd2JIDEIuz4Fv/gy1NTRv/3DPD4c5YmeEQYncvh9PraurufK9S28Yl0j4VDI3UVa2+GuxqmpW9kbU4wxpgyqMxHkM+7KnIf/ArIJUtvezSfGbufBnyfx+4QbNrdy++WrufWSVTRE7ZJCY8yFrboSgSo89x340f+EkSPollt5aP3v8Qe7UoynU3zgNVt4x3XraamtKXekxhhzzlRPIjjxDHzvw+6Rs+2XMvyWr/PRfS384F9Ocvm6Bj791mvYuuocPffcGGMqSPUkgtQwDB1Ab/8M3/bdwp9860WS2QHuum0r/+1VGwn4z+Dpg8YYcwGonkSw8VWcePcePvbP3fz4hWe4squRP3/rFWxury13ZMYYU1ZVkwh2vdjP793/BLlCkT/+lZfzrhs2rlzvV8YYcx6rmkSwsSXGlV1NfPJXL2VD6xJ7pTLGmCpQNYlgQ2uMr7x7R7nDMMaYilPSFlIRuU1EXhSRbhH56Dyv14jIg97ru0VkQynjMcYYc6qSJQIR8QN3A28ALgHuEJFL5qz228Cwqm4G/gr4s1LFY4wxZn6lPCPYAXSr6iFVzQIPAG+es86bgfu86X8CXiNiz2wwxphzqZSJYC3QM2P+mLds3nVUNQ+MAi1zNyQid4rIXhHZOzAwUKJwjTGmOp0Xd1Gp6j2qul1Vt7e1tZU7HGOMuaCUMhEcBzpnzK/zls27jogEgAZgqIQxGWOMmaOUiWAPsEVENopICHg78N0563wXeKc3/VbgJ3q+9ZRjjDHnuZLdR6CqeRF5P/ADwA/cq6rPisgngb2q+l3g74B/EJFuII5LFsYYY86h866rShEZAI6c4dtbgcEVDGelVXp8UPkxWnxnx+I7O5Uc33pVnbeR9bxLBGdDRPYu1GdnJaj0+KDyY7T4zo7Fd3YqPb6FnBdXDRljjCkdSwTGGFPlqi0R3FPuAE6j0uODyo/R4js7Ft/ZqfT45lVVbQTGGGNOVW1nBMYYY+awRGCMMVWuahLB6fpGKDcROSwiT4vIPhHZWwHx3Csi/SLyzIxlzSLyIxE54I2bKiy+T4jIcW8f7hORN5Yxvk4R2SUiz4nIsyLyAW95RezDReKriH0oImEReVxEnvTi+xNv+Uav75Jury+TUIXF92UReWnG/ttWjviWqyraCLy+EfYDr8M9BXUPcIeqPlfWwGYQkcPAdlWtiJtRROQmYAL4iqpe5i37NBBX1T/1kmmTqt5VQfF9AphQ1b8oR0wzichqYLWq/lJE6oBfAL8G/BYVsA8Xie9tVMA+9B5HH1PVCREJAj8HPgD8PvBNVX1ARL4IPKmqX6ig+N4L/Iuq/tO5julsVMsZwVL6RjAzqOrDuMd+zDSz/4j7cAVHWSwQX8VQ1T5V/aU3PQ48j3vsekXsw0XiqwjqTHizQW9Q4BZc3yVQ3v23UHznpWpJBEvpG6HcFPihiPxCRO4sdzAL6FDVPm/6BNBRzmAW8H4RecqrOipb1dVMXhesVwK7qcB9OCc+qJB9KCJ+EdkH9AM/Ag4CI17fJVDm3/Hc+FR1cv99ytt/fyUiNeWKbzmqJRGcD25U1atwXXv+jlf1UbG8p8RW2hHQF4CLgG1AH/B/yxsOiEgt8A3gg6o6NvO1StiH88RXMftQVQuqug33CPsdwNZyxTKfufGJyGXAH+LivBpoBspSdbpc1ZIIltI3Qlmp6nFv3A98C/ePX2lOenXLk3XM/WWOZxZVPen9OIvA31LmfejVHX8D+KrkuzjmAAAC2klEQVSqftNbXDH7cL74Km0fejGNALuA64BGr+8SqJDf8Yz4bvOq3FRVM8DfUwH7bymqJREspW+EshGRmNdgh4jEgNcDzyz+rrKY2X/EO4HvlDGWU0wWsJ5fp4z70GtM/DvgeVX9yxkvVcQ+XCi+StmHItImIo3edAR3ocfzuAL3rd5q5dx/88X3wowkL7j2i0r8HZ+iKq4aAvAug/sM030jfKrMIU0RkU24swBwfUR8rdzxicj9wE7cY3VPAh8Hvg18HejCPQr8bapalgbbBeLbiavSUOAw8J4Z9fHnOr4bgZ8BTwNFb/Ef4erhy74PF4nvDipgH4rI5bjGYD/ugPXrqvpJ77fyAK7a5QngN72j70qJ7ydAGyDAPuC9MxqVK1bVJAJjjDHzq5aqIWOMMQuwRGCMMVXOEoExxlQ5SwTGGFPlLBEYY0yVs0RgzBwiUpjx9Mh9soJPqxWRDTLjianGVILA6VcxpuqkvEcHGFMV7IzAmCUS12fEp8X1G/G4iGz2lm8QkZ94Dxr7sYh0ecs7RORb3jPrnxSR671N+UXkb73n2P/QuzPVmLKxRGDMqSJzqoZ+Y8Zro6r6CuDzuDvVAT4H3KeqlwNfBT7rLf8s8FNVvQK4CnjWW74FuFtVLwVGgLeU+PsYsyi7s9iYOURkQlVr51l+GLhFVQ95D2w7oaotIjKI6+Ql5y3vU9VWERkA1s18BIL3yOcfqeoWb/4uIKiq/7v038yY+dkZgTHLowtML8fMZ+MUsLY6U2aWCIxZnt+YMX7Um34E90RbgP+Ke5gbwI+B98FUJyYN5ypIY5bDjkSMOVXE63lq0vdVdfIS0iYReQp3VH+Ht+x3gb8XkQ8DA8C7vOUfAO4Rkd/GHfm/D9fZizEVxdoIjFkir41gu6oOljsWY1aSVQ0ZY0yVszMCY4ypcnZGYIwxVc4SgTHGVDlLBMYYU+UsERhjTJWzRGCMMVXu/wPksVAqvzhJDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell to load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0lP8ck8ttJDb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.5755537106710966\n",
      "Recall: 0.4899\n",
      "Accuracy: 0.4899\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_2 = Dropout(0.3)(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Dropout(0.3)(conv_3)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "conv_2 = Dropout(0.3)(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "conv_3 = Dropout(0.3)(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_4 = Dropout(0.3)(conv_4)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "#conv_1 = Dropout(0.5)(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "conv_21 = Dropout(0.3)(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_4 = Dropout(0.3)(conv_4)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(64, 3, activation=LeakyReLU(0.3))(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(256, activation=LeakyReLU(0.3))(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "#model = create_model()\n",
    "model.load_weights('Inception_Adam_dropout.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU(0.3))(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_2 = Dropout(0.3)(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Dropout(0.3)(conv_3)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_1 = Dropout(0.3)(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "conv_2 = Dropout(0.3)(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "conv_3 = Dropout(0.4)(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_4 = Dropout(0.3)(conv_4)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "#conv_1 = Dropout(0.5)(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU(0.3))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "conv_21 = Dropout(0.3)(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU(0.3))(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU(0.3))(X)\n",
    "conv_4 = Dropout(0.3)(conv_4)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation=LeakyReLU(0.3))(X)\n",
    "X = Conv2D(64, 3, activation=LeakyReLU(0.3))(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(256, activation=LeakyReLU(0.3))(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "#model = create_model()\n",
    "model.load_weights('../weights/InceptionV2_Adam_With_DropOut.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Inception_Adam_Dropout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
