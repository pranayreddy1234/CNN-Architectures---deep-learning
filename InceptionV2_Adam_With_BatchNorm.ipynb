{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yld2InOdn1Mm"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "70z6vOi2n6q-",
    "outputId": "ec48cb4e-43de-4153-b676-22f982ad68f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0McGBQNn6t1"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 50 # iterations over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wZ5vLhon64R"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "KKBioWzNn67i",
    "outputId": "df92de47-3c43-48a0-bf04-95cf03b77fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVap-IGon6-g"
   },
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = BatchNormalization()(conv_11)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_2)\n",
    "conv_21 = BatchNormalization()(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation='relu')(X)\n",
    "X = Conv2D(64, 3, activation='relu')(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0Py-1C0Wn7EN",
    "outputId": "456decb9-215c-417f-d164-e0fd31b1792f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 32)   9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9248        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 32)   1056        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 32)   1056        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 32)   9248        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 32)   1056        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 128)  0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 32)   4128        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 32)   7200        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 32)   4128        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 32)   7200        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 32)   4128        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 32)   7200        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 32)   7200        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 32)   128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 32)   4128        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 128)  0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 32)   3104        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 32)   4128        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 32)   4128        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 192)  0           batch_normalization_10[0][0]     \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 30, 30, 32)   55328       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 28, 28, 64)   18496       conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 7, 7, 64)     0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1606144     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          51300       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,909,796\n",
      "Trainable params: 1,909,028\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuUvx9XAn7Kt"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cA5dOEPvn7O4"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate = 0.001,clipvalue = 0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bVKENCZnn7TA",
    "outputId": "248ec61d-fa20-44af-e993-adc547de8308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-10-8ac9fdfbecbc>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.8518 - accuracy: 0.1128\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.16690, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 3.8518 - accuracy: 0.1128 - val_loss: 3.5939 - val_accuracy: 0.1669\n",
      "Epoch 2/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.2293 - accuracy: 0.2137\n",
      "Epoch 00002: val_accuracy improved from 0.16690 to 0.25410, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 3.2293 - accuracy: 0.2137 - val_loss: 3.0850 - val_accuracy: 0.2541\n",
      "Epoch 3/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.9298 - accuracy: 0.2707\n",
      "Epoch 00003: val_accuracy improved from 0.25410 to 0.29570, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 2.9298 - accuracy: 0.2707 - val_loss: 2.9145 - val_accuracy: 0.2957\n",
      "Epoch 4/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.7201 - accuracy: 0.3129\n",
      "Epoch 00004: val_accuracy improved from 0.29570 to 0.33300, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 2.7201 - accuracy: 0.3129 - val_loss: 2.6891 - val_accuracy: 0.3330\n",
      "Epoch 5/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5588 - accuracy: 0.3416\n",
      "Epoch 00005: val_accuracy did not improve from 0.33300\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 2.5588 - accuracy: 0.3416 - val_loss: 2.7270 - val_accuracy: 0.3323\n",
      "Epoch 6/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4434 - accuracy: 0.3700\n",
      "Epoch 00006: val_accuracy improved from 0.33300 to 0.37130, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 2.4434 - accuracy: 0.3700 - val_loss: 2.5688 - val_accuracy: 0.3713\n",
      "Epoch 7/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3275 - accuracy: 0.3934\n",
      "Epoch 00007: val_accuracy improved from 0.37130 to 0.37810, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 2.3275 - accuracy: 0.3934 - val_loss: 2.4742 - val_accuracy: 0.3781\n",
      "Epoch 8/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2523 - accuracy: 0.4075\n",
      "Epoch 00008: val_accuracy improved from 0.37810 to 0.38820, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 2.2523 - accuracy: 0.4075 - val_loss: 2.3827 - val_accuracy: 0.3882\n",
      "Epoch 9/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1667 - accuracy: 0.4313\n",
      "Epoch 00009: val_accuracy did not improve from 0.38820\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 2.1667 - accuracy: 0.4313 - val_loss: 2.5923 - val_accuracy: 0.3615\n",
      "Epoch 10/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1044 - accuracy: 0.4405\n",
      "Epoch 00010: val_accuracy improved from 0.38820 to 0.42980, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 113ms/step - loss: 2.1044 - accuracy: 0.4405 - val_loss: 2.1836 - val_accuracy: 0.4298\n",
      "Epoch 11/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0556 - accuracy: 0.4528\n",
      "Epoch 00011: val_accuracy did not improve from 0.42980\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 2.0556 - accuracy: 0.4528 - val_loss: 2.2960 - val_accuracy: 0.4222\n",
      "Epoch 12/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9898 - accuracy: 0.4658\n",
      "Epoch 00012: val_accuracy improved from 0.42980 to 0.43520, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.9898 - accuracy: 0.4658 - val_loss: 2.2496 - val_accuracy: 0.4352\n",
      "Epoch 13/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9347 - accuracy: 0.4817\n",
      "Epoch 00013: val_accuracy improved from 0.43520 to 0.43690, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.9347 - accuracy: 0.4817 - val_loss: 2.2108 - val_accuracy: 0.4369\n",
      "Epoch 14/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8903 - accuracy: 0.4867\n",
      "Epoch 00014: val_accuracy improved from 0.43690 to 0.44320, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.8903 - accuracy: 0.4867 - val_loss: 2.1987 - val_accuracy: 0.4432\n",
      "Epoch 15/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8529 - accuracy: 0.4992\n",
      "Epoch 00015: val_accuracy improved from 0.44320 to 0.45530, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.8529 - accuracy: 0.4992 - val_loss: 2.1207 - val_accuracy: 0.4553\n",
      "Epoch 16/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8177 - accuracy: 0.5052\n",
      "Epoch 00016: val_accuracy improved from 0.45530 to 0.45560, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.8177 - accuracy: 0.5052 - val_loss: 2.1357 - val_accuracy: 0.4556\n",
      "Epoch 17/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7725 - accuracy: 0.5174\n",
      "Epoch 00017: val_accuracy improved from 0.45560 to 0.48450, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.7725 - accuracy: 0.5174 - val_loss: 1.9794 - val_accuracy: 0.4845\n",
      "Epoch 18/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7391 - accuracy: 0.5225\n",
      "Epoch 00018: val_accuracy did not improve from 0.48450\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.7391 - accuracy: 0.5225 - val_loss: 2.0791 - val_accuracy: 0.4804\n",
      "Epoch 19/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7084 - accuracy: 0.5286\n",
      "Epoch 00019: val_accuracy did not improve from 0.48450\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.7084 - accuracy: 0.5286 - val_loss: 2.1832 - val_accuracy: 0.4599\n",
      "Epoch 20/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6789 - accuracy: 0.5356\n",
      "Epoch 00020: val_accuracy improved from 0.48450 to 0.48740, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.6789 - accuracy: 0.5356 - val_loss: 2.0156 - val_accuracy: 0.4874\n",
      "Epoch 21/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6408 - accuracy: 0.5480\n",
      "Epoch 00021: val_accuracy did not improve from 0.48740\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.6408 - accuracy: 0.5480 - val_loss: 2.1764 - val_accuracy: 0.4715\n",
      "Epoch 22/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6148 - accuracy: 0.5531\n",
      "Epoch 00022: val_accuracy did not improve from 0.48740\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.6148 - accuracy: 0.5531 - val_loss: 2.0392 - val_accuracy: 0.4866\n",
      "Epoch 23/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5934 - accuracy: 0.5562\n",
      "Epoch 00023: val_accuracy did not improve from 0.48740\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.5934 - accuracy: 0.5562 - val_loss: 2.0575 - val_accuracy: 0.4817\n",
      "Epoch 24/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5698 - accuracy: 0.5638\n",
      "Epoch 00024: val_accuracy did not improve from 0.48740\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.5698 - accuracy: 0.5638 - val_loss: 2.1192 - val_accuracy: 0.4774\n",
      "Epoch 25/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5534 - accuracy: 0.5660\n",
      "Epoch 00025: val_accuracy did not improve from 0.48740\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.5534 - accuracy: 0.5660 - val_loss: 2.0707 - val_accuracy: 0.4845\n",
      "Epoch 26/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5217 - accuracy: 0.5735\n",
      "Epoch 00026: val_accuracy improved from 0.48740 to 0.48820, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.5217 - accuracy: 0.5735 - val_loss: 2.0733 - val_accuracy: 0.4882\n",
      "Epoch 27/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5010 - accuracy: 0.5778\n",
      "Epoch 00027: val_accuracy did not improve from 0.48820\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.5010 - accuracy: 0.5778 - val_loss: 2.1523 - val_accuracy: 0.4803\n",
      "Epoch 28/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4785 - accuracy: 0.5833\n",
      "Epoch 00028: val_accuracy improved from 0.48820 to 0.50220, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.4785 - accuracy: 0.5833 - val_loss: 2.0385 - val_accuracy: 0.5022\n",
      "Epoch 29/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.5866\n",
      "Epoch 00029: val_accuracy did not improve from 0.50220\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.4617 - accuracy: 0.5866 - val_loss: 2.1339 - val_accuracy: 0.4925\n",
      "Epoch 30/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4451 - accuracy: 0.5914\n",
      "Epoch 00030: val_accuracy improved from 0.50220 to 0.50620, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.4451 - accuracy: 0.5914 - val_loss: 1.9640 - val_accuracy: 0.5062\n",
      "Epoch 31/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4212 - accuracy: 0.5998\n",
      "Epoch 00031: val_accuracy did not improve from 0.50620\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.4212 - accuracy: 0.5998 - val_loss: 2.0101 - val_accuracy: 0.4990\n",
      "Epoch 32/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4045 - accuracy: 0.6016\n",
      "Epoch 00032: val_accuracy did not improve from 0.50620\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.4045 - accuracy: 0.6016 - val_loss: 2.1011 - val_accuracy: 0.5031\n",
      "Epoch 33/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3836 - accuracy: 0.6075\n",
      "Epoch 00033: val_accuracy did not improve from 0.50620\n",
      "391/390 [==============================] - 43s 110ms/step - loss: 1.3836 - accuracy: 0.6075 - val_loss: 2.0601 - val_accuracy: 0.4942\n",
      "Epoch 34/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3686 - accuracy: 0.6108\n",
      "Epoch 00034: val_accuracy improved from 0.50620 to 0.51660, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.3686 - accuracy: 0.6108 - val_loss: 1.9562 - val_accuracy: 0.5166\n",
      "Epoch 35/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3443 - accuracy: 0.6179\n",
      "Epoch 00035: val_accuracy did not improve from 0.51660\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.3443 - accuracy: 0.6179 - val_loss: 2.1504 - val_accuracy: 0.4898\n",
      "Epoch 36/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3344 - accuracy: 0.6208\n",
      "Epoch 00036: val_accuracy did not improve from 0.51660\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.3344 - accuracy: 0.6208 - val_loss: 2.1709 - val_accuracy: 0.4899\n",
      "Epoch 37/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3164 - accuracy: 0.6253\n",
      "Epoch 00037: val_accuracy improved from 0.51660 to 0.51770, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 43s 110ms/step - loss: 1.3164 - accuracy: 0.6253 - val_loss: 1.9717 - val_accuracy: 0.5177\n",
      "Epoch 38/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2969 - accuracy: 0.6300\n",
      "Epoch 00038: val_accuracy did not improve from 0.51770\n",
      "391/390 [==============================] - 43s 109ms/step - loss: 1.2969 - accuracy: 0.6300 - val_loss: 2.0900 - val_accuracy: 0.4998\n",
      "Epoch 39/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2963 - accuracy: 0.6271\n",
      "Epoch 00039: val_accuracy improved from 0.51770 to 0.52050, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.2963 - accuracy: 0.6271 - val_loss: 1.9987 - val_accuracy: 0.5205\n",
      "Epoch 40/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2806 - accuracy: 0.6313\n",
      "Epoch 00040: val_accuracy did not improve from 0.52050\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.2806 - accuracy: 0.6313 - val_loss: 2.0879 - val_accuracy: 0.5102\n",
      "Epoch 41/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2642 - accuracy: 0.6355\n",
      "Epoch 00041: val_accuracy did not improve from 0.52050\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.2642 - accuracy: 0.6355 - val_loss: 2.0835 - val_accuracy: 0.5100\n",
      "Epoch 42/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2413 - accuracy: 0.6437\n",
      "Epoch 00042: val_accuracy did not improve from 0.52050\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.2413 - accuracy: 0.6437 - val_loss: 1.9475 - val_accuracy: 0.5180\n",
      "Epoch 43/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2331 - accuracy: 0.6427\n",
      "Epoch 00043: val_accuracy did not improve from 0.52050\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.2331 - accuracy: 0.6427 - val_loss: 2.0963 - val_accuracy: 0.5059\n",
      "Epoch 44/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2214 - accuracy: 0.6498\n",
      "Epoch 00044: val_accuracy improved from 0.52050 to 0.52830, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.2214 - accuracy: 0.6498 - val_loss: 1.9673 - val_accuracy: 0.5283\n",
      "Epoch 45/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2125 - accuracy: 0.6499\n",
      "Epoch 00045: val_accuracy did not improve from 0.52830\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.2125 - accuracy: 0.6499 - val_loss: 2.1469 - val_accuracy: 0.5015\n",
      "Epoch 46/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2029 - accuracy: 0.6536\n",
      "Epoch 00046: val_accuracy did not improve from 0.52830\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.2029 - accuracy: 0.6536 - val_loss: 2.0633 - val_accuracy: 0.5227\n",
      "Epoch 47/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1849 - accuracy: 0.6570\n",
      "Epoch 00047: val_accuracy did not improve from 0.52830\n",
      "391/390 [==============================] - 43s 111ms/step - loss: 1.1849 - accuracy: 0.6570 - val_loss: 2.0732 - val_accuracy: 0.5221\n",
      "Epoch 48/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1716 - accuracy: 0.6604\n",
      "Epoch 00048: val_accuracy did not improve from 0.52830\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.1716 - accuracy: 0.6604 - val_loss: 2.0502 - val_accuracy: 0.5124\n",
      "Epoch 49/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1672 - accuracy: 0.6588\n",
      "Epoch 00049: val_accuracy did not improve from 0.52830\n",
      "391/390 [==============================] - 44s 111ms/step - loss: 1.1672 - accuracy: 0.6588 - val_loss: 2.0061 - val_accuracy: 0.5243\n",
      "Epoch 50/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1550 - accuracy: 0.6638\n",
      "Epoch 00050: val_accuracy improved from 0.52830 to 0.52890, saving model to Inception_Adam_BN.hdf5\n",
      "391/390 [==============================] - 44s 112ms/step - loss: 1.1550 - accuracy: 0.6638 - val_loss: 2.0071 - val_accuracy: 0.5289\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# save model after each epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"Inception_Adam_BN.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "#hist=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=50, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "8NhxdYj9n7WS",
    "outputId": "0204bf93-ef02-4794-c7cf-a550aa65ea4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.5473424806879272\n",
      "Recall: 0.5289\n",
      "Accuracy: 0.5289\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, classification_report\n",
    "#print(classification_report(y_true,y_pred))\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "EqeYlYwDn7HA",
    "outputId": "6e6ce5a1-7491-4c06-9193-6cbf2c9fc10e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVhV1frA8e9iEEQGRVEcUEwFHBAFUcs5rczM2dIsM0vLW5aV3eb0Wjb8svleLdPUytSyNM3UctacJScmR0YFBWSez3l/f5wjgQKCcEBlfZ7nPHH2XnvtdyOd9+y11l5LiQiapmlazWVV3QFomqZp1UsnAk3TtBpOJwJN07QaTicCTdO0Gk4nAk3TtBpOJwJN07QaTicCrUZRSi1WSr1TxrIRSqkBlo5J06qbTgSapmk1nE4EmnYTUkrZVHcM2q1DJwLthmNuknlJKXVUKZWhlFqolGqklFqvlEpTSm1SStUrVH6IUipYKZWslNqmlGpbaF9npVSQ+bgVgP0V5xqslDpsPna3UqpjGWO8Tyn1t1IqVSkVrZSaecX+nub6ks37J5i311ZKfaSUilRKpSildpm39VVKxRTzexhg/nmmUmqlUup7pVQqMEEp1VUptcd8jvNKqf8qpWoVOr69UupPpVSSUipeKfWaUspdKZWplKpfqJy/UuqiUsq2LNeu3Xp0ItBuVCOBuwAv4H5gPfAa4Ibp7/ZZAKWUF7AMmGbe9zuwVilVy/yhuBr4DnAFfjLXi/nYzsA3wJNAfeArYI1Syq4M8WUA44G6wH3AFKXUMHO9LczxfmGOqRNw2HzcHCAAuMMc078BYxl/J0OBleZzLgUMwPNAA+B2oD/wL3MMTsAmYAPQBGgNbBaROGAb8ECheh8BlotIXhnj0G4xOhFoN6ovRCReRGKBncA+EflbRLKBVUBnc7kHgXUi8qf5g2wOUBvTB213wBb4VETyRGQlcKDQOSYDX4nIPhExiMgSIMd8XKlEZJuIHBMRo4gcxZSM+ph3PwRsEpFl5vMmishhpZQVMBF4TkRizefcLSI5Zfyd7BGR1eZzZonIIRHZKyL5IhKBKZFdjmEwECciH4lItoikicg+874lwMMASilrYCymZKnVUDoRaDeq+EI/ZxXz3tH8cxMg8vIOETEC0UBT875YKTqzYmShn1sAL5qbVpKVUsmAh/m4UimluimltpqbVFKApzB9M8dcx+liDmuAqWmquH1lEX1FDF5Kqd+UUnHm5qJ3yxADwK9AO6VUS0x3XSkisv86Y9JuAToRaDe7c5g+0AFQSilMH4KxwHmgqXnbZc0L/RwNzBaRuoVeDiKyrAzn/QFYA3iIiAvwJXD5PNFAq2KOSQCyS9iXATgUug5rTM1KhV05VfA8IAxoIyLOmJrOCsdwW3GBm++qfsR0V/AI+m6gxtOJQLvZ/Qjcp5Tqb+7sfBFT885uYA+QDzyrlLJVSo0AuhY69mvgKfO3e6WUqmPuBHYqw3mdgCQRyVZKdcXUHHTZUmCAUuoBpZSNUqq+UqqT+W7lG+BjpVQTpZS1Uup2c5/ECcDefH5b4A3gWn0VTkAqkK6U8gGmFNr3G9BYKTVNKWWnlHJSSnUrtP9bYAIwBJ0IajydCLSbmoiEY/pm+wWmb9z3A/eLSK6I5AIjMH3gJWHqT/il0LEHgUnAf4FLwClz2bL4FzBLKZUGvIUpIV2uNwoYhCkpJWHqKPYz754OHMPUV5EEfABYiUiKuc4FmO5mMoAio4iKMR1TAkrDlNRWFIohDVOzz/1AHHAS6Fdo/1+YOqmDRKRwc5lWAym9MI2m1UxKqS3ADyKyoLpj0aqXTgSaVgMppQKBPzH1caRVdzxa9dJNQ5pWwyillmB6xmCaTgIa6DsCTdO0Gs/idwTmkRF/K6V+K2afnVJqhVLqlFJqn1LK09LxaJqmaUVVxcRVzwGhgHMx+x4HLolIa6XUGEwjKB4srbIGDRqIp6dnpQepaZp2Kzt06FCCiFz5bApg4USglGqGaR6W2cALxRQZCsw0/7wS+K9SSkkp7VWenp4cPHiwskPVNE27pSmlShwmbOmmoU8pfVKtppgfmxeRfCAF0+RfRSilJiulDiqlDl68eNFSsWqaptVIFksESqnBwAUROVTRukRkvoh0EZEubm7F3tlomqZp18mSdwQ9gCFKqQhgOXCnUur7K8rEYpoX5vJCGy5AogVj0jRN065gsT4CEXkVeBVAKdUXmC4iD19RbA3wKKY5YUYBW0rrH9A0rai8vDxiYmLIzs6u7lC0G4S9vT3NmjXD1rbs6wxV+XJ3SqlZwEERWQMsBL5TSp3CNO/KmKqOR9NuZjExMTg5OeHp6UnRSVa1mkhESExMJCYmhpYtW5b5uCpJBCKyDdOqSIjIW4W2ZwOjqyIGTbsVZWdn6ySgFVBKUb9+fco7qEZPMaFpNzmdBLTCrufvocYkgpOXTvLxwY/JyMuo7lA0TdNuKDUmEZxLP8ei4EWcvHSyukPRtFvO6tWrUUoRFhZW3aFo16HGJAJvV28AQpNCqzkSTbv1LFu2jJ49e7JsWVlW+bw+BoPBYnXXdDUmETRyaERdu7qEJ4VXdyiadktJT09n165dLFy4kOXLlwOmD+3p06fToUMHOnbsyBdffAHAgQMHuOOOO/Dz86Nr166kpaWxePFinnnmmYL6Bg8ezLZt2wBwdHTkxRdfxM/Pjz179jBr1iwCAwPp0KEDkydP5vJo81OnTjFgwAD8/Pzw9/fn9OnTjB8/ntWrVxfUO27cOH799dcq+q3cXKp8+Gh1UUrh4+pDWJK+ddVuTf9ZG0zIudRKrbNdE2dm3N++1DK//vorAwcOxMvLi/r163Po0CH2799PREQEhw8fxsbGhqSkJHJzc3nwwQdZsWIFgYGBpKamUrt27VLrzsjIoFu3bnz00UemeNq14623TAMPH3nkEX777Tfuv/9+xo0bxyuvvMLw4cPJzs7GaDTy+OOP88knnzBs2DBSUlLYvXs3S5YsqZxfzC2mxtwRAPi4+nDy0knyjHnVHYqm3TKWLVvGmDGmR4DGjBnDsmXL2LRpE08++SQ2Nqbvmq6uroSHh9O4cWMCAwMBcHZ2LthfEmtra0aOHFnwfuvWrXTr1g1fX1+2bNlCcHAwaWlpxMbGMnz4cMD0QJWDgwN9+vTh5MmTXLx4kWXLljFy5Mhrnq+mqlG/FW9Xb3KNuUSkRNCmXpvqDkfTKtW1vrlbQlJSElu2bOHYsWMopTAYDCilCj7sy8LGxgaj8Z95KQs/JW1vb4+1tXXB9n/9618cPHgQDw8PZs6cec0nqsePH8/333/P8uXLWbRoUTmvruaoUXcEbV3bAujmIU2rJCtXruSRRx4hMjKSiIgIoqOjadmyJX5+fnz11Vfk5+cDpoTh7e3N+fPnOXDgAABpaWnk5+fj6enJ4cOHMRqNREdHs3///mLPdflDv0GDBqSnp7Ny5UoAnJycaNasWUF/QE5ODpmZmQBMmDCBTz/9FDA1K2nFq1GJoIVzC+ys7XQi0LRKsmzZsoImmctGjhzJ+fPnad68OR07dsTPz48ffviBWrVqsWLFCqZOnYqfnx933XUX2dnZ9OjRg5YtW9KuXTueffZZ/P39iz1X3bp1mTRpEh06dOCee+4pctfx3Xff8fnnn9OxY0fuuOMO4uLiAGjUqBFt27blscces9wv4RZw061Z3KVLF6nIwjRjfxtLHds6LLhnQSVGpWnVIzQ0lLZt21Z3GDeszMxMfH19CQoKwsXFpbrDqTLF/V0opQ6JSJfiyteoOwIAn/o+hF0K42ZLgJqmlc+mTZto27YtU6dOrVFJ4HrUqM5iAJ96Pqw8sZK4jDgaOzau7nA0TbOQAQMGEBlZ4uqMWiE17o7g8hPGup9A0zTNpEYlAhHBq54XCkXYJZ0INE3ToAYlgrQtWzjZoye2Sem0cG5BWKJOBJqmaVCDEoFNgwYYkpLI+jsIH1cfwi/pOYc0TdOgBiUC+7ZtUfb2ZAaZEkFseiypuZU7L4um1TT9+vVj48aNRbZ9+umnTJkypcRj+vbty+Uh4IMGDSI5OfmqMjNnzmTOnDmlnnv16tWEhIQUvH/rrbfYtGlTecIv1bRp02jatGmRp55vVRZLBEope6XUfqXUEaVUsFLqP8WUmaCUuqiUOmx+PWGxeGxtqe3rS1bQ3/i4+gDomUg1rYLGjh1bMOPoZcuXL2fs2LFlOv7333+nbt2613XuKxPBrFmzGDBgwHXVdSWj0ciqVavw8PBg+/btlVJncS4/eV3dLHlHkAPcKSJ+QCdgoFKqezHlVohIJ/PLok951fb3Jzs0FK/azQE9ckjTKmrUqFGsW7eO3NxcACIiIjh37hy9evViypQpdOnShfbt2zNjxoxij/f09CQhIQGA2bNn4+XlRc+ePQkP/+dL2tdff01gYCB+fn6MHDmSzMxMdu/ezZo1a3jppZfo1KkTp0+fZsKECQXTTmzevJnOnTvj6+vLxIkTycnJKTjfjBkz8Pf3x9fXt8SFdLZt20b79u2ZMmVKkTUW4uPjGT58OH5+fvj5+bF7924Avv3224KnqB955BGAIvGAaUrty3X36tWLIUOGFEx7MWzYMAICAmjfvj3z588vOGbDhg34+/vj5+dH//79MRqNtGnTpmBNYqPRSOvWrcu9RvGVLPYcgZie2Eo3v7U1v6r1KS6HAH8SvzLgcOIcDWo30IlAu7WsfwXijlVune6+cO/7Je52dXWla9eurF+/nqFDh7J8+XIeeOABlFLMnj0bV1dXDAYD/fv35+jRo3Ts2LHYeg4dOsTy5cs5fPgw+fn5+Pv7ExAQAMCIESOYNGkSAG+88QYLFy5k6tSpDBkyhMGDBzNq1KgidWVnZzNhwgQ2b96Ml5cX48ePZ968eUybNg0wzVUUFBTE3LlzmTNnDgsWXP39c9myZYwdO5ahQ4fy2muvkZeXh62tLc8++yx9+vRh1apVGAwG0tPTCQ4O5p133mH37t00aNCApKSka/5ag4KCOH78OC1btgTgm2++wdXVlaysLAIDAxk5ciRGo5FJkyaxY8cOWrZsSVJSElZWVjz88MMsXbqUadOmsWnTJvz8/HBzc7vmOUtj0T4CpZS1UuowcAH4U0T2FVNspFLqqFJqpVLKo4R6JiulDiqlDlYk89Xu1AmUKugw1olA0yqucPNQ4WahH3/8EX9/fzp37kxwcHCRZpwr7dy5k+HDh+Pg4ICzszNDhgwp2Hf8+HF69eqFr68vS5cuJTg4uNR4wsPDadmyJV5eXgA8+uij7Nixo2D/iBEjAAgICCAiIuKq43Nzc/n9998ZNmwYzs7OdOvWraAfZMuWLQX9H9bW1ri4uLBlyxZGjx5NgwYNAFNyvJauXbsWJAGAzz//HD8/P7p37050dDQnT55k79699O7du6Dc5XonTpzIt99+C5gSSGXMo2TRJ4tFxAB0UkrVBVYppTqIyPFCRdYCy0QkRyn1JLAEuLOYeuYD88E019D1xmPt7Ixd69ZkHgrCp1sH9p7bS64hl1rWta63Sk27cZTyzd2Shg4dyvPPP09QUBCZmZkEBARw9uxZ5syZw4EDB6hXrx4TJky45pTRJZkwYQKrV6/Gz8+PxYsXF6xedr3s7OwA0wd5cW30GzduJDk5GV9fX8A0X1Ht2rUZPHhwuc5TeHpto9FY0HwGUKdOnYKft23bxqZNm9izZw8ODg707du31N+Vh4cHjRo1YsuWLezfv5+lS5eWK67iVMmoIRFJBrYCA6/YnigiOea3C4AAS8dS29+frMOH8XZpQ77kczr5tKVPqWm3NEdHR/r168fEiRML7gZSU1OpU6cOLi4uxMfHs379+lLr6N27N6tXryYrK4u0tDTWrl1bsC8tLY3GjRuTl5dX5EPPycmJtLS0q+ry9vYmIiKCU6dOAaaZSfv06VPm61m2bBkLFiwgIiKCiIgIzp49y59//klmZib9+/dn3rx5gGk5zpSUFO68805++uknEhMTAQqahjw9PTl06BAAa9asIS+v+AWxUlJSqFevHg4ODoSFhbF3714Aunfvzo4dOzh79myRegGeeOIJHn74YUaPHl2wXkNFWHLUkJv5TgClVG3gLiDsijKFJ/sZAlh8ZXkH/84Y09PxTjYtkaebhzSt4saOHcuRI0cKEoGfnx+dO3fGx8eHhx56iB49epR6vL+/Pw8++CB+fn7ce++9RaaYfvvtt+nWrRs9evTAx8enYPuYMWP48MMP6dy5M6dP//OFzt7enkWLFjF69Gh8fX2xsrLiqaeeKtN1ZGZmsmHDBu67776CbXXq1KFnz56sXbuWzz77jK1bt+Lr60tAQAAhISG0b9+e119/nT59+uDn58cLL7wAwKRJk9i+fXvBesuF7wIKGzhwIPn5+bRt25ZXXnmF7t1NY2rc3NyYP38+I0aMwM/PjwcffLDgmCFDhpCenl5p02tbbBpqpVRHTE091pgSzo8iMkspNQs4KCJrlFLvYUoA+UASMEVESv1krug01LnR0Zy+624avvUm98qnDG89nFe7vXrd9WladdLTUNdMBw8e5Pnnn2fnzp3F7i/vNNSWHDV0FOhczPa3Cv38KlCln8K2zZph7daA7L8P493PW98RaJp2U3n//feZN29epfQNXFZjniy+TCmFQ2d/soL+mWrCKLf+k4Oapt0aXnnlFSIjI+nZs2el1VnjEgFAbf/O5MXG0kGakJGXQWxabHWHpGmaVm1qZCJwMK+J2jraNHRMT0mtaVpNViMTweUJ6OqeiMNaWROaaPHBSpqmaTesGpkILk9Al3v4KC1dWuopqTVNq9FqZCKAfyag61CntR45pGnX6fJEatrNrcYmAocAfzAY6JzgyIXMCyRlX3uiKE3TtFtRjU0ElyegaxlpmuFCL12paddPRHjppZfo0KEDvr6+rFixAoDz58/Tu3dvOnXqRIcOHdi5cycGg4EJEyYUlP3kk0+qOXrNopPO3cguT0BnF34e2ya2bI/Zzh1N76jusDTtun2w/4NKb+b0cfXh5a4vX7PcL7/8wuHDhzly5AgJCQkEBgbSu3dvfvjhB+655x5ef/11DAYDmZmZHD58mNjYWI4fN80/WdwKZVrVqrF3BGDqJ8g7epy7mvVn7Zm1ZOdf3+yImlbT7dq1i7Fjx2JtbU2jRo3o06cPBw4cIDAwkEWLFjFz5kyOHTuGk5MTt912G2fOnGHq1Kls2LABZ2fn6g6/xquxdwRgmoAuecUKRtl24/fcDWyK2sTg28o31aym3SjK8s29qvXu3ZsdO3awbt06JkyYwAsvvMD48eM5cuQIGzdu5Msvv+THH3/km2++qe5Qa7Qaf0cAcFtULs0cm/HziZ+rOSJNuzn16tWLFStWYDAYuHjxIjt27KBr165ERkbSqFEjJk2axBNPPEFQUBAJCQkYjUZGjhzJO++8Q1BQUHWHX+PV6DuCwhPQjRw/ks+CPiMiJQJPF8/qDk3TbirDhw9nz549+Pn5oZTi//7v/3B3d2fJkiV8+OGH2Nra4ujoyLfffktsbCyPPfZYwaIt7733XjVHr1lsGmpLqeg01FeKefY5soODcVm7jLtW3sWj7R/l+YDnK61+TbMkPQ21VpzyTkNdo5uG4J8J6OqmCb2b9ebXU7+SZyx+JSFN07RbUY1PBJcnoEvfto2RbUaSmJ3Ijugd1zhK0zTt1lHjE4F9hw7U9vPjwscf082mNQ0dGrLy5MrqDkvTNK3KWHLNYnul1H6l1BGlVLBS6j/FlLFTSq1QSp1SSu1TSnlaKp4S47SyoskH7yO5uVx4cybDWg3lr9i/iMuIq+pQNE3TqoUl7whygDtFxA/oBAxUSnW/oszjwCURaQ18AnxgwXhKVMvTk0b/fomMXbsYfNQWgFUnV1VHKJqmaVXOYolATNLNb23NryuHKA3FtMA9wEqgv1JKWSqm0tQdM4Y6PXuS89nXDLT2Y9WpVRiMhuoIRdM0rUpZtI9AKWWtlDoMXAD+FJF9VxRpCkQDiEg+kALUL6aeyUqpg0qpgxcvXrRUrDSe/Q6qVi0eWnmR+LRz7D2/1yLn0rRbRb9+/di4cWORbZ9++ilTpkwp8Zi+fftyeQj4oEGDip1raObMmcyZM6fUc69evZqQkJCC92+99RabNm0qT/jF2rZtG4MH16wZBiyaCETEICKdgGZAV6VUh+usZ76IdBGRLm5ubpUbZCG2jRrh/tab2IVFMuaAHT+f1E8aa1ppxo4dy/Lly4tsW758OWPHji3T8b///jt169a9rnNfmQhmzZrFgAEDrquumq5KRg2JSDKwFRh4xa5YwANAKWUDuACJVRFTSVzuuw/nQYMYsj2LM/s3k5hVreFo2g1t1KhRrFu3jtzcXAAiIiI4d+4cvXr1YsqUKXTp0oX27dszY8aMYo/39PQkISEBgNmzZ+Pl5UXPnj0JD/9n1cCvv/6awMBA/Pz8GDlyJJmZmezevZs1a9bw0ksv0alTJ06fPs2ECRNYudI04m/z5s107twZX19fJk6cSE5OTsH5ZsyYgb+/P76+voSFlX221mXLluHr60uHDh14+WXTvE4lTan9+eef065dOzp27MiYMWPK+VutehabYkIp5QbkiUiyUqo2cBdXdwavAR4F9gCjgC1yAzzq7P7Wm6Qe2MeUNYms7v8Tjwc8Vd0hado1xb37LjmhlTsNtV1bH9xfe63E/a6urnTt2pX169czdOhQli9fzgMPPIBSitmzZ+Pq6orBYKB///4cPXqUjh07FlvPoUOHWL58OYcPHyY/Px9/f38CAgIAGDFiBJMmTQLgjTfeYOHChUydOpUhQ4YwePBgRo0aVaSu7OxsJkyYwObNm/Hy8mL8+PHMmzePadOmAdCgQQOCgoKYO3cuc+bMYcGCBdf8PZw7d46XX36ZQ4cOUa9ePe6++25Wr16Nh4dHsVNqv//++5w9exY7O7ubYpptS94RNAa2KqWOAgcw9RH8ppSapZQaYi6zEKivlDoFvAC8YsF4ysy6bl083n2f5glw6cv5pOSkVHdImnbDKtw8VLhZ6Mcff8Tf35/OnTsTHBxcpBnnSjt37mT48OE4ODjg7OzMkCFDCvYdP36cXr164evry9KlSwkODi41nvDwcFq2bImXlxcAjz76KDt2/POQ6IgRIwAICAggIiKiTNd44MAB+vbti5ubGzY2NowbN44dO3aUOKV2x44dGTduHN9//z02Njf+lG4Wi1BEjgKdi9n+VqGfs4HRloqhIhx79YS7+zBgy3aW7PiUZ+8q/tZW024UpX1zt6ShQ4fy/PPPExQURGZmJgEBAZw9e5Y5c+Zw4MAB6tWrx4QJE8jOvr71PiZMmMDq1avx8/Nj8eLFbNu2rULx2tnZAWBtbU1+fn6F6qpXr16xU2qvW7eOHTt2sHbtWmbPns2xY8du6IRQ458sLk2rF1/FVhTGJT8RnRpd3eFo2g3J0dGRfv36MXHixIK7gdTUVOrUqYOLiwvx8fGsX7++1Dp69+7N6tWrycrKIi0tjbVr1xbsS0tLo3HjxuTl5bF06dKC7U5OTqSlpV1Vl7e3NxEREZw6dQqA7777jj59+lToGrt27cr27dtJSEjAYDCwbNky+vTpU+yU2kajkejoaPr168cHH3xASkoK6enp1z5JNbpxU9QNoFaLFtQeOpj+q9fy9R+zmTXqy+oOSdNuSGPHjmX48OEFTUR+fn507twZHx8fPDw86NGjR6nH+/v78+CDD+Ln50fDhg0JDAws2Pf222/TrVs33Nzc6NatW8GH/5gxY5g0aRKff/55QScxgL29PYsWLWL06NHk5+cTGBjIU0+Vr59v8+bNNGvWrOD9Tz/9xPvvv0+/fv0QEe677z6GDh3KkSNHrppS22Aw8PDDD5OSkoKI8Oyzz173yKiqUuOnob6WvLg4Ttw1gO1tjXT/4nv8G/lX2bk17Vr0NNRacfQ01JXM1t0dlzFj6HNMWLTuHYxirO6QNE3TKpVOBGXg/tQUsKtFp7VhrD9belunpmnazUYngjKwqV8ftwmPcUeosHLdh2TnX9/oB02zhJuteVezrOv5e9CJoIzqT5yIODrQf8MFvg/9vrrD0TTA1DGamJiok4EGmJJAYmIi9vb25TpOjxoqI2tnZxpOfoqAjz9m9u9fMrz1cOrXvmp+PESEappAVauBmjVrRkxMDJaajFG7+djb2xcZ8VQWetRQORgzMwkfMIBgxxSOzxjFzB7/QUTICQ0l9Y8/SPvjTwypqbT8cQW2TZpUS4yapmnFKW3UkL4jKAcrBwcaPTUF3n2XfctXcmh9Ei57w8iLiQErKxwCA8mPjyf2xem0+HYJyta2ukPWNE27Jt1HUE51xzyIjbs7E/80UuuXTeDZjMbvvE2bv3bRYsli3Gf9h6y//+bi519Ud6iapmllou8IysmqVi085s0l+vhenkqdS+tmVsy/azjWVtaAaRrrzH37Sfz6axy6djXNWaRpmnYD03cE18G+bVvajH6Mab1fY3/cfr45/k2R/Y1eexW7Nm049/LL5MVfqKYoNU3TykYnggoY1noY93rey/8O/4/DFw4XbLeyt6fpp59gzMri3EsvIQa99rGmaTcunQgqQCnFm7e/iXsdd17e8TKpuakF++xatcJ9xltk7t9Pwjw9WZ2maTcunQgqyKmWEx/0/oD4zHhm7ZlV5MGeusOG4TJsGAn/+x8Ze/dVyvkuzp1L7PSXKqUuTdM00ImgUvi5+fFM52fYGLGRVadWFdnn/uYb1GrZknMvvURuVFSFzpNz9iwJc+eR+ttv5JvXedU0TasonQgqycQOE+nWuBvv7nuX3ed2F2y3qlOHpp98guTmcnb0A6Tv+uu6z3Fhzkdgfmo5feeuCsesaZoGFkwESikPpdRWpVSIUipYKfVcMWX6KqVSlFKHza+3iqvrZmClrPiw94d4OnsydfNUdsbsLNhn7+2F58qfsG3UiOjJk0lc+E2554bJ2Lef9M2bcXv6aWzc3MjYuePaB2mappWBJe8I8oEXRaQd0B14WinVrphyO0Wkk/k1y4LxWFw9+3osuHsBreq24rmtz7E9envBvloeHnguX4bT3Xdz4YY29icAACAASURBVMMPOTf9JYxZWWWqV4xG4j94H5smjXGd8Ch1evUifddfSAXXW9U0TQMLJgIROS8iQeaf04BQoKmlznejqGtfl6/v/hqvel5M2zaNzVGbC/ZZOTjQ9JOPcXvhBVJ//52Ih8aRFxt7zTpTfl1DTkgoDZ9/ASt7exx798aYmkrWkSOWvBRN02qIKukjUEp5Ap2B4obO3K6UOqKUWq+Ual/C8ZOVUgeVUgdvhlkWXexcmH/3fNq5tmP6tun8EfFHwT6lFA0mT8Ljqy/Ji4nh7MhRZOzZU2JdxsxMLn76Kfa+vjjfNwiAOnfcDtbWpO/YWeJxmqZpZWXxRKCUcgR+BqaJSOoVu4OAFiLiB3wBrC6uDhGZLyJdRKSLm5ubZQOuJM61nPnqrq/wdfPl3zv+zYazG4rsd+zdm5Y//Yh1g/pEPf4ECfO/LrbfIHHRIvLj42n0yssoK9M/l7WzMw6dO5O+Q/cTaJpWcRZNBEopW0xJYKmI/HLlfhFJFZF088+/A7ZKqQaWjKkqOdZy5MsBX9KpYSde3vkyv535rcj+Wp6etFyxAueB93Dx44+JeWYqhrS0gv158RdIXLAQp7vvxiEgoMixdfr0Jic0VE9hoWlahVly1JACFgKhIvJxCWXczeVQSnU1x5NoqZiqg4OtA3P7z6VLoy68vut11pxeU2S/VZ06NPnoIxq99irp27dzdtQossNPAHDx88+Q/HwaTn/xqnode/cGIGOXbh7SNK1iLHlH0AN4BLiz0PDQQUqpp5RST5nLjAKOK6WOAJ8DY+RmWymnDBxsHfhv///S1b0rb+x6g1Uniz50ppTCdfx4WixZjDEzk4gHH+Ti//5Hyi+rcB03jlrNm19Vp52XFzaNGul+Ak3TKkyvUFaFsvOzeW7rc+w5t4cZt89gpNfIq8rkXbhA7AsvkHXwENYuLrT6YyPWLi7F1nf+zTdJXb8Brz279SI4mqaVqrQVyvSTxVXI3saez+/8nDua3sHMPTP5MfzHq8rYNmxIi0WLcHvhBZp8+H8lJgGAOr17Y0xPJ/Pvvy0ZtqZpt7hrJgKl1P1KKZ0wKomdtR2f9fuM3s168/bet1ketvyqMsrWlgaTJxX0A5Skzu23g40NGTt185CmadevLB/wDwInlVL/p5TysXRANYGdtR2f9P2Evs36MnvfbOYcmENWftmeMi7M2tERh4AA0rfrYaSapl2/ayYCEXkY08Ngp4HFSqk95ge8nCwe3S2slnUtPu77MaO9RrMkZAkjfh3BnnMlP1hWEsfevck5cYK8uLhi94sI2WFhSG5uRUPWNO0WVaYmH/ODYCuB5UBjYDgQpJSaasHYbnm21ra8dftbfHPPN1hbWTP5z8m8sesNkrOTy1yHY+9eAMU+XCYixL/3HmeHDedkvzuJ//BDcs6erbT4NU27NZSlj2CIUmoVsA2wBbqKyL2AH3D1AHet3ALdA/l5yM9M8p3EujPrGPrrUNafXV+mGUprtW6NTZPGV/UTiMFA3FszuPTtd7gMH07tzp1IWryEM/cOIvKR8aSsXYsxJ8dSl6Rp2k3kmsNHlVJLgIUictVXTqVUfxHZXMxhFnMzDx8ti/CkcGbunsnxxOPc6XEns3rMwsWu5JFDAOdnzCR17Vq89u5B1aqF5Odz7tXXSF27lvpPPYnbc8+hlCLvwgVSVv9K8sqV5EVFYeXigvM99+B0z93U6dYNZWNTRVepaVpVK234aFkSQUvgvIhkm9/XBhqJSERlB1oWt3oiADAYDXwX8h2f/f0Z9e3r836v9+niXuy/HwBpW7YQ86+nab54EQ7+/sS+OJ20P//Ebdo0Gjz15FXlxWgkc/9+klf+TNqWLUhmJtZ16+J01wCc7hlInW5d9XMJmnaLqWgiOAjcISK55ve1gL9EJLDSIy2DmpAILgtODObf2/9NTHoMT3Z8kskdJ2NjdfW3dmNGBie6307d0aPJjYkmY8dOGr32Kq7jx1/zHMbsbDJ27SJ1w0bSt2zBmJmJtYsLtTt1wqZRI2waNsSmoRu25p9rNW+OVZ06lrhcTdMsqKKJ4LCIdLpi2xHzjKFVriYlAoCMvAze3fcua06vwb+hPx/0/gD3Ou5XlYuaOJGM3XtAKdz/M5N6DzxQ7nMZc3LI+Osv0jZuJPvkSfLjL2BILDr1k5WTE41eeQWXEcMxTxNVJQzpGRgSLlLL07PKzqlpt5KKJoI/gS9EZI35/VDgWRHpX+mRlkFNSwSXrT29lnf2voONlQ1v3v4m97S4p8gH8aUVPxI3axZN3nsXlyFDKu28kptLfkIC+RcukBcXz6Xvvyfz4EHq9OxJ47dnYdu4caWdqyS5MbFET55MblQUniuWU7t9sctWFJEXG0vM1GdxfewxXO4fbPEYa7L8S5fICT9BzokT5Jw5jct99+EQWC0NBlopKpoIWgFLgSaAAqKB8SJyqrIDLYuamggAolKj+PeOfxOcGEzHBh2ZFjCNQHfT/3AigjE1tdQpKSqDGI1c+mEZFz76CGVlRcNXXqbuqFEWuzvIDg0lavJkJCcXZVcLaydnWv68EqvatUuOMT+fyEfGk/X332BrS/MFC6jTratF4isPY04OSYsWYdvMA5fB91V3ONdN8vJI+Go+WUGHyD55EsPFhH92Wllh06gRrdb9hpWDQ/UFaSGZQUHU8vTExtW1ukMptwolgkKVOAJcXj+gutTkRACQb8xnzek1zD08l/jMeO5ocgfP+j9L+/rX/pZcmXKjozn/+htk7t9PnR49cH/rTdP2mBjyYmLJi4khLzYWQ3oaDadNw75dcctVly79r7+InfosVi4uNJ//FfkXLxI18XHqjRuH+5tvlHjchU8/JfHLr3Cf8RZJ331PfmIinsuWYXdby+u+3orKOnaMc6+8Su7p0wA0euMNXB8ed83jMg8eNHX8P/88Vvb2lg6zTBIXLuTCh3Owb9cOO29v7Ly8sPNqg12bNuRFRxM57mHqT3mKhs89V92hVqqMPXuIemwi1vXr0+S9d685BcyNpsKJQCl1H9AeKPhLrK6F5mt6Irgsx5DD8rDlLDi2gOScZO7xvIdnOj2Dp4tnlcUgRiOXli/nwpyPkMzMojttbLBt0gRjSgpWjo60XPUL1s7OZa47efVqzr/xJnatWuEx/ytsGzUCIP6990ha8i0eX8/HsVevq47L2LuXqMcm4jJ8OE3enU1udDQRD47BytERzxXLsalXr1zXmBcXR8LceWQdO4bzvfdSd+QIbOrXL/PxxtxcEv43l8QFC7Bxc8N9xlsk//wz6Zs20/Cll6j/+MRijxMRLi1bRvy770F+Pq6PPkqjV18pV+yWkBcXx+lB91GnWzc85s0ttkzsS/8mbeNGblv3G7U8PKo4QsswZmRwZugwsLLCyt6enBMnqPfwwzSc/uINk6CvpbREgIiU+gK+BL7F1CQ0AziG6bmCax5riVdAQIBo/0jNSZUvgr6QwO8DxXexrzy96WnZEb1DDEZDlcWQEx0jCV9/LZd+WSXp+/ZJbmysGPPzRUQk8++/JaR9B4l+5hkxGo3XrMtoNMrFeV9KiLePREyYIPmpqUX2G7Kz5fTgwRLes6fkJSUV2ZeXmCgnevaSUwPvFUNGRsH2jKAgCfXtKGcfGieGnJwyXVNeUpLEvfe+hPp2lJAOvnJm5CgJ8faRkA6+EvPidMk4ePCa15N5/Licvn+IhHj7SOyrr0l+SorpGnNzJeb55yXE20cuzp179e8gJ0fOvfGmhHj7SNTkJyX2tdckxNtH0vfsLVPsxcmNi5PIJybJ6eHD5eJX8yUnOua66ol+bpqEdvSTnOjoUs4VL2Gd/SVqyr+uWV/+pUuSceBAuWLICg+XjENBkhUcLNmnz0hubKzkJSWJITOzXPVkHjki52fPLvK3UpLz78yWEG8fyThwQAzZ2RL37rsS4u0jpwffL1lh4eU6b3UBDkoJn6tl6SM4KiIdC/3XEVgvIld/HasC+o6geAlZCSwLW8bPJ34mMTuRZo7NeMD7AYa3Hk5d+7rVGlviosVc+OCDaw5plbw84t6ZTfKKFTjffz9NZr+DqlXrqnLZYWFEjH4Ax759afr5ZyilEBFinppCxu7deP64Avu2bYsck7p+PbHPv4Dz4ME0+fD/SuzTMKSnk7R4CUmLFmHMysJl6FAaPP00tZo1Jef0aS4tX0HKqlUY09Oxa9MGl5EjsHapi+TlIvn5kJeH5OeTdz6OS8tNdyDub8/CqW/fotdqMHD+tddJ+fXXIg/95SckEPPsc2QFBVF/8mTcnnsWycnh7PARGHNzuW3Nr1g7lW+ar4y9+4h98UWMWVnYtW5N9tGjANTu3BnnwffhPHBgme5y0nf9RfQTT+D23LM0mDKl1LKJCxZwYc5HJd65AeRfvEjkoxPIPXOGumMepNFrr2FVzL/3ZZKbS/ycOVz69rsSy7gMHULj994rWN+7JHnx8ZwdMRJDYiJ1+vTG47//LfHZmcygICLHPUy9hx4q0iSZvnMX5157FWNKKg2nv0i9sWMxpKSQn5iE4VIS+YmJGBKTwMoK+3Ztsff2rtah1xXtLN4vIl2VUnuBEZiWkgwWkdaVH+q16URQujxDHpujNrM8fDmH4g9Ry6oWA1sO5MmOT9Lc+eqVzqqCiBDz9DOk79yJ59Lvqd2x41VlDKmpxE57nozdu6k/aRJuz08r9X/mxIXfcOHDD2k8ezZ1R44gackS4t97v9S294Qvv+Lip5/S4OmncZv6DCJC/oWL5J49Q86ZM+SePkPqunUYkpNxuvtu3J6dil3rq//MjZmZpKxbx6UflpETGlpijM5D7sf99ddL7MAXo5G4GTNI/mklro89hvOgQcRMnYohOZkm787GedCggrJZR44Q8dA4XAYPpskH75d4ziL1i5C0cCEXPv6EWp6eNPv8M+xatyY3JobUdb+T+ttv5Jw8CdbWOA0YQON33i4xyRhzczl7v2k0Wsu1a0r9wAbTh/aZIUMBuG3Nr1cl9PyEBCIfnUDeuXM4DxxIyqpV2HfsSLNPP8G2SZOr6ss7d46Y558n+8hR6j3yCI59+iDZWRizspGcbIxZ2eScOkXyihXUf+JxGk6fXmJsxtxcIh95hJyTp3B9+GES588vMYEYc3I4O2w4kpPDbWvXXPVBnp+UxPnX3yB969ZSfx8AKEWt227Dvl077Nu1o7ZfR2p36nTNpFVZKto09CZQFxgJxAHngVllOM4D2AqEAMHAc8WUUZiWqDwFHAX8r1Wvbhoqu/CkcHl7z9sS+H2gdPq2k7y/731Jzk6ulljyL12Sk/3ulJN39pf85KIx5ERFyalB90lI+w5yaeXPZarPaDBIxCPjJayzv6Ss3yAhHXwl6l9Pl9pcYzQaJfaVV0239MOGS5h/gKm5x/wK6+wvkZMnS+bRY2WLwWiU3JgYyYmOltzz5yUvIUHyk5PFkJEhxtzcMl/H+Vlvm2Jo205O9OsnWSEhxZa98NlnEuLtIykbN16z3vzUVIl6+mkJ8faR6OemSX5aerHlssLCJf7DDyWkfQc5PWSo5MbFFVvu4rx5EuLtI2k7d5XpukRE0nbskBBvH0n4+usi2/MuXpRT990noZ06S/q+fSIikvLHHxLmHyDh3bpL+l9/FSmfunWrhHftJmEBXSRlQ8nXbjQa5dzMmRLi7SNJy1eUWO7cWzNMv8f1G0zXNneuhHj7SNz7H1xVNn7OR6br3lXydRuNRkles1YufP6FJC5dKinr10v6vn2SfeqU5CUlSe7585K6eYtc+OK/EjXlX3Kid5+Cv7kT/frJhc8+k5zIyBLrryyU0jR0rQ9zK0xPFV9+bwe4lHZMobKNL3+wA07ACaDdFWUGAevNCaE7sO9a9epEUH4XMi7IjL9mSMclHeWOH+6Qb4O/ldz8sn1QVabMw4dNH9hP//OBnXHokIR3v13CunaT9L37ylVfbmyshHUJNP0P1afvVX0Gxbnc/h752EQ5//Y7krh0qaTv2SO5cXFl6sOwBKPRKBc++1yinn5a8hITSy6XmytnRoyU8G7dJe/ChRLLZYWFycm775aQ9h0kcfHiMl1X2q5dEuYfICf69JWs8KJt3jnRMRLq10min32u7BdlFjXlXxLW2V9y4+JFRCQvIeGfJHDFv3f2mTNyevD9EuLTVi7OmyfG3FyJ/+hjU+IeOkxyIiKueT5jXp5ETp4sIe3aS9qOHVftv/TTTxLi7SPxH374zzFGY0EyTliwoGB75rHjEtKuvcS+9lq5r/ta8i5elOS1v0nk409IiE9bCfH2kbPjxsmln36S/LS0Sj+fSAUSgelY/r5WmbK8gF+Bu67Y9hUwttD7cKBxafXoRHD9whLDZNLGSdJhcQcZ9PMg2RS5qco//BIXL5YQbx9JXLxYkteskdAOvnLq7nsk+8yZ66ov5fffJaxrN8nYv7+SI70xZZ86JaEd/SRq8pNF/u2MubmS+uefpg/Btu3kRM9eknHwYLnqzgoJkRM9e0lYl8AiH9JRU/4loZ39Jff8+XLHmxMVJaG+HSVm+kuSl5gopwcPllC/TiV2fBsyMiTmxekS4u0j4T16Soi3j5x7400xZGWV+Zz5aemmO77O/pIVGlqwPfPoUQn17SiRjz0mxry8IscYDYaCDvxLv6wSY06OnB4yVE707FXQyW8puefPy8Wv5supgfcWDEgIC+giYZ39JbRTZwnt6CehHXwlpH0Hif/o4+s+T2mJoCx9BHOAPcAvcq3CJdfhCewAOohpbYPL238D3heRXeb3m4GXReTgFcdPBiYDNG/ePCAyMvJ6wtAwJf5dsbv46OBHnE45Tfv67Xnc93Hu9LgTayvrKjl/zNSppG/dBgYDDoGBNP38s3IP6yxSp8GAsrZ87DeKpG+/Jf7d93Cf9R/qdO9O8k8rSV69CsPFBGzc3HAZMQLX8Y+Ua5jrZXnnzhE1aTJ5UVE0fv89rBwciJnyLxq+NJ36jz9+XfFe+OwzEud9iW2zZuQnJODx5TzqdO9eYnkR4dLSH0j8ZiENn3sOl6FDy38d8fFEPPAgAJ4/rkDZ2nJ25ChQ0PLnn4v9ezPm5hLz1FNk7NuPY58+pG/ZQrO5/8PpzjvLff7rISJkHz1K2qbNSG4OKCuwskJZqYKfHbp0wbFXz+uqv6KdxWlAHSAfyMbUjCMiUqZB4eZRRtuB2SLyyxX7ypQICtOdxZXj8oNpC48tJCotCk9nTx7r8BiDbxtMLevSOwIrypCSQtRjE7Fv3x73N98odmSQVjIxGol6/HEyDxyE/HywssKxTx/qjh6NY+9eFZ5O3JCSQszTz5B58CBWLi7YuDXgtlWrrntGWmNWFqcH3YchKcmUBG6/vULxlVV2WBiRD43DtkULrJ2dyfr7b1r88AO1O5T88KUhPYOoCRPIPn4c50GDaPrxR1USa1WolCeLr/PEtsBvwEYR+biY/V8B20Rkmfl9ONBXRM6XVKdOBJXLYDSwKWoTC48tJDQplIYODRnfbjyjvEZRx1bPMnqjyjt/nvMzZuDg74/L8OEFD9xVFmNODudeeYW0jX/QfNGiCk/RkRsVheTmFjsKy5LSd+4k+qkpYDDQ+L33qDt82DWPyU9K4tLSH6j38LgK3aneaCp6R1Dsc9RSzEI1VxyngCVAkohMK6HMfcAzmDqNuwGfi0ipf3E6EViGiLDn3B4WHl/I/rj91LapzV0t7mJY62EENArASlXNEDftxiEiGBJMzU03s9Q//yQ/Lh7XRx6u7lCqVUUTwdpCb+2BrsAhESm14Uwp1RPYielJZKN582tAcwAR+dKcLP4LDAQygcdKaxYCnQiqwrGLx/j55M9siNhARl4GzRybMaT1EIa2GkoTx6vHeGuaduOr1KYhpZQH8KmIjKyM4MpLJ4Kqk5mXyeaozfx66lf2xe1Doeji3oUBzQdwZ/M7i10XQdO0G1NlJwKF6cni8k8nWQl0IqgesemxrDm1hg0RGziTcgYA3wa+3Nn8TgY0H1Clk91pmlZ+FW0a+gK4XMgK6AREiEi1NLjpRFD9zqScYUvUFjZHbuZ44nEAWrm0oo9HH/p69KVjg45VMhRV07Syq2gieLTQ23xMSeCvSoyvXHQiuLHEZcSxJWoLW6K3cCjuEPmST127uvRq2os+Hn3o0aQHjrUcqztMTavxKpoI6gDZImIwv7cG7EQks9QDLUQnghtXWm4af537i+3R29kZu5OUnBRsrGzo26wvw9sMp0eTHvpOQdOqSUUTwV5ggJhXJjM/IPaHiNxR6ZGWgU4EN4d8Yz5HLh5hU+Qm1p1Zx6WcSzR0aMjQVkMZ3no4Hs63xoIlmnazqGgiOCwina61raroRHDzyTPksT1mO6tOrWJX7C6MYqRLoy4M9BxIj6Y9aObUrLpD1LRbXmmJoCzPomcopfxFJMhcWQCQVZkBarc2W2tbBrQYwIAWA4jPiGftmbWsPrWad/a9A4Cnsyc9m/akZ9OedHHvgp21XTVHrGk1S1nuCAKB5cA5TPMMuQMPisghy4d3NX1HcGsQESJSI/gr9i92xe7iQNwBco252FvbE9AogO6Nu9OtcTe8Xb31U82aVgkqY/F6W8Db/DZcRPIqMb5y0Yng1pSVn8XBuIPsit3FnvN7OJtyFoC6dnUJdA8sSAzNnZqXuMykpmklq2gfwdPAUhFJNr+vh2kNgbmVHmkZ6ERQM8RnxLM/bj97z+9l3/l9xGfGA9CwdkO6uHch0D2QQPdAnRg0rYws0Vn8t4h0rsQYy0wngppHRIhMjWR/3H4Oxh3kQPwBErISAFNiCGwcSD+PfvRq2gsHW4dqjlbTbkwV7Sy2Vkqpy4vSmJ8j0BPIa1VGKYWniyeeLp484P1AQf/CgbgDHIw7yO7Y3aw7sw57a3t6NO3BgBYD6NOsD061il+IXdO0osqSCDYAK8xrBwA8iWmdYU2rFkopWrq0pKVLSx7wfgCD0UDQhSD+jPyTzZGb2Ry1GVsr24J+BT83P9rWb6tHI2laCcrSNGSFaZnI/uZNRwF3EXnawrEVSzcNaaUxipGjF4/yZ+SfbI3eSnRaNAA2Vja0dW2Ln5sfHd060r5+e5o5NdMjkrQaozJGDXUGHgIeAM4AP4vIfys1yjLSiUArj4SsBI5ePMqRi0c4cvEIwQnBZBuyAahtU5s29drgXc8b73reeLl64VXPS6/Mpt2SrisRKKW8gLHmVwKwApguIi0sFWhZ6ESgVUSeMY+Tl04SlhTGiUsnCE8KJ/xSOGm5aQAoFC2cW9C+QXvaubajXf12tK3fVicH7aZ3vYnAiGmFscdF5JR52xkRuc1ikZaBTgRaZRMR4jPjCU8KJzQplODEYEISQ7iQeQEwJYfmzs1p4dwCDycPPJw8aO7UnObOzWni2ARbq+tb1F3TqtL1jhoaAYwBtiqlNmB6urjMA7aVUt8Ag4ELItKhmP19gV+Bs+ZNv4jIrLLWr2mVRSmFex133Ou408ejT8H2hKwEQhJDCE4M5uSlk0SlRnEg7gBZ+f/MsGJjZYOfmx+3N76d25vcTvv67fUMq9pNp6zTUA/F1ER0J/AtsEpE/rjGcb2BdODbUhLBdBEZXJ6A9R2BVp1EhMTsRKJSo4hOi+ZU8in2nd9HaFIoAE61nOjm3o3bm9xOhwYdaFW3lR6tpN0QKvQcgYhkAD8AP5ifKh4NvAyUmghEZIdSyrPc0WraDUwpRYPaDWhQuwH+jfwLtidlJ7H//H72nN/DnnN72BS1CQArZUVzp+Z41fOiTb02BZ3TTR2b6ieitRtGudcsLlflpkTwWyl3BD8DMZgmtJsuIsHXqlPfEWg3OhEhOi2asKQwTiaf5ETSCU4mnyQmLQYxr/rqVMsJH1efIq+WLi11f4NmMZW6eH05T+xJyYnAGTCKSLpSahDwmYi0KaGeyZieZaB58+YBkZGRFotZ0ywlMy+TU8mnCL8UTlhiWMHIpcvDWW2UDU2dmhZ0RDd3MnVQN3dqTmPHxthYleX5T00r3g2ZCIopGwF0EZGE0srpOwLtVpJvzCcyNZLQpFBOJ58mMjWS6LRoIlMji3ZKm5NE4RFLzZ2a4+Pqg5uDWzVegXazqOhcQxahlHIH4kVElFJdASsgsbri0bTqYGNlQ6u6rWhVt1WR7Zc7pSNTIws6pi8nib8v/E1GXkZB2YYODWlfv73p1aA97eq3w9XetaovRbuJWSwRKKWWAX2BBkqpGGAGYAsgIl8Co4ApSql8TCuejRFL3p5o2k2kcKd0QKOAIvtEhKTsJCJSIwqGtwYnBLM1emtBGVd71yJ3Ds2dTS9PZ0/9cJx2FYs2DVmCbhrStOKl5aYRlhRGcEIwEakRRKVFEZkaWfBg3GVNHZsWGcXkVc+L5k7NdR/ELe6GbBrSNK1yOdVyKliwp7Cs/Cxi0mKISo3idMppTlw6wclLJ9kesx2jGAFTH4R7HXeaOjWlmWMzmjo2pamjqU+iTb022NvYV8claVVE3xFoWg2VY8jhTPIZTlw6wdmUs8Smx3Iu/Rwx6TEkZScVlLNRNrSu17qgD6JD/Q60rtdaD3W9yVTbqCFL0IlA0ywvMy+Tc+nniEyNJDgxmOMJxwlODCY1NxUAWytb3Gq74WrvimttV+rZ1cO1tiv17evTuE5jPF08aeHcQj9VfQPRiUDTtAoTEWLSYjieeJzQpFASMhNIyk4qeF3KvkSuMbegvELRxLEJns6eBQsJtarbilYurahrX7car6Rm0n0EmqZVmFIKD2cPPJw9uLflvVftFxHS89KJSYshIjWCiJQIzqaeJSIlgqALQUWei6hvX79g2GxTx6ZYK+uCKTeslBUKha2VLY3rNKaZUzMa12mMrbVuirIUnQg0TasUSimcajnRtn5b2tZvW2SfiBCXEcep5FOcSTnDqeRTnE4+za+nfiUzP/OadVspK1NScGxGM6dm/0wH7vz/7d17G2+gBgAAGDlJREFUcFzXfdjx72/v3SewwOJFEHyApCRast60aVGWFUeRxrHsuHE08sRWnNR2lMp1HnIyTeOk004aN2mdptM4rj1NFdePJI4TJ44SjuKk0tiy3FiWZKqyKFKiTL1IggJAgMBiAex799c/zt3FEgT4XoLA/X04d+5jdy/OWe7+fueee/fcYTanN9slsefJEoExpu1EhKHOIYY6h/iRTT/S3K6qzFZmUVU3Bf/qWqdSq/D6/OscmT3CyOyIm8+N8OiRR084mQ3uCGO4a5jLui9zNxPqfaNd7XQW7ByBMWbVmSvPMTLnLok9PHuYkdkRDuUOcTB7kJnSDACeeGzr3sbVfVeztWsr3fFuuuPddMW6msuZeCY0RxN2jsAYs6Z0xjqbo7a2UlVG50d54fgLPD/1PAemDvD464+z++Xdy+4r6SdZl1rHQHLATSk3zyQyZOInTl3xLiISaXf1LjpLBMaYNUPEXam0oXMDd2y5o7m9WC2SK+eYKc0wU5ppLk+XppnITzBRmGAiP8G+4/uYODLRHBF2sYhE6I5105PooSfRQ2+il0w8Q0+ix102G1wh1ZvoXVX3m7BEYIxZ8xJ+goSfYF1q3Wmf27j6KVvKki1m3byUbSaObDHLdGmaqeIUL2dfZro4TbaUbd5rAtyvvLd1bWNr91aG08PNW6Gu71jPYGrwkjt3YYnAGGNaNK5+SsfSbE5vPqPX1Oo1xvJjvDrjLpdtXD77xOgTS3ZL9cR76E/1k/JTJLxEM1HFvThJP0lfso/B1GCzy2owNUh3vLttRxmWCIwx5jx5Ea85PtOtG2894bFSrcT4/Dhj82OM5cfcfH6MycIkxWqRYq1ILp+jUC1QrBXJV/LNX3C3ikVi3Hvdvfzijb94wctvicAYY9oo7sWbw4CfqXKtzERhgmP5YxzLH2Mi75av6bumLWW0RGCMMZeYmBdrHmFcDGvvOihjjDFnxRKBMcaEnCUCY4wJubYlAhH5gogcE5F9yzwuIvIZEXlJRPaKyJvaVRZjjDHLa+cRwZeAO0/x+LuA7cF0H/A/21gWY4wxy2hbIlDV7wBTp3jKe4E/VecJICMiQ+0qjzHGmKWt5DmCjcCRlvWRYNtJROQ+EdkjInsmJiYuSuGMMSYsVsXJYlV9QFV3qurOgYGBlS6OMcasKSuZCI4CrQN5bAq2GWOMuYhWMhHsBv5lcPXQzcCMqo6uYHmMMSaU2jbEhIh8FbgN6BeREeC3gSiAqv4x8A3g3cBLQB74SLvKYowxZnltSwSqes9pHlfgl9r1940xxpyZVXGy2BhjTPtYIjDGmJCzRGCMMSFnicAYY0LOEoExxoScJQJjjAk5SwTGGBNylgiMMSbkLBEYY0zIWSIwxpiQs0RgjDEh17axhowxZrVQVfLlGrPFKrPFCrOlKm44tMXPg3KtTqlap1SpBfM6pWqwHEzlqttWbllvbqu511TrSkTAi0jLFCEiUKzUKJRr5Ms1Ci3L9966jV9/55UXvP6WCIwxF42qUqrWKVYWglylVifqRYh5EWJ+hKgXIeoJfiRCuVqnWHWBsFitUay417rJBdZG0CxW68wVq2QLZbL5CjOFCtl8hWyhTKFcx4tARMRNwXJdNQj+VWr1kwP/uYp5EeK+q0/Md8tx3zthPeVFqNeVWl2pqVKp1KnVa9RVSfgemVSMoW6PVMwjGXPzN2/tuWBlbGWJwBiDqjZbuuUTWrB1ZosVcsUKs8UquUKFXBA4S1UXxMvVOpWae33jNcUgyBcrLfNg2wWMtyfxIkImGaU7GaU7FaW/M8blAx0kYx71OtRVqWtjrgiQTkTpSvpunoiSTvh0Jnw8kSX/Rmtgj0dPXo55EWSZ116qLBEYs4pUa3XylRrFco35ci1o9ZaZKVSYni+TDVrBpWqdWt11P9Tq6uY1pVitMV+qMl+qMV+uMl+qMleqUqzUz6ocMS9CPOqCXrTZkheiXoRE1CMZ9ejvjJGMec31RHShdZsMtiVjHlEvckJCaSxX60rcd/tLRFvmvke8uc/GdrecjHqrLghfCiwRGHOBqGozOOcKFfLlGqVmi7h+Qst4vlwlX3ZBuTEvBH3OzRZ5baFfudDsRjl9czqd8ElEPfyg39lv6YOO+x4dcY8NmQQdcZ9UzKcz7pGM+c3WbKP7ohHsuxJRupKupdxoMSei3kV4R83FYonAhEajNV0o1yhV6pRrC4G3UlPK1Tr5ctUF8mK1GdBzxQrzpWqztVqtuVZ2pV6nUquTK1TJFd1zz6bbIxl1QTkV80kFLee4HyGd8Bf6l4PAnIr5J7Wkk1GPTCpKJhUjk4rSk4rRlfDxPbsY0JydtiYCEbkT+CPAAz6vqp9a9PiHgT9g4ab1n1XVz7ezTGZtqNTqzSs8svkK47ki47kiY7kiYzMlxnNFjs0WmStWyVdq5Evuao2z1WgFd8Z9or47gelHBN8TOqM+US/C5QM+3UnXv9ydXOhvTsUWukSSMY+E77ovUnGfZNTDi1gXhrk0tPOexR7wOeAdwAjwfRHZrarPL3rqX6nqL7erHObSUqsrx+dKjOdKzBZd94kL1NXmVSSuD7vKbDCfL9WYLVWZC05YzhZdN8pSvIiwLh1nsCvBtv6OhYAc80hFfTribrl5BUdwdUejnzsZ9dyJxmTUnTAMc7Au52F2FHq2QuQ8uoJUYfpVt7/eyyCWOvXzC1k49jxMH4JEN3Sug45+6Fh3+tc21CpQnIHCtNsfCun10Lke/NjJzy/OwNhzMLrXzadfhYErYfPNsPkmV+6lzj3MH4fxfTC+H4pZQNzzJBIsA34CUv2uDqm+YN7vthem3Hs8O7YwnxuH8jxU8lApBFOwfOMH4ZYLHy7beURwE/CSqr4CICJ/CbwXWJwIzCqlqswUKozlikzMlpgrtgbvKnOlGrPFChOzpaDFXmJirnTay/S8iNAZ9+mMu8DdGffpSvhszCRIxxda3I3WelcyymBXnPVdCfo646sreNfrkH0Nxva5oNAMGP3Q0QeJjAssxRzkjsLMCMwccfPZcYgmIdHlAmaiG+Jdbl2BagEqxRPnkagLRqleNyV73XqtAmN7gykIiMcPgtYhloZNO2E4CIobd7q/sWydai44HvoeHH4cDj/hgltD92bouwL6t0PfdrevYy+44D/+PORGlt93tMO9P14QzJvBOZhX8i74l+eW30eqH7qGID3k9jO+D6ZfW3i8Yx30boN9D8LTXwq2DcDmXbDxzW7/4/vdNDe2/N85HYm493exRMb9P0aTbop1QLIHuja4pNgG7UwEG4EjLesjwK4lnne3iLwd+CHwa6p6ZPETROQ+4D6A4eHhNhTVAJSqNUamCxyeyjM9X3Yt9BN+1FIlW6gwNrPQDXOqq01iXoTOhM9AZ5x1XXHeMJhmfTrKlXKIywv76IiU8WIpookkfryDWDxJLNFBtHs9su4q9yVYTq3igtXh78HIAfel7t0GPdvcvHNwIUiU5iB7CLKHXSszexjqleCL1uFamdGU+8JFk+AnF76E0aRruUU8F4xLOdd6LAbz0qwLsNUSVIvBVHJTNAXJjPtiJzPuy5zIuKA4vs8F3LF9UJ5dvp4R3/39xYFNPBecaiVXjqUCyrnq2gRD18M1d7ngM/osHHkKvv0pQF0AG7gK4umTX1uvwcSLC3Xq3gzbftQlkWQGJl9yCWbyIPzgLxbqFYlC/xtgy1th3dUweI1rhZdmYX7CTXPHYH7SLderrizgjjjcgvv/bH2vkz1uXestre6g5Z173bWyh26AHT/n5uuvc0cO4JL0xAE48uTCdOAhlzwGroTLb3flHLwGBq+FzgFXFlVXFq275WrBlTt/PJhPunl53gX29Hr3+U2vd59bP37h/i/PkCz167kLsmOR9wF3quovBOs/B+xq7QYSkT5gTlVLIvJR4P2qevup9rtz507ds2dPW8q81hXKNcZyRUazBUZniozOFDgyVeDQ1DyHj+cZzRVZ7uMQ8yIkYx5dSZ/1XQkGuxIMdTfmSQbScXf9dbMl7xPzI1Crwtiz8Np34dB3XSuxNHP6wkrEBYJ1b4R118Dg1e5LPvJUEPz3uNYfuBZtYfrEYOgnoXuTa2Xnj5+472jKfZkreaiVz+3NbNUI1n58Ye7FXFdIMeuSx2KxThc81l/rgs/661xLNH88CBSN+YQLVukhV5/uzW7eOQhe0I5TdUGlOBMkp5x7//zEQiJrzGtlyE8tvC/5YC7iyjN0gztSWEoxB0f3wOEn4fVnXBJaSu/lMPxWF/wzm5d/31RdQC7lXAJfqsvmUlOYdv93XnSlS3LWRORpVd255GNtTARvBf6jqr4zWP8tAFX9L8s83wOmVLX7VPu1RHCycrVONl9mcq7ccsK02HICtcTYTIHpfOWk1/Z3xtnSl2K4102N5f6OKB0USWqeRH0evzLvWnn5qaVbVvkp0KDfvtEiAtdyrwd/t+8K2PI22HorbLnFdUtUiy7Qtc5nRlw3QaOrYOqVhf1JxAXNRqDZfLM7zK+WXZfJ1Kuuf3fqVbee6oXMFujZApmtkBl2XQuNo4VataUvdt4F70ZZKoWgW6XgWrqNLph4a1dM+vRBoVZ1wa7RX53MuMAXsat7zMWzUonAx3X33IG7Kuj7wM+o6v6W5wyp6miwfBfwCVW9+VT7DWMiqNWVVyfn2Dsyw96RGQ4dn2cq735AND1fZrZU5S1ygHd7T5Inzox2MEsH9XgGvyNDR2cXw4l5NntZ1nOcntokXaVxYoVxItWiO8yuV12w05pbrhZPXSg/udDPml7v+l0j/skn1CK+62bY8raFQ+6zVc7D5IuuRbrxTUt3SRhjTulUiaBt5whUtSoivwz8H9zlo19Q1f0i8klgj6ruBu4XkZ8EqsAU8OF2lWc1KFfrjM4UOJotcHS6wIGxWZ4bmWH/6zPMl11rOxn1uGygg96OGNv6UmyJTvETo3/CGyYfoeYliNQrSKNlXgdmg6kh4kN6A3RvhA03un7xiO/6wCN+EMwjrvsk3umCbjztWsGxTteaTQ+51vDF+gVnLAUbdlycv2VMCLXtiKBd1sIRQa5YYf/RHPuOuiB/eCrP+HSO2twkfeTokxn6yJHzMpQGd3DF8Cau3djN9Zu6uXyg010VU87D45+Bf/40oHDrr8Et97u+4GZ/cTboM55zV6B0bXInGK1LwpjQWZEjAuOUK1VeffbbzO5/hNnpY5TmpqE0R5o8uyTPnV6RXnJ06DwsdbHApEDkjSA3gbcL/F3uEr+H/4PrA7/mLnjHfzrxpFy8003dGy9aPY0xq5clggusUK7xzOHjHNn7GOmX/4Edc49xpUwBMEeKst+JptP4qQzJ9BCxju7gmvGB4EczA25K9bnrqY885S5ba72mGWDwOrjrj92JV2OMOQ+WCM5WMQcvPeKuShGhVMNdez9d5NBUAZkZ4ccjT3GLTFHB55XMzRzb/i/YePPd9PcPnN3f6r8CLrvNLdfr7oTp4Sdcv/61d5/frz2NMSZgieBMzE3Ai9+AAw+hr3wbabn2PA5cHkwAVT/K9Ia3k99xN6lr38OViVNeDXvmIpHgmvo3Xpj9GWNMwBLBcmbHYf+D8MJu9PD3EK2TjQ3xD/pOHizt4IB3BTdsyrBrS4adW3u4cVOaVNTD9+MMrMAvA40x5lxZImhVzLmfkO/9Grz6GGid4x2X843YT/PV3PUcrGzltisH+fkdG7n9qnU2JrsxZk2wRKAKBx+BH3wFfvhPUC1S6Rrmsb4P8gev38CLxQ28eUsP9/zYRt5z3RA9HavgZ/DGGHMWwp0Iijl46Fdh39ch1c/0VR/gi7m38NmDGaKexz03D/PA27aypa9jpUtqjDFtE95E8Poz8Ncfgexhxt7yG/zO8Tv4xz3H6Yh5/Ku3b+EXbr2MgbT19Rtj1r7wJQJVePJ/wcP/Hu1cx0Nv+jz3/3OcdHyG++/Yzkdu2WrdP8aYUAlXIshPwe5fgQMPUd9+J5+K388D383yrmvX8/vvu56uxOobWtYYY85XeBLByNPw1x+C2TFKd/wuHz14E99+bpKP/uhlfOKdVxFZTXe1MsaYCyg8iQDAjzP5/r/nZ/+xxsFjx/nPd13Hz+yyO54ZY8ItPIlg05vZ91MPc++fPcN8qcYXP/wW3v6GsxzywRhj1qDQJILv/HCCf/3nT9OTivH1j+3iyvV2cxNjjIEQJYLNvSl2bu3lv73vetZ1JVa6OMYYc8kITSLY1t/Bn/78TStdDGOMueTYraqMMSbk2poIROROEXlRRF4Skd9c4vG4iPxV8PiTIrK1neUxxhhzsrYlAhHxgM8B7wKuBu4RkasXPe1eYFpVrwD+EPj9dpXHGGPM0tp5RHAT8JKqvqKqZeAvgfcues57gS8Hy38D3CEi9ssuY4y5iNqZCDYCR1rWR4JtSz5HVavADNC3eEcicp+I7BGRPRMTE20qrjHGhNOqOFmsqg+o6k5V3TkwYD8CM8aYC6mdieAosLllfVOwbcnniIgPdAPH21gmY4wxi7QzEXwf2C4i20QkBnwA2L3oObuBDwXL7wO+paraxjIZY4xZRNoZd0Xk3cCnAQ/4gqr+noh8EtijqrtFJAH8GbADmAI+oKqvnGafE8ChcyxSPzB5jq9d7cJad6t3uFi9l7dFVZfsW29rIrjUiMgeVd250uVYCWGtu9U7XKze52ZVnCw2xhjTPpYIjDEm5MKWCB5Y6QKsoLDW3eodLlbvcxCqcwTGGGNOFrYjAmOMMYtYIjDGmJALTSI43ZDYa4WIfEFEjonIvpZtvSLyiIgcDOY9K1nGdhCRzSLyqIg8LyL7ReTjwfY1XXcRSYjIUyLybFDv3wm2bwuGdn8pGOo9ttJlbQcR8UTkGRF5KFhf8/UWkddE5DkR+YGI7Am2ndfnPBSJ4AyHxF4rvgTcuWjbbwLfVNXtwDeD9bWmCvwbVb0auBn4peD/eK3XvQTcrqo3ADcCd4rIzbgh3f8wGOJ9Gjfk+1r0ceCFlvWw1PvHVPXGlt8OnNfnPBSJgDMbEntNUNXv4H6l3ap1uO8vAz91UQt1EajqqKr+v2B5FhccNrLG667OXLAaDSYFbscN7Q5rsN4AIrIJ+Ang88G6EIJ6L+O8PudhSQRnMiT2WjaoqqPB8hgwuJKFabfgTnc7gCcJQd2D7pEfAMeAR4CXgWwwtDus3c/7p4HfAOrBeh/hqLcCD4vI0yJyX7DtvD7nobl5vXFUVUVkzV4zLCKdwNeBX1XVXOt9jtZq3VW1BtwoIhngQeCqFS5S24nIe4Bjqvq0iNy20uW5yG5V1aMisg54REQOtD54Lp/zsBwRnMmQ2GvZuIgMAQTzYytcnrYQkSguCXxFVf822ByKugOoahZ4FHgrkAmGdoe1+Xl/G/CTIvIarqv3duCPWPv1RlWPBvNjuMR/E+f5OQ9LIjiTIbHXstbhvj8E/P0KlqUtgv7h/w28oKr/veWhNV13ERkIjgQQkSTwDtz5kUdxQ7vDGqy3qv6Wqm5S1a247/O3VPWDrPF6i0iHiKQby8CPA/s4z895aH5ZvNSQ2CtcpLYQka8Ct+GGpR0Hfhv4O+BrwDBuCO+fVtXFJ5RXNRG5Ffi/wHMs9Bn/O9x5gjVbdxG5Hndy0MM17L6mqp8UkctwLeVe4BngZ1W1tHIlbZ+ga+jXVfU9a73eQf0eDFZ94C+C4f37OI/PeWgSgTHGmKWFpWvIGGPMMiwRGGNMyFkiMMaYkLNEYIwxIWeJwBhjQs4SgTGLiEgtGNmxMV2wgepEZGvryLDGXApsiAljTlZQ1RtXuhDGXCx2RGDMGQrGgf+vwVjwT4nIFcH2rSLyLRHZKyLfFJHhYPugiDwY3CvgWRG5JdiVJyJ/Etw/4OHgF8HGrBhLBMacLLmoa+j9LY/NqOp1wGdxv1QH+B/Al1X1euArwGeC7Z8BHgvuFfAmYH+wfTvwOVW9BsgCd7e5Psackv2y2JhFRGROVTuX2P4a7iYwrwQD3I2pap+ITAJDqloJto+qar+ITACbWoc4CIbIfiS4gQgi8gkgqqq/2/6aGbM0OyIw5uzoMstno3Xsmxp2rs6sMEsExpyd97fMvxcsP44bARPgg7jB78DdMvBj0Lx5TPfFKqQxZ8NaIsacLBnc8avhn1S1cQlpj4jsxbXq7wm2/QrwRRH5t8AE8JFg+8eBB0TkXlzL/2PAKMZcYuwcgTFnKDhHsFNVJ1e6LMZcSNY1ZIwxIWdHBMYYE3J2RGCMMSFnicAYY0LOEoExxoScJQJjjAk5SwTGGBNy/x+rZkDZu+kHtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQNn1oamn7B5"
   },
   "source": [
    "# cell to load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIg5KzZ1n61l"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = BatchNormalization()(conv_11)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_2)\n",
    "conv_21 = BatchNormalization()(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation='relu')(X)\n",
    "X = Conv2D(64, 3, activation='relu')(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "\n",
    "#model = create_model()\n",
    "model.load_weights('../weights/InceptionV2_Adam_With_BatchNorm.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9sYcCaNn6zh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgbxDbNen6xL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Inception_Adam_BN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
