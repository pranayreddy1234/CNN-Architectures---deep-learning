{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3ehSwCoJHA6"
   },
   "outputs": [],
   "source": [
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.layers import ELU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cx3J75qjJL17"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTf_xlkRJL4u"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 #batch size as 128\n",
    "num_classes = 100 # we got 100 classes dataset\n",
    "epochs = 50 # iterations over dataset\n",
    "elu_alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Enf6v70UJL7_"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "Xdnhsa2UJMD9",
    "outputId": "93e8e6cb-4603-46c8-f4d1-d4baafd641f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#Channels first means that in a specific tensor (consider a photo), you would have (Number_Of_Channels, Height , Width).\n",
    "# we convert channel first to channel last.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBkrkxe1JMJ8"
   },
   "outputs": [],
   "source": [
    "initializer = keras.initializers.HeNormal()\n",
    "#layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n-hj2gyzW3js",
    "outputId": "f9aac495-fc22-4fb9-c8c8-0fd1d6f04d01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "elu_17 (ELU)                 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "elu_18 (ELU)                 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "elu_19 (ELU)                 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "elu_20 (ELU)                 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "elu_21 (ELU)                 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "elu_22 (ELU)                 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "elu_23 (ELU)                 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "elu_24 (ELU)                 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_25 (ELU)                 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_26 (ELU)                 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_27 (ELU)                 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_28 (ELU)                 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "elu_29 (ELU)                 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "elu_30 (ELU)                 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "elu_31 (ELU)                 (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "elu_32 (ELU)                 (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               204900    \n",
      "=================================================================\n",
      "Total params: 20,183,460\n",
      "Trainable params: 20,175,012\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building the sequential model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = input_shape,filters=64,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=2048))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dense(units=2048))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dense(units=100, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Jlr0hhsJMH2"
   },
   "outputs": [],
   "source": [
    "# # this is the augmentation configuration we will use for training\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# # this is the augmentation configuration we will use for testing:\n",
    "# # only rescaling\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# set up image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    #zoom_range=0.3\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3JOyIFlJMBG"
   },
   "outputs": [],
   "source": [
    "#initial_learning_rate = 0.1\n",
    "#lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "     #initial_learning_rate,\n",
    "    #  decay_steps=1000,\n",
    "    #  decay_rate=0.96,\n",
    "    #  staircase=True)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate = 0.001, clipnorm = 0.6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zJnkIr_e-CIu",
    "outputId": "e5a84cf4-f05a-4172-c1b2-dbf7593638a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "checkpoint = ModelCheckpoint('VGG_Adam_BATCHNORM.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XUQ5ghfGJL-9",
    "outputId": "1a4464dd-3b55-42cb-b4a8-ff701b9b15b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-2c9200f440d6>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 4.0713 - accuracy: 0.0622\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03260, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 39s 100ms/step - loss: 4.0713 - accuracy: 0.0622 - val_loss: 6.0806 - val_accuracy: 0.0326\n",
      "Epoch 2/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.7078 - accuracy: 0.1069\n",
      "Epoch 00002: val_accuracy improved from 0.03260 to 0.09740, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 3.7078 - accuracy: 0.1069 - val_loss: 4.2921 - val_accuracy: 0.0974\n",
      "Epoch 3/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.4201 - accuracy: 0.1482\n",
      "Epoch 00003: val_accuracy improved from 0.09740 to 0.12860, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 3.4201 - accuracy: 0.1482 - val_loss: 3.9115 - val_accuracy: 0.1286\n",
      "Epoch 4/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.1803 - accuracy: 0.1904\n",
      "Epoch 00004: val_accuracy improved from 0.12860 to 0.19070, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 3.1803 - accuracy: 0.1904 - val_loss: 3.3620 - val_accuracy: 0.1907\n",
      "Epoch 5/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.9422 - accuracy: 0.2366\n",
      "Epoch 00005: val_accuracy improved from 0.19070 to 0.19890, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 2.9422 - accuracy: 0.2366 - val_loss: 3.2537 - val_accuracy: 0.1989\n",
      "Epoch 6/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6977 - accuracy: 0.2873\n",
      "Epoch 00006: val_accuracy improved from 0.19890 to 0.25410, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 2.6977 - accuracy: 0.2873 - val_loss: 2.9496 - val_accuracy: 0.2541\n",
      "Epoch 7/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5129 - accuracy: 0.3274\n",
      "Epoch 00007: val_accuracy improved from 0.25410 to 0.31900, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 2.5129 - accuracy: 0.3274 - val_loss: 2.6959 - val_accuracy: 0.3190\n",
      "Epoch 8/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3359 - accuracy: 0.3652\n",
      "Epoch 00008: val_accuracy improved from 0.31900 to 0.34350, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 40s 104ms/step - loss: 2.3359 - accuracy: 0.3652 - val_loss: 2.5552 - val_accuracy: 0.3435\n",
      "Epoch 9/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2113 - accuracy: 0.3968\n",
      "Epoch 00009: val_accuracy did not improve from 0.34350\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 2.2113 - accuracy: 0.3968 - val_loss: 2.7320 - val_accuracy: 0.3281\n",
      "Epoch 10/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0871 - accuracy: 0.4278\n",
      "Epoch 00010: val_accuracy improved from 0.34350 to 0.39940, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 2.0871 - accuracy: 0.4278 - val_loss: 2.3631 - val_accuracy: 0.3994\n",
      "Epoch 11/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9758 - accuracy: 0.4563\n",
      "Epoch 00011: val_accuracy improved from 0.39940 to 0.43460, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 105ms/step - loss: 1.9758 - accuracy: 0.4563 - val_loss: 2.1444 - val_accuracy: 0.4346\n",
      "Epoch 12/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8895 - accuracy: 0.4755\n",
      "Epoch 00012: val_accuracy improved from 0.43460 to 0.45340, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 105ms/step - loss: 1.8895 - accuracy: 0.4755 - val_loss: 2.0938 - val_accuracy: 0.4534\n",
      "Epoch 13/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8092 - accuracy: 0.4969\n",
      "Epoch 00013: val_accuracy improved from 0.45340 to 0.47770, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 105ms/step - loss: 1.8092 - accuracy: 0.4969 - val_loss: 1.9621 - val_accuracy: 0.4777\n",
      "Epoch 14/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7347 - accuracy: 0.5166\n",
      "Epoch 00014: val_accuracy improved from 0.47770 to 0.48200, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 105ms/step - loss: 1.7347 - accuracy: 0.5166 - val_loss: 1.9930 - val_accuracy: 0.4820\n",
      "Epoch 15/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6501 - accuracy: 0.5407\n",
      "Epoch 00015: val_accuracy did not improve from 0.48200\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 1.6501 - accuracy: 0.5407 - val_loss: 2.0422 - val_accuracy: 0.4804\n",
      "Epoch 16/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5836 - accuracy: 0.5567\n",
      "Epoch 00016: val_accuracy improved from 0.48200 to 0.49120, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 1.5836 - accuracy: 0.5567 - val_loss: 2.0739 - val_accuracy: 0.4912\n",
      "Epoch 17/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5315 - accuracy: 0.5689\n",
      "Epoch 00017: val_accuracy did not improve from 0.49120\n",
      "391/390 [==============================] - 40s 104ms/step - loss: 1.5315 - accuracy: 0.5689 - val_loss: 2.2359 - val_accuracy: 0.4525\n",
      "Epoch 18/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4671 - accuracy: 0.5845\n",
      "Epoch 00018: val_accuracy improved from 0.49120 to 0.50030, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 1.4671 - accuracy: 0.5845 - val_loss: 1.9862 - val_accuracy: 0.5003\n",
      "Epoch 19/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4052 - accuracy: 0.6017\n",
      "Epoch 00019: val_accuracy improved from 0.50030 to 0.52640, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 105ms/step - loss: 1.4052 - accuracy: 0.6017 - val_loss: 1.8393 - val_accuracy: 0.5264\n",
      "Epoch 20/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3684 - accuracy: 0.6129\n",
      "Epoch 00020: val_accuracy did not improve from 0.52640\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 1.3684 - accuracy: 0.6129 - val_loss: 1.9341 - val_accuracy: 0.5155\n",
      "Epoch 21/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3300 - accuracy: 0.6234\n",
      "Epoch 00021: val_accuracy did not improve from 0.52640\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 1.3300 - accuracy: 0.6234 - val_loss: 1.9277 - val_accuracy: 0.5206\n",
      "Epoch 22/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2716 - accuracy: 0.6381\n",
      "Epoch 00022: val_accuracy improved from 0.52640 to 0.54240, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 1.2716 - accuracy: 0.6381 - val_loss: 1.8689 - val_accuracy: 0.5424\n",
      "Epoch 23/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2256 - accuracy: 0.6494\n",
      "Epoch 00023: val_accuracy did not improve from 0.54240\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 1.2256 - accuracy: 0.6494 - val_loss: 1.9859 - val_accuracy: 0.5194\n",
      "Epoch 24/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1913 - accuracy: 0.6578\n",
      "Epoch 00024: val_accuracy did not improve from 0.54240\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 1.1913 - accuracy: 0.6578 - val_loss: 1.9481 - val_accuracy: 0.5247\n",
      "Epoch 25/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1618 - accuracy: 0.6682\n",
      "Epoch 00025: val_accuracy improved from 0.54240 to 0.55650, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 1.1618 - accuracy: 0.6682 - val_loss: 1.7588 - val_accuracy: 0.5565\n",
      "Epoch 26/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1411 - accuracy: 0.6720\n",
      "Epoch 00026: val_accuracy did not improve from 0.55650\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 1.1411 - accuracy: 0.6720 - val_loss: 1.8737 - val_accuracy: 0.5448\n",
      "Epoch 27/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1096 - accuracy: 0.6823\n",
      "Epoch 00027: val_accuracy improved from 0.55650 to 0.56150, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 1.1096 - accuracy: 0.6823 - val_loss: 1.7873 - val_accuracy: 0.5615\n",
      "Epoch 28/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0766 - accuracy: 0.6904\n",
      "Epoch 00028: val_accuracy did not improve from 0.56150\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 1.0766 - accuracy: 0.6904 - val_loss: 1.8183 - val_accuracy: 0.5557\n",
      "Epoch 29/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0318 - accuracy: 0.7015\n",
      "Epoch 00029: val_accuracy improved from 0.56150 to 0.56840, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 1.0318 - accuracy: 0.7015 - val_loss: 1.9627 - val_accuracy: 0.5684\n",
      "Epoch 30/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9937 - accuracy: 0.7118\n",
      "Epoch 00030: val_accuracy improved from 0.56840 to 0.57500, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 0.9937 - accuracy: 0.7118 - val_loss: 1.7404 - val_accuracy: 0.5750\n",
      "Epoch 31/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9684 - accuracy: 0.7172\n",
      "Epoch 00031: val_accuracy did not improve from 0.57500\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 0.9684 - accuracy: 0.7172 - val_loss: 1.8775 - val_accuracy: 0.5501\n",
      "Epoch 32/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9369 - accuracy: 0.7272\n",
      "Epoch 00032: val_accuracy improved from 0.57500 to 0.58030, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 41s 104ms/step - loss: 0.9369 - accuracy: 0.7272 - val_loss: 1.7052 - val_accuracy: 0.5803\n",
      "Epoch 33/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9080 - accuracy: 0.7350\n",
      "Epoch 00033: val_accuracy did not improve from 0.58030\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 0.9080 - accuracy: 0.7350 - val_loss: 1.9964 - val_accuracy: 0.5468\n",
      "Epoch 34/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8803 - accuracy: 0.7441\n",
      "Epoch 00034: val_accuracy did not improve from 0.58030\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 0.8803 - accuracy: 0.7441 - val_loss: 1.7524 - val_accuracy: 0.5779\n",
      "Epoch 35/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8566 - accuracy: 0.7479\n",
      "Epoch 00035: val_accuracy did not improve from 0.58030\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 0.8566 - accuracy: 0.7479 - val_loss: 2.2967 - val_accuracy: 0.5565\n",
      "Epoch 36/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8319 - accuracy: 0.7553\n",
      "Epoch 00036: val_accuracy did not improve from 0.58030\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.8319 - accuracy: 0.7553 - val_loss: 1.8501 - val_accuracy: 0.5610\n",
      "Epoch 37/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8114 - accuracy: 0.7593\n",
      "Epoch 00037: val_accuracy did not improve from 0.58030\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.8114 - accuracy: 0.7593 - val_loss: 1.9045 - val_accuracy: 0.5580\n",
      "Epoch 38/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.7646\n",
      "Epoch 00038: val_accuracy did not improve from 0.58030\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.7976 - accuracy: 0.7646 - val_loss: 1.7965 - val_accuracy: 0.5799\n",
      "Epoch 39/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7661 - accuracy: 0.7723\n",
      "Epoch 00039: val_accuracy improved from 0.58030 to 0.60470, saving model to VGG_Adam_BATCHNORM.hdf5\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 0.7661 - accuracy: 0.7723 - val_loss: 1.7202 - val_accuracy: 0.6047\n",
      "Epoch 40/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7484 - accuracy: 0.7764\n",
      "Epoch 00040: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.7484 - accuracy: 0.7764 - val_loss: 1.9494 - val_accuracy: 0.5708\n",
      "Epoch 41/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.7812\n",
      "Epoch 00041: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.7346 - accuracy: 0.7812 - val_loss: 2.0028 - val_accuracy: 0.5598\n",
      "Epoch 42/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7058 - accuracy: 0.7900\n",
      "Epoch 00042: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 103ms/step - loss: 0.7058 - accuracy: 0.7900 - val_loss: 1.8366 - val_accuracy: 0.5891\n",
      "Epoch 43/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.7949\n",
      "Epoch 00043: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.6900 - accuracy: 0.7949 - val_loss: 1.8304 - val_accuracy: 0.5919\n",
      "Epoch 44/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.8006\n",
      "Epoch 00044: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.6705 - accuracy: 0.8006 - val_loss: 1.8271 - val_accuracy: 0.6003\n",
      "Epoch 45/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.8033\n",
      "Epoch 00045: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.6590 - accuracy: 0.8033 - val_loss: 1.7848 - val_accuracy: 0.5965\n",
      "Epoch 46/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.8116\n",
      "Epoch 00046: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.6352 - accuracy: 0.8116 - val_loss: 1.8821 - val_accuracy: 0.5754\n",
      "Epoch 47/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.8144\n",
      "Epoch 00047: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.6215 - accuracy: 0.8144 - val_loss: 2.2377 - val_accuracy: 0.5409\n",
      "Epoch 48/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.8204\n",
      "Epoch 00048: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.6035 - accuracy: 0.8204 - val_loss: 1.8451 - val_accuracy: 0.5982\n",
      "Epoch 49/50\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5908 - accuracy: 0.8228Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.60470\n",
      "391/390 [==============================] - 40s 102ms/step - loss: 0.5908 - accuracy: 0.8228 - val_loss: 2.0749 - val_accuracy: 0.5808\n",
      "Epoch 00049: early stopping\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=50, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "hKbldP9lJfI4",
    "outputId": "4c42454a-9667-4f3e-d20a-702ee20b2755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.6314587318430532\n",
      "Recall: 0.6047\n",
      "Accuracy: 0.6047\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "pqfbpy9AJfMZ",
    "outputId": "4cbd4bb5-0c96-4d4a-8ab7-5280a34319ae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEt6YxfvJfQY"
   },
   "source": [
    "# cell to load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required packages and libraries.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.layers import ELU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalising the data.\n",
    "x_test /= 255 #normalising the data.\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "initializer = keras.initializers.HeNormal()\n",
    "\n",
    "#building the sequential model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = input_shape,filters=64,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=2048))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dense(units=2048))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dense(units=100, activation=\"softmax\"))\n",
    "\n",
    "model.load_weights('../weights/VGG16_Adam_With_BatchNormalization.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG_Adam_BATCHNORM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
